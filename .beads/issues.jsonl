{"id":"coding_agent_usage_tracker-0a0","title":"Doctor: Provider health check trait and implementations","description":"## Purpose\n\nImplement the health check logic for each provider. This is the core diagnostic logic that determines whether a provider is ready to use.\n\n## Background\n\nEach provider has different requirements:\n- **Claude**: Needs `claude` CLI installed, ~/.claude/.credentials.json present\n- **Codex**: Needs `codex` CLI installed, ~/.codex/auth.json with valid tokens\n- **Gemini**: May need API key or gcloud auth\n- **Cursor**: Needs cursor CLI authenticated\n\nThe health check must be:\n1. Fast (timeout after 5s per provider)\n2. Non-destructive (read-only operations)\n3. Informative (capture version, auth status, etc.)\n\n## Implementation Details\n\n### New file: src/core/doctor/checks.rs\n\n```rust\nuse super::{CheckStatus, DiagnosticCheck, ProviderHealth};\nuse crate::core::provider::Provider;\nuse std::time::{Duration, Instant};\n\n/// Check if a CLI binary is available and get its version.\npub async fn check_cli_installed(provider: Provider) -\u003e DiagnosticCheck {\n    let cli_name = provider.cli_name();\n    let start = Instant::now();\n    \n    match which::which(cli_name) {\n        Ok(path) =\u003e {\n            // Try to get version\n            let version = get_cli_version(cli_name).await;\n            DiagnosticCheck {\n                name: format!(\"{} CLI installed\", cli_name),\n                status: CheckStatus::Pass {\n                    details: Some(format!(\"Found at {:?}, version: {}\", path, version.unwrap_or(\"unknown\".into()))),\n                },\n                duration: Some(start.elapsed()),\n            }\n        }\n        Err(_) =\u003e DiagnosticCheck {\n            name: format!(\"{} CLI installed\", cli_name),\n            status: CheckStatus::Fail {\n                reason: \"CLI not found in PATH\".into(),\n                suggestion: Some(provider.install_suggestion()),\n            },\n            duration: Some(start.elapsed()),\n        },\n    }\n}\n\n/// Check authentication status for a provider.\npub async fn check_authenticated(provider: Provider) -\u003e DiagnosticCheck {\n    // Provider-specific auth checks\n    match provider {\n        Provider::Claude =\u003e check_claude_auth().await,\n        Provider::Codex =\u003e check_codex_auth().await,\n        // ... other providers\n    }\n}\n\n/// Check if provider API/service is reachable.\npub async fn check_api_reachable(provider: Provider) -\u003e DiagnosticCheck {\n    // Lightweight connectivity check\n    // For CLI-based providers, might just verify CLI responds\n    // For API providers, might ping a health endpoint\n}\n```\n\n### Provider-specific helpers\n\nEach provider needs specific auth check logic:\n\n```rust\nasync fn check_claude_auth() -\u003e DiagnosticCheck {\n    let claude_dir = dirs::home_dir().map(|h| h.join(\".claude\"));\n    \n    if let Some(dir) = claude_dir {\n        let creds_path = dir.join(\".credentials.json\");\n        if creds_path.exists() {\n            // Try to read and validate\n            match read_claude_credentials(\u0026creds_path) {\n                Ok(creds) =\u003e CheckStatus::Pass {\n                    details: creds.email.map(|e| format!(\"Logged in as {}\", e)),\n                },\n                Err(e) =\u003e CheckStatus::Fail {\n                    reason: format!(\"Credentials file invalid: {}\", e),\n                    suggestion: Some(\"Run: claude auth login\".into()),\n                },\n            }\n        } else {\n            CheckStatus::Fail {\n                reason: \"No credentials file found\".into(),\n                suggestion: Some(\"Run: claude auth login\".into()),\n            }\n        }\n    } else {\n        CheckStatus::Fail {\n            reason: \"Cannot determine home directory\".into(),\n            suggestion: None,\n        }\n    }\n}\n```\n\n## Testing Strategy\n\n- Mock filesystem for auth file checks\n- Mock which::which for CLI detection\n- Integration tests with actual CLIs where available\n\n## Acceptance Criteria\n\n- [ ] check_cli_installed works for all providers\n- [ ] check_authenticated detects auth state accurately\n- [ ] check_api_reachable has reasonable timeout (5s)\n- [ ] All checks return actionable suggestions on failure\n- [ ] Checks run in parallel for performance","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:48:37.696602386-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:56:32.86329994-05:00","closed_at":"2026-01-18T04:56:32.86329994-05:00","close_reason":"Implemented provider health checks in src/core/doctor/checks.rs. Features: check_cli_installed with version detection, check_authenticated (Claude, Codex, Gemini, Cursor, generic), check_api_reachable with 5s timeout, parallel execution via tokio::join!/futures::join_all, actionable suggestions via Provider::install_suggestion()/auth_suggestion(). All 94 tests pass.","dependencies":[{"issue_id":"coding_agent_usage_tracker-0a0","depends_on_id":"coding_agent_usage_tracker-4yc","type":"blocks","created_at":"2026-01-18T02:48:45.259671266-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-0o5","title":"Offline: Add fallback logic with fetch strategies","description":"## Summary\nImplement fallback logic that returns cached data when network fetches fail.\n\n## Background\nThe cache layer stores data; this task implements the fetch-with-fallback pattern:\n1. Try network fetch\n2. On failure, return cached data\n3. Mark data as stale\n4. Continue operating\n\n## Technical Design\n\n### Fetch with Fallback\n```rust\npub struct FallbackFetcher {\n    inner_fetcher: Box\u003cdyn UsageFetcher\u003e,\n    cache: OfflineCache,\n}\n\nimpl FallbackFetcher {\n    pub async fn fetch(\u0026self, provider: \u0026str) -\u003e FetchOutcome {\n        // Try network fetch\n        match self.inner_fetcher.fetch(provider).await {\n            Ok(payload) =\u003e {\n                // Update cache on success\n                self.cache.set(provider, \u0026payload).ok();\n                \n                FetchOutcome {\n                    payload,\n                    source: DataSource::Live,\n                    staleness: Staleness::Fresh,\n                    error: None,\n                }\n            }\n            Err(fetch_error) =\u003e {\n                // Try cache fallback\n                self.fallback_to_cache(provider, fetch_error)\n            }\n        }\n    }\n    \n    fn fallback_to_cache(\u0026self, provider: \u0026str, error: FetchError) -\u003e FetchOutcome {\n        match self.cache.get(provider) {\n            Some(entry) =\u003e {\n                FetchOutcome {\n                    payload: entry.payload,\n                    source: DataSource::Cached,\n                    staleness: entry.staleness(),\n                    error: Some(error),\n                }\n            }\n            None =\u003e {\n                FetchOutcome {\n                    payload: ProviderPayload::unavailable(provider),\n                    source: DataSource::None,\n                    staleness: Staleness::VeryStale { age: Duration::MAX },\n                    error: Some(error),\n                }\n            }\n        }\n    }\n}\n```\n\n### Fetch Outcome\n```rust\n#[derive(Debug)]\npub struct FetchOutcome {\n    pub payload: ProviderPayload,\n    pub source: DataSource,\n    pub staleness: Staleness,\n    pub error: Option\u003cFetchError\u003e,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq)]\npub enum DataSource {\n    Live,       // Fresh from network\n    Cached,     // From cache (may be stale)\n    None,       // No data available\n}\n\nimpl FetchOutcome {\n    pub fn is_live(\u0026self) -\u003e bool {\n        self.source == DataSource::Live\n    }\n    \n    pub fn is_cached(\u0026self) -\u003e bool {\n        self.source == DataSource::Cached\n    }\n    \n    pub fn is_usable(\u0026self) -\u003e bool {\n        self.source != DataSource::None\n    }\n    \n    pub fn had_error(\u0026self) -\u003e bool {\n        self.error.is_some()\n    }\n}\n```\n\n### Network Detection\n```rust\npub struct NetworkChecker;\n\nimpl NetworkChecker {\n    /// Quick check if network is likely available\n    pub async fn is_available(\u0026self) -\u003e bool {\n        // Try to reach a reliable endpoint\n        let client = reqwest::Client::builder()\n            .timeout(Duration::from_secs(2))\n            .build()\n            .ok();\n        \n        if let Some(client) = client {\n            // Try multiple endpoints in parallel\n            let checks = vec![\n                client.head(\"https://www.google.com\").send(),\n                client.head(\"https://api.anthropic.com\").send(),\n            ];\n            \n            let results = futures::future::join_all(checks).await;\n            results.iter().any(|r| r.is_ok())\n        } else {\n            false\n        }\n    }\n    \n    /// Check with minimal latency (for prompt integration)\n    pub fn is_likely_available(\u0026self) -\u003e bool {\n        // Just check if we have any network interface up\n        // This is faster but less reliable\n        #[cfg(unix)]\n        {\n            use std::process::Command;\n            Command::new(\"ping\")\n                .args([\"-c\", \"1\", \"-W\", \"1\", \"8.8.8.8\"])\n                .output()\n                .map(|o| o.status.success())\n                .unwrap_or(false)\n        }\n        \n        #[cfg(not(unix))]\n        true  // Assume available on non-unix\n    }\n}\n```\n\n### Fetch Strategy\n```rust\npub enum FetchStrategy {\n    NetworkOnly,           // Fail if network unavailable\n    NetworkWithFallback,   // Try network, fall back to cache\n    CacheFirst,            // Use cache if fresh, else fetch\n    CacheOnly,             // Only use cache, never fetch\n}\n\nimpl FallbackFetcher {\n    pub async fn fetch_with_strategy(\n        \u0026self,\n        provider: \u0026str,\n        strategy: FetchStrategy,\n    ) -\u003e FetchOutcome {\n        match strategy {\n            FetchStrategy::NetworkOnly =\u003e {\n                self.fetch_network_only(provider).await\n            }\n            FetchStrategy::NetworkWithFallback =\u003e {\n                self.fetch(provider).await  // Default behavior\n            }\n            FetchStrategy::CacheFirst =\u003e {\n                if let Some(entry) = self.cache.get(provider) {\n                    if entry.is_fresh() {\n                        return FetchOutcome::from_cache(entry);\n                    }\n                }\n                self.fetch(provider).await\n            }\n            FetchStrategy::CacheOnly =\u003e {\n                self.cache.get(provider)\n                    .map(FetchOutcome::from_cache)\n                    .unwrap_or_else(|| FetchOutcome::unavailable(provider))\n            }\n        }\n    }\n}\n```\n\n## CLI Integration\n```bash\n# Normal behavior (network with fallback)\ncaut\n\n# Force cache only (fast, offline)\ncaut --offline\n\n# Force network only (fail if unavailable)\ncaut --no-cache\n\n# Refresh cache even if fresh\ncaut --refresh\n```\n\n## Acceptance Criteria\n- [ ] Network fetch with automatic cache fallback\n- [ ] Staleness preserved from cache\n- [ ] Errors preserved for display\n- [ ] CacheFirst strategy works\n- [ ] CacheOnly strategy works\n- [ ] NetworkOnly strategy works\n- [ ] --offline flag works\n- [ ] --no-cache flag works\n- [ ] --refresh flag works\n\n## Error Scenarios\n| Scenario | Behavior |\n|----------|----------|\n| Network OK | Return live data, update cache |\n| Network fail, cache fresh | Return cached (stale), show warning |\n| Network fail, cache stale | Return cached (very stale), show warning |\n| Network fail, no cache | Return unavailable, show error |\n| --offline | Skip network, use cache only |\n\n## Dependencies\n- Requires cache layer (sibling task)\n- Used by CLI and watch mode\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:19:04.838748796-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:19:04.838748796-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-0o5","depends_on_id":"coding_agent_usage_tracker-bkz","type":"blocks","created_at":"2026-01-18T14:22:18.462473084-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-0vz","title":"Unit tests for utility functions (utils.rs)","description":"## Overview\nTest utility functions used across the codebase.\n\n## Target: src/utils.rs or equivalent utility modules\n\n## Test Cases\n1. **Number Formatting**\n   - Thousand separators\n   - Decimal precision\n   - Negative numbers\n   - Large numbers\n\n2. **Time Formatting**\n   - Duration display (2h 30m)\n   - Relative time (\"in 2 hours\")\n   - Timezone handling\n\n3. **String Utilities**\n   - Truncation with ellipsis\n   - Sanitization\n   - Case conversion\n\n4. **Path Utilities**\n   - Home directory expansion\n   - Path joining\n   - Extension handling\n\n## Acceptance Criteria\n- [ ] All utility functions tested\n- [ ] Edge cases covered\n- [ ] Cross-platform behavior verified","status":"open","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:15:02.545646872-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:15:02.545646872-05:00"}
{"id":"coding_agent_usage_tracker-109","title":"TUI: Implement provider card widgets with gauges","description":"Implement ProviderCard component with usage gauges, status indicators, cost info, and compact mode. See /tmp/bead_tui_impl_tasks.md Task 2 for detailed implementation.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:13:08.358205984-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:13:08.358205984-05:00"}
{"id":"coding_agent_usage_tracker-1i9","title":"Unit tests for render/robot.rs (JSON/Markdown output)","description":"## Overview\nTest JSON/robot mode output rendering.\n\n## Target: src/render/json.rs (or robot.rs)\nCritical for: Machine-readable output, CI integration\n\n## Test Cases\n1. **RobotOutput Envelope**\n   - Schema version present\n   - Generated timestamp format\n   - Command field accuracy\n\n2. **Provider Serialization**\n   - All fields serialized correctly\n   - Optional fields omitted when None\n   - camelCase field naming\n\n3. **Error Handling**\n   - Errors array populated\n   - Partial success (some providers fail)\n\n4. **Pretty vs Compact**\n   - --json produces valid JSON\n   - Formatting options\n\n## Acceptance Criteria\n- [ ] Valid JSON output verified\n- [ ] Schema compliance checked\n- [ ] Round-trip deserialization works\n- [ ] Error envelope tested","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:14:36.54507486-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T11:10:28.678377745-05:00","closed_at":"2026-01-18T11:10:28.678377745-05:00","close_reason":"33 unit tests for render/robot.rs: RobotOutput envelope (schema, timestamp, command, meta), provider serialization (all fields, optional fields, camelCase), error handling (empty/populated arrays, partial success), pretty vs compact JSON, round-trip serialization, multi-provider, markdown format tests","dependencies":[{"issue_id":"coding_agent_usage_tracker-1i9","depends_on_id":"coding_agent_usage_tracker-32d","type":"blocks","created_at":"2026-01-18T02:18:19.61107567-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-1mj","title":"Errors: Fix suggestion database","description":"## Overview\nCreate a database of fix suggestions mapped to error types, including commands, context, and prevention tips.\n\n## Background \u0026 Rationale\nThis is the knowledge base that powers actionable errors. Each error type needs curated fix suggestions that are specific, accurate, and helpful.\n\n## Technical Approach\n\n### 1. Fix Suggestion Structure\n```rust\n// In error/suggestions.rs\n#[derive(Debug, Clone)]\npub struct FixSuggestion {\n    /// Primary fix commands (in order of preference).\n    pub commands: Vec\u003cString\u003e,\n    \n    /// Explanation of why this error occurred.\n    pub context: String,\n    \n    /// Tips to prevent this error in future.\n    pub prevention: Option\u003cString\u003e,\n    \n    /// Link to documentation.\n    pub doc_url: Option\u003cString\u003e,\n    \n    /// Whether this can be auto-fixed.\n    pub auto_fixable: bool,\n}\n\n#[derive(Debug, Clone)]\npub struct ErrorWithFix {\n    pub error: CautError,\n    pub suggestions: Vec\u003cFixSuggestion\u003e,\n}\n```\n\n### 2. Suggestion Database\n```rust\nimpl CautError {\n    pub fn fix_suggestions(\u0026self) -\u003e Vec\u003cFixSuggestion\u003e {\n        match self {\n            Self::AuthExpired { provider, .. } =\u003e vec![\n                FixSuggestion {\n                    commands: vec![\n                        format!(\"caut auth refresh {}\", provider),\n                        format!(\"caut auth login {}\", provider),\n                    ],\n                    context: format!(\n                        \"Your OAuth token for {} has expired. Tokens are typically \\\n                        valid for 24 hours. The token may have been revoked if you \\\n                        logged out elsewhere.\",\n                        provider\n                    ),\n                    prevention: Some(\n                        \"Use `caut usage --watch` to monitor session health and \\\n                        get alerts before tokens expire.\".to_string()\n                    ),\n                    doc_url: Some(\"https://github.com/.../docs/auth.md\".to_string()),\n                    auto_fixable: false,\n                },\n            ],\n            \n            Self::AuthNotConfigured { provider } =\u003e vec![\n                FixSuggestion {\n                    commands: vec![\n                        format!(\"caut auth login {}\", provider),\n                        format!(\"caut setup {}\", provider),\n                    ],\n                    context: format!(\n                        \"No credentials found for {}. This provider requires \\\n                        authentication to access usage data.\",\n                        provider\n                    ),\n                    prevention: None,\n                    doc_url: Some(\"https://github.com/.../docs/setup.md\".to_string()),\n                    auto_fixable: false,\n                },\n            ],\n            \n            Self::Timeout { provider, seconds } =\u003e vec![\n                FixSuggestion {\n                    commands: vec![\n                        format!(\"caut usage --provider {} --timeout {}\", provider, seconds * 2),\n                        \"caut doctor --provider \u003cprovider\u003e\".to_string(),\n                    ],\n                    context: format!(\n                        \"The {} provider did not respond within {}s. This could be \\\n                        due to network issues, provider slowness, or the CLI tool \\\n                        being unresponsive.\",\n                        provider, seconds\n                    ),\n                    prevention: Some(\n                        \"Increase timeout with --timeout or in config file. Consider \\\n                        disabling slow providers if this persists.\".to_string()\n                    ),\n                    doc_url: None,\n                    auto_fixable: false,\n                },\n            ],\n            \n            Self::ConfigParse { path, line, message } =\u003e vec![\n                FixSuggestion {\n                    commands: vec![\n                        format!(\"$EDITOR {}\", path),\n                        \"caut config init --force\".to_string(),\n                    ],\n                    context: format!(\n                        \"The config file has a syntax error{}. The TOML parser \\\n                        reported: {}\",\n                        line.map(|l| format!(\" on line {}\", l)).unwrap_or_default(),\n                        message\n                    ),\n                    prevention: Some(\n                        \"Use `caut config show` after editing to validate config. \\\n                        Consider using a TOML-aware editor.\".to_string()\n                    ),\n                    doc_url: None,\n                    auto_fixable: false,\n                },\n            ],\n            \n            Self::CliNotFound { name } =\u003e vec![\n                FixSuggestion {\n                    commands: Self::install_commands_for_cli(name),\n                    context: format!(\n                        \"The {} CLI tool is not installed or not in PATH. This \\\n                        provider requires the CLI to fetch usage data.\",\n                        name\n                    ),\n                    prevention: None,\n                    doc_url: Self::install_doc_for_cli(name),\n                    auto_fixable: false,\n                },\n            ],\n            \n            Self::RateLimited { provider, retry_after, .. } =\u003e vec![\n                FixSuggestion {\n                    commands: retry_after.map(|d| vec![\n                        format!(\"sleep {} \u0026\u0026 caut usage --provider {}\", d.as_secs(), provider)\n                    ]).unwrap_or_default(),\n                    context: format!(\n                        \"You have been rate limited by {}. {}\",\n                        provider,\n                        retry_after.map(|d| format!(\"Try again in {} seconds.\", d.as_secs()))\n                            .unwrap_or_else(|| \"Wait before retrying.\".to_string())\n                    ),\n                    prevention: Some(\n                        \"Use `caut usage --watch` with longer intervals to avoid \\\n                        hitting rate limits.\".to_string()\n                    ),\n                    doc_url: None,\n                    auto_fixable: false,\n                },\n            ],\n            \n            // Default for errors without specific suggestions\n            _ =\u003e vec![],\n        }\n    }\n    \n    fn install_commands_for_cli(name: \u0026str) -\u003e Vec\u003cString\u003e {\n        match name {\n            \"claude\" =\u003e vec![\n                \"npm install -g @anthropic-ai/claude-code\".to_string(),\n            ],\n            \"codex\" =\u003e vec![\n                \"npm install -g @openai/codex\".to_string(),\n            ],\n            _ =\u003e vec![],\n        }\n    }\n    \n    fn install_doc_for_cli(name: \u0026str) -\u003e Option\u003cString\u003e {\n        match name {\n            \"claude\" =\u003e Some(\"https://claude.ai/code\".to_string()),\n            \"codex\" =\u003e Some(\"https://openai.com/codex\".to_string()),\n            _ =\u003e None,\n        }\n    }\n}\n```\n\n### 3. Provider-Specific Suggestions\nEach provider module can contribute suggestions:\n```rust\n// In providers/claude/mod.rs\nimpl ClaudeError {\n    pub fn to_caut_error(\u0026self) -\u003e CautError {\n        match self {\n            Self::TokenExpired =\u003e CautError::AuthExpired {\n                provider: \"claude\".to_string(),\n                source: None,\n            },\n            // ...\n        }\n    }\n}\n```\n\n## Files to Create/Modify\n- `src/error/suggestions.rs`: New file for suggestion database\n- `src/error.rs`: Add fix_suggestions() method\n- Provider files: Map provider errors to CautErrors\n\n## Dependencies\n- Requires error taxonomy (v53) to be complete\n\n## Acceptance Criteria\n- [ ] All common errors have at least one suggestion\n- [ ] Commands are copy-paste ready\n- [ ] Context explains root cause\n- [ ] Prevention tips where applicable\n- [ ] CLI install commands for common tools\n\n## Testing Strategy\n- Test all error variants have suggestions (or intentionally dont)\n- Test command formatting\n- Test provider-specific mappings\n- Manual review of suggestion quality","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T03:01:43.149320092-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T12:29:18.614289736-05:00","closed_at":"2026-01-18T12:29:18.614289736-05:00","close_reason":"Created src/error/suggestions.rs with FixSuggestion struct and 20+ suggestion generators for all error types. Added fix_suggestions() method to CautError that provides actionable commands, context, prevention tips, and doc links. Includes CLI install helpers for 10+ tools (claude, codex, cursor, gemini, aider, etc.). Added 39 tests total (7 in suggestions.rs, 32 in mod.rs), all passing.","dependencies":[{"issue_id":"coding_agent_usage_tracker-1mj","depends_on_id":"coding_agent_usage_tracker-v53","type":"blocks","created_at":"2026-01-18T03:03:20.199836418-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-1n2","title":"Config: Core loading, parsing, and validation","description":"## Overview\nImplement the core configuration loading and parsing infrastructure for the caut config file.\n\n## Background \u0026 Rationale\nThis is the foundation for the config system. We need reliable loading with good error messages, validation to catch mistakes early, and a clean API for the rest of the codebase to consume settings.\n\n## Technical Approach\n\n### 1. Config File Location\n```rust\n// In storage/config.rs or core/config.rs\nuse directories::ProjectDirs;\n\npub fn config_path() -\u003e Option\u003cPathBuf\u003e {\n    // Primary: XDG config directory\n    if let Some(proj_dirs) = ProjectDirs::from(\"\", \"\", \"caut\") {\n        let config = proj_dirs.config_dir().join(\"config.toml\");\n        if config.exists() {\n            return Some(config);\n        }\n    }\n    \n    // Fallback: home directory\n    if let Some(home) = dirs::home_dir() {\n        let rc = home.join(\".cautrc\");\n        if rc.exists() {\n            return Some(rc);\n        }\n    }\n    \n    None\n}\n```\n\n### 2. Config Structure\n```rust\n#[derive(Debug, Deserialize, Default)]\n#[serde(default)]\npub struct Config {\n    pub defaults: DefaultsConfig,\n    pub providers: HashMap\u003cString, ProviderConfig\u003e,\n    pub output: OutputConfig,\n}\n\n#[derive(Debug, Deserialize, Default)]\n#[serde(default)]\npub struct DefaultsConfig {\n    pub providers: Option\u003cVec\u003cString\u003e\u003e,\n    pub format: Option\u003cString\u003e,  // \"human\", \"json\", \"md\"\n    pub timeout_seconds: Option\u003cu64\u003e,\n    pub no_color: bool,\n    pub verbose: bool,\n}\n\n#[derive(Debug, Deserialize, Default)]\n#[serde(default)]\npub struct ProviderConfig {\n    pub enabled: bool,\n    pub priority: Option\u003ci32\u003e,\n    pub timeout_seconds: Option\u003cu64\u003e,\n    // Provider-specific settings can be added\n}\n\n#[derive(Debug, Deserialize, Default)]\n#[serde(default)]\npub struct OutputConfig {\n    pub pretty: bool,\n    pub quiet: bool,\n}\n```\n\n### 3. Loading with Error Handling\n```rust\nimpl Config {\n    pub fn load() -\u003e Result\u003cSelf\u003e {\n        match config_path() {\n            Some(path) =\u003e Self::load_from(\u0026path),\n            None =\u003e Ok(Self::default()),\n        }\n    }\n    \n    pub fn load_from(path: \u0026Path) -\u003e Result\u003cSelf\u003e {\n        let content = fs::read_to_string(path)\n            .map_err(|e| CautError::Config(format\\!(\n                \"Failed to read config at {}: {}\", path.display(), e\n            )))?;\n        \n        toml::from_str(\u0026content)\n            .map_err(|e| CautError::Config(format\\!(\n                \"Invalid config at {}: {}\", path.display(), e\n            )))\n    }\n}\n```\n\n### 4. Validation\n```rust\nimpl Config {\n    pub fn validate(\u0026self) -\u003e Result\u003c()\u003e {\n        // Validate provider names\n        if let Some(providers) = \u0026self.defaults.providers {\n            for name in providers {\n                Provider::from_cli_name(name)?;\n            }\n        }\n        \n        // Validate format\n        if let Some(format) = \u0026self.defaults.format {\n            if \\![\"human\", \"json\", \"md\"].contains(\u0026format.as_str()) {\n                return Err(CautError::Config(format\\!(\n                    \"Invalid format \\\"{}\\\". Valid: human, json, md\", format\n                )));\n            }\n        }\n        \n        // Validate timeouts (reasonable bounds)\n        if let Some(timeout) = self.defaults.timeout_seconds {\n            if timeout == 0 || timeout \u003e 300 {\n                return Err(CautError::Config(\n                    \"Timeout must be between 1 and 300 seconds\".to_string()\n                ));\n            }\n        }\n        \n        Ok(())\n    }\n}\n```\n\n## Files to Create/Modify\n- `src/core/config.rs`: New file for config types and loading\n- `src/storage/paths.rs`: Add config path helper\n- `src/lib.rs`: Export config module\n\n## Dependencies\n- None - this is the foundation subtask\n\n## Acceptance Criteria\n- [ ] Config loads from XDG path or ~/.cautrc fallback\n- [ ] Missing config file returns default (not error)\n- [ ] Invalid TOML gives clear error with line number\n- [ ] Invalid values (bad provider name) give clear error\n- [ ] Config struct has sensible defaults via serde(default)\n\n## Testing Strategy\n- Test loading valid config files\n- Test graceful handling of missing file\n- Test error messages for various invalid configs\n- Test XDG path detection","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:55:50.520688461-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T05:10:54.995759764-05:00","closed_at":"2026-01-18T05:10:54.995759764-05:00","close_reason":"Config core loading complete: XDG-based path resolution, TOML parsing with clear errors, validate() method for provider names/formats/timeouts, sensible defaults via serde(default). All 114 tests pass including 6 new validation tests."}
{"id":"coding_agent_usage_tracker-1pf","title":"E2E test script: Error scenarios and edge cases","description":"## Overview\nEnd-to-end tests for error handling, edge cases, and failure recovery.\n\n## Dual Implementation Strategy\nCreate BOTH shell scripts and Rust integration tests.\n\n## Shell Script: tests/e2e/test_errors.sh\n\n### Test Scenarios\n```bash\n#!/usr/bin/env bash\nset -uo pipefail  # No -e: we expect some failures\n\nLOG_DIR=\"${TEST_LOG_DIR:-./test-logs}\"\nLOG_FILE=\"$LOG_DIR/test_errors_$(date +%Y%m%d_%H%M%S).log\"\nmkdir -p \"$LOG_DIR\"\n\nlog() { echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $*\" | tee -a \"$LOG_FILE\"; }\npass() { log \"‚úì PASS: $*\"; }\nfail() { log \"‚úó FAIL: $*\"; }\n\n# Test 1: Invalid Provider Name\nlog \"TEST: Invalid provider name\"\nOUTPUT=$(caut usage --provider=nonexistent 2\u003e\u00261)\nEXIT_CODE=$?\nif [ $EXIT_CODE -ne 0 ]; then\n    pass \"Exit code non-zero for invalid provider\"\n    log \"STDERR: $OUTPUT\"\n    # Verify helpful error message\n    if echo \"$OUTPUT\" | grep -qiE 'invalid|unknown|not found|available'; then\n        pass \"Error message is helpful\"\n    else\n        fail \"Error message not helpful enough\"\n    fi\nelse\n    fail \"Should have exited non-zero\"\nfi\n\n# Test 2: Invalid Command\nlog \"TEST: Invalid command\"\nOUTPUT=$(caut invalidcmd 2\u003e\u00261)\nEXIT_CODE=$?\nif [ $EXIT_CODE -ne 0 ]; then\n    pass \"Exit code non-zero for invalid command\"\nelse\n    fail \"Should have rejected invalid command\"\nfi\n\n# Test 3: Help Flag\nlog \"TEST: Help flag\"\nOUTPUT=$(caut --help 2\u003e\u00261)\nEXIT_CODE=$?\nif [ $EXIT_CODE -eq 0 ]; then\n    pass \"Help exits cleanly\"\n    if echo \"$OUTPUT\" | grep -qE 'usage|cost|USAGE'; then\n        pass \"Help mentions commands\"\n    fi\nelse\n    fail \"Help should exit 0\"\nfi\n\n# Test 4: Version Flag\nlog \"TEST: Version flag\"\nOUTPUT=$(caut --version 2\u003e\u00261)\nif [ $? -eq 0 ] \u0026\u0026 echo \"$OUTPUT\" | grep -qE '[0-9]+\\.[0-9]+'; then\n    pass \"Version output valid\"\nelse\n    fail \"Version output missing or invalid\"\nfi\n\n# Test 5: Conflicting Flags (if any)\nlog \"TEST: Flag conflicts\"\n# Example: --json and --no-color might conflict or one might win\nOUTPUT=$(caut usage --json --no-color 2\u003e\u00261)\nEXIT_CODE=$?\nlog \"Combined flags exit code: $EXIT_CODE\"\nlog \"Output: $OUTPUT\"\n# Verify output is still valid\nif [ $EXIT_CODE -eq 0 ]; then\n    if echo \"$OUTPUT\" | jq . \u003e/dev/null 2\u003e\u00261; then\n        pass \"JSON mode takes precedence (expected)\"\n    else\n        log \"INFO: Human output with no-color (also valid)\"\n    fi\nfi\n\n# Test 6: No Providers Available (simulated)\nlog \"TEST: No providers scenario\"\n# Would require isolated environment with no configs\nlog \"SKIP: Requires isolated test environment\"\n\n# Test 7: Corrupted Config File\nlog \"TEST: Corrupted config handling\"\nTEMP_CONFIG=$(mktemp)\necho \"this is not valid toml {{{{\" \u003e \"$TEMP_CONFIG\"\nOUTPUT=$(CAUT_CONFIG=\"$TEMP_CONFIG\" caut usage 2\u003e\u00261) || true\nrm -f \"$TEMP_CONFIG\"\nlog \"Corrupted config output: $OUTPUT\"\n# Should not panic\nif echo \"$OUTPUT\" | grep -qi \"panic\"; then\n    fail \"Panic detected with corrupted config\"\nelse\n    pass \"No panic with corrupted config\"\nfi\n\n# Test 8: Timeout Simulation\nlog \"TEST: Timeout behavior\"\n# Would need network simulation\nlog \"SKIP: Requires network simulation\"\n\n# Test 9: Permission Denied\nlog \"TEST: Permission denied handling\"\nif [ \"$(id -u)\" -ne 0 ]; then\n    # Try to read a protected path\n    OUTPUT=$(caut usage --verbose 2\u003e\u00261) || true\n    # Should not crash even if some configs unreadable\n    if echo \"$OUTPUT\" | grep -qi \"panic\"; then\n        fail \"Panic on permission issues\"\n    else\n        pass \"Handled permission issues gracefully\"\n    fi\nelse\n    log \"SKIP: Running as root, can't test permissions\"\nfi\n\n# Generate summary\nlog \"========== TEST SUMMARY ==========\"\nPASS_COUNT=$(grep -c \"‚úì PASS\" \"$LOG_FILE\" || echo 0)\nFAIL_COUNT=$(grep -c \"‚úó FAIL\" \"$LOG_FILE\" || echo 0)\nlog \"Passed: $PASS_COUNT\"\nlog \"Failed: $FAIL_COUNT\"\nlog \"Log file: $LOG_FILE\"\n```\n\n## Rust Tests: tests/e2e_errors.rs\n\n```rust\nuse assert_cmd::Command;\nuse predicates::prelude::*;\nuse std::io::Write;\nuse tempfile::NamedTempFile;\n\n#[test]\nfn test_invalid_provider() {\n    let mut cmd = Command::cargo_bin(\"caut\").unwrap();\n    cmd.arg(\"usage\")\n        .arg(\"--provider=nonexistent\")\n        .assert()\n        .failure()\n        .stderr(predicate::str::contains(\"invalid\").or(\n            predicate::str::contains(\"unknown\")\n        ));\n}\n\n#[test]\nfn test_invalid_command() {\n    let mut cmd = Command::cargo_bin(\"caut\").unwrap();\n    cmd.arg(\"notacommand\")\n        .assert()\n        .failure();\n}\n\n#[test]\nfn test_help_exits_zero() {\n    let mut cmd = Command::cargo_bin(\"caut\").unwrap();\n    cmd.arg(\"--help\")\n        .assert()\n        .success()\n        .stdout(predicate::str::contains(\"usage\").or(\n            predicate::str::contains(\"Usage\")\n        ));\n}\n\n#[test]\nfn test_version_format() {\n    let mut cmd = Command::cargo_bin(\"caut\").unwrap();\n    cmd.arg(\"--version\")\n        .assert()\n        .success()\n        .stdout(predicate::str::is_match(r\"\\d+\\.\\d+\").unwrap());\n}\n\n#[test]\nfn test_corrupted_config_no_panic() {\n    // Create a corrupted config file\n    let mut temp_config = NamedTempFile::new().unwrap();\n    writeln!(temp_config, \"this is {{ not valid toml\").unwrap();\n    \n    let mut cmd = Command::cargo_bin(\"caut\").unwrap();\n    let output = cmd.arg(\"usage\")\n        .env(\"CAUT_CONFIG\", temp_config.path())\n        .output()\n        .unwrap();\n    \n    // Should not contain panic\n    let stderr = String::from_utf8_lossy(\u0026output.stderr);\n    assert!(!stderr.to_lowercase().contains(\"panic\"),\n        \"Should not panic on corrupted config\");\n}\n\n#[test]\nfn test_empty_output_json_valid() {\n    // Even with no data, JSON should be valid\n    let mut cmd = Command::cargo_bin(\"caut\").unwrap();\n    let output = cmd.arg(\"usage\")\n        .arg(\"--json\")\n        .output()\n        .unwrap();\n    \n    // Should always produce valid JSON (even if data is empty)\n    let _: serde_json::Value = serde_json::from_slice(\u0026output.stdout)\n        .expect(\"Output should always be valid JSON\");\n}\n```\n\n## Exit Code Specification\n- `0`: Success (data retrieved)\n- `1`: General error (invalid args, config issues)\n- `2`: No providers available\n- `3`: All providers failed\n- `4`: Partial success (some providers failed)\n\n## Error Message Guidelines\nError messages should:\n1. State WHAT went wrong clearly\n2. Suggest HOW to fix it if possible\n3. NOT include stack traces in normal mode\n4. Include stack traces in --verbose mode\n5. Be human-readable, not codes\n\n## Acceptance Criteria\n- [ ] Invalid provider name tested\n- [ ] Invalid command tested\n- [ ] Help flag tested\n- [ ] Version flag tested\n- [ ] Corrupted config handled (no panic)\n- [ ] Exit codes verified\n- [ ] Error messages validated for helpfulness\n- [ ] No panics under any error condition","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:17:05.928581153-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:55:20.849377611-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-1pf","depends_on_id":"coding_agent_usage_tracker-cn8","type":"blocks","created_at":"2026-01-18T02:18:32.847856336-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-1pf","depends_on_id":"coding_agent_usage_tracker-oyf","type":"blocks","created_at":"2026-01-18T02:18:32.898026234-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-1uv","title":"E2E test script: Performance and stress tests","description":"## Overview\nPerformance benchmarks and stress tests for the CLI.\n\n## Script: tests/e2e/test_performance.sh\n\n## Test Scenarios\n1. **Cold Start Time**\n   ```bash\n   time caut usage --help\n   # Target: \u003c 100ms\n   # Log: Multiple runs, avg/p95\n   ```\n\n2. **Full Usage Query**\n   ```bash\n   time caut usage\n   # Target: \u003c 2s (network dependent)\n   # Log: Breakdown by phase\n   ```\n\n3. **Large History**\n   ```bash\n   # Create large cost history\n   caut cost\n   # Target: \u003c 5s for 1000 entries\n   # Log: Memory usage, duration\n   ```\n\n4. **Concurrent Runs**\n   ```bash\n   # Run multiple instances\n   # Target: No data corruption\n   # Log: File locking behavior\n   ```\n\n5. **Repeated Queries**\n   ```bash\n   # Run 100 queries in sequence\n   # Target: Consistent performance\n   # Log: Cache hit ratio\n   ```\n\n## Logging Requirements\n- Timing for each phase\n- Memory usage snapshots\n- CPU usage\n- Cache statistics\n\n## Acceptance Criteria\n- [ ] Baseline metrics established\n- [ ] No performance regressions\n- [ ] Memory stays bounded\n- [ ] Concurrent safety verified","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:17:19.4641482-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:17:19.4641482-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-1uv","depends_on_id":"coding_agent_usage_tracker-cn8","type":"blocks","created_at":"2026-01-18T02:18:32.948277545-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-1wb","title":"TUI: Implement responsive layout for terminal sizes","description":"Create DashboardLayout system that adapts to terminal size (1-4 columns), shows condensed view on small terminals, and gracefully handles resize. See /tmp/bead_tui_impl_tasks.md Task 5.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:13:11.506991052-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:13:11.506991052-05:00"}
{"id":"coding_agent_usage_tracker-295","title":"History: Implement data export to JSON and CSV formats","description":"## Summary\nExport historical usage data for external analysis and backup.\n\n## Commands\n- `caut history export --format json --output history.json`\n- `caut history export --format csv --output history.csv`\n- `caut history export --format json` (stdout)\n\n## JSON Format\n```json\n{\n  \"exported_at\": \"2026-01-18T12:00:00Z\",\n  \"range\": {\n    \"start\": \"2026-01-01T00:00:00Z\",\n    \"end\": \"2026-01-18T12:00:00Z\"\n  },\n  \"snapshots\": [\n    {\n      \"id\": 1,\n      \"provider\": \"claude\",\n      \"fetched_at\": \"2026-01-15T10:30:00Z\",\n      \"primary_used_pct\": 45.5,\n      \"secondary_used_pct\": 32.0,\n      \"tertiary_used_pct\": null\n    }\n  ],\n  \"summary\": {\n    \"total_snapshots\": 1234,\n    \"providers\": [\"claude\", \"codex\"],\n    \"date_range_days\": 18\n  }\n}\n```\n\n## CSV Format\n```csv\nid,provider,fetched_at,primary_used_pct,secondary_used_pct,tertiary_used_pct\n1,claude,2026-01-15T10:30:00Z,45.5,32.0,\n2,codex,2026-01-15T10:30:05Z,28.0,,\n```\n\n## Filtering Options\n- `--since DATE` - Start date\n- `--until DATE` - End date  \n- `--provider NAME` - Single provider\n- `--limit N` - Max rows\n\n## Acceptance Criteria\n- [ ] JSON export with proper structure\n- [ ] CSV export with proper escaping\n- [ ] Date filtering works\n- [ ] Provider filtering works\n- [ ] Large exports don't OOM (streaming)\n- [ ] Stdout output for piping","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:01:58.830712418-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:01:58.830712418-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-295","depends_on_id":"coding_agent_usage_tracker-smv","type":"blocks","created_at":"2026-01-18T15:03:56.204279143-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-2k1","title":"Unit tests for providers/codex.rs (CRITICAL)","description":"## Overview\nüö® CRITICAL: Provider tests have 0% coverage. This is the highest priority.\n\n## Target: src/providers/codex/mod.rs (581 lines)\n\n## Test Cases - Organized by Function\n\n### 1. JWT Decoding (SECURITY-CRITICAL)\n**`decode_jwt_payload()` and `base64_decode()`**\n- Valid 3-part JWT decoding\n- Invalid JWT format (wrong number of parts)\n- Base64url to standard base64 conversion (- to +, _ to /)\n- Padding calculation for base64\n- Malformed base64 handling\n- Invalid JSON in payload\n- Real-world OpenAI JWT samples from fixtures\n\n### 2. Auth File Handling\n**`read_local_auth()`**\n- Valid auth.json with OPENAI_API_KEY\n- Valid auth.json with OAuth tokens (id_token, access_token)\n- Missing auth.json file\n- Empty auth.json\n- Malformed JSON\n\n**`is_authenticated()`**\n- Returns true with API key only\n- Returns true with tokens only\n- Returns true with both\n- Returns false with neither\n\n**`get_local_identity()`**\n- Extract email from JWT claims\n- Extract organization from default org in JWT\n- Extract subscription info (plan_type, dates)\n- Fallback to account_id when JWT decode fails\n- API key auth path (no identity info)\n- Unauthenticated path\n\n### 3. Fetch Plan Creation\n**`fetch_plan()`**\n- Returns two strategies (web-dashboard, cli-rpc)\n- Web dashboard availability check (platform-conditional)\n- CLI availability check via which::which\n\n**`is_cli_available()`**\n- Returns true when codex binary in PATH\n- Returns false when missing\n\n### 4. CLI Version Parsing\n**`get_cli_version()`**\n- Parse \"codex 0.6.0\" format\n- Parse \"0.6.0\" format (version only)\n- Handle CLI error output\n\n### 5. Rate Limit Response Parsing\n**`try_json_rate_limit()`**\n- Test all command variations tried\n- Handle command not found errors\n\n**`parse_rate_limit_response()`**\n- Full response with all fields\n- Response with only rate_limit\n- Response with only credits\n- Response with only user\n- Empty/null fields\n- Calculate used_percent from remaining_percent\n- Weekly reset calculation (10080 minutes = 7 days)\n- Timestamp parsing for resets_at\n\n### 6. Main Fetch Functions\n**`fetch_cli()`**\n- Successful fetch with identity extraction\n- No auth.json exists\n- Invalid auth.json\n- Integration with get_local_identity\n\n**`fetch_web_dashboard()`**\n- Returns UnsupportedSource on non-macOS\n- (macOS-only tests if applicable)\n\n**`fetch_credits()`**\n- Successful credits fetch\n- No credits data available error\n\n## Fixture Requirements\n- Sample ~/.codex/auth.json with real JWT structure\n- Sample CodexRateLimitResponse JSON\n- Real OpenAI JWT tokens (with claims sanitized)\n\n## Acceptance Criteria\n- [ ] JWT decode/encode round-trip tests pass\n- [ ] All auth.json parsing paths covered\n- [ ] Identity extraction verified for all auth methods\n- [ ] Rate limit parsing tested with real response shapes\n- [ ] Error paths tested (missing files, malformed data)\n- [ ] Platform-conditional code tested","status":"closed","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:14:43.1033329-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T10:56:52.409006145-05:00","closed_at":"2026-01-18T10:56:52.409006145-05:00","close_reason":"38 tests now passing covering JWT decoding, auth JSON parsing, rate limit responses, organizations, and fixture-based tests","dependencies":[{"issue_id":"coding_agent_usage_tracker-2k1","depends_on_id":"coding_agent_usage_tracker-32d","type":"blocks","created_at":"2026-01-18T02:18:16.76253207-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-2k1","depends_on_id":"coding_agent_usage_tracker-5b7","type":"blocks","created_at":"2026-01-18T02:18:16.813617693-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-2tn","title":"[EPIC] Credential Health Monitoring and Warnings","description":"## Overview\n\nCredential Health Monitoring proactively warns users before authentication failures occur. Instead of discovering broken auth when something fails, users get advance warning: \"Your Claude OAuth token expires in 3 days.\"\n\n## Strategic Importance (Why P1)\n\n- **Proactive \u003e Reactive**: Prevents frustrating debugging sessions\n- **Builds trust**: Tool that warns you feels reliable\n- **Low complexity**: Extends existing doctor infrastructure\n- **Table stakes**: Expected behavior for any auth-aware tool\n\n## User Value Proposition\n\n**Current state**: User is working, everything seems fine, then suddenly Claude calls fail with auth errors. User spends 30 minutes debugging before realizing token expired.\n\n**Target state**:\n```\n$ caut doctor\nSystem Health Check\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n‚úì Claude CLI: installed (v1.2.3)\n‚úì Codex CLI: installed (v0.6.0)\n‚ö† Claude OAuth: token expires in 3 days\n  ‚Üí Run: caut auth refresh claude\n‚úì Codex Auth: valid (expires in 28 days)\n‚úì Network: all providers reachable\n```\n\nOr integrated into regular usage:\n```\n$ caut usage\n‚ö†Ô∏è Heads up: Your Claude token expires in 3 days\n\nClaude: 45% used...\n```\n\n## Technical Approach\n\n### JWT Expiration Checking\n\nMost OAuth tokens are JWTs with `exp` claim:\n```rust\nfn check_token_expiry(token: \u0026str) -\u003e CredentialStatus {\n    let claims = decode_jwt_payload(token)?;\n    let exp = claims.exp?;\n    let now = Utc::now().timestamp();\n    let days_until = (exp - now) / 86400;\n    \n    match days_until {\n        d if d \u003c 0 =\u003e CredentialStatus::Expired,\n        d if d \u003c 7 =\u003e CredentialStatus::ExpiringSoon { days: d },\n        d =\u003e CredentialStatus::Valid { expires_in_days: d },\n    }\n}\n```\n\n### Auth Freshness Tracking\n\nTrack last successful authentication per provider:\n```rust\nstruct AuthHealth {\n    provider: Provider,\n    last_success: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    last_failure: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    consecutive_failures: u32,\n    token_status: CredentialStatus,\n}\n```\n\n### Warning Thresholds\n\n- **7 days**: Informational notice\n- **3 days**: Warning with action suggestion\n- **1 day**: Urgent warning\n- **Expired**: Error with remediation steps\n\n## Integration Points\n\n1. **Doctor command**: Comprehensive credential health check\n2. **Usage command**: Header warning if issues detected\n3. **Watch mode**: Persistent banner for credential issues\n4. **Background check**: Optional periodic validation\n\n## Commands\n\n- `caut doctor` - Full health check (existing, enhanced)\n- `caut doctor --credentials` - Credential-focused check\n- `caut auth status` - Credential status for all providers\n- `caut auth refresh \u003cprovider\u003e` - Refresh/renew credentials\n\n## Success Criteria\n\n- [ ] JWT expiration checked for all OAuth-based providers\n- [ ] API key validity checked where possible\n- [ ] Warning thresholds configurable\n- [ ] Clear remediation suggestions provided\n- [ ] Doctor output includes credential health\n- [ ] Proactive warnings in usage output\n\n## Dependencies\n\n- **Extends**: Existing doctor module infrastructure\n- **Independent of**: Other EPICs (can be built standalone)\n- **Existing code**: JWT decoding already exists in codex provider\n\n## Considerations\n\n- Not all auth methods have checkable expiration (API keys)\n- Some providers don't expose expiration info\n- Avoid excessive validation requests (rate limits)\n- Cache validation results appropriately","status":"open","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:12:27.100820643-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:12:27.100820643-05:00"}
{"id":"coding_agent_usage_tracker-2yz","title":"Unit tests for render/human.rs (terminal output)","description":"## Overview\nTest human-readable terminal rendering with rich_rust.\n\n## Target: src/render/human.rs\nRecently implemented with Panel and ProgressBar components\n\n## Test Cases\n1. **render_usage()**\n   - Single provider output\n   - Multiple providers output\n   - Empty results handling\n\n2. **render_provider_usage()**\n   - All rate windows present\n   - Partial windows (primary only, etc.)\n   - Credits display\n   - Status indicator colors\n\n3. **format_rate_window_segments()**\n   - Color thresholds (green/yellow/red)\n   - Progress bar rendering\n   - Reset description display\n\n4. **format_status_segments()**\n   - All StatusIndicator variants\n   - Description appending\n\n5. **render_cost()**\n   - Cost display formatting\n   - Token number formatting\n   - Empty activity handling\n\n6. **no_color Mode**\n   - ANSI codes suppressed\n   - Content preserved\n\n## Acceptance Criteria\n- [ ] All public functions tested\n- [ ] Color output verified (contains ANSI)\n- [ ] no_color mode verified (no ANSI)\n- [ ] Edge cases (empty, missing fields)","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:13:59.921725555-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T11:12:39.14252621-05:00","closed_at":"2026-01-18T11:12:39.14252621-05:00","close_reason":"39 unit tests for render/human.rs: render_usage (single/multiple/empty), render_provider_usage (all windows/partial/credits/identity/empty), format_rate_window_segments (label/percentage/reset), percentage_color (green/yellow/red), format_status_segments (all indicators), render_cost (single/multiple/empty/no_activity), format_number (thousands/millions/small), no_color mode tests","dependencies":[{"issue_id":"coding_agent_usage_tracker-2yz","depends_on_id":"coding_agent_usage_tracker-32d","type":"blocks","created_at":"2026-01-18T02:18:19.519304695-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-32d","title":"Create test data fixtures and factories","description":"## Overview\nBuild reusable test data fixtures for consistent, realistic test scenarios.\n\n## Requirements\n- Provider response fixtures (Claude, Codex) - **NOT Cursor (provider does not exist)**\n- Rate window test data at various percentages\n- Status page response samples\n- Cost calculation test data\n- Error response fixtures\n- Token account fixtures\n- Cost scanner cache fixtures\n\n## Implementation Details\n- Create `tests/fixtures/` directory structure\n- JSON fixture files for provider responses\n- Rust factory functions in `tests/common/fixtures.rs`\n- Builder patterns for complex test objects\n\n## Claude Provider Fixtures (CRITICAL for 8gp)\n1. **credentials.json samples**\n   ```json\n   // tests/fixtures/claude/credentials_full.json\n   {\"account_email\": \"user@example.com\", \"organization\": \"Anthropic\"}\n   // tests/fixtures/claude/credentials_minimal.json\n   {\"account_email\": \"user@example.com\"}\n   // tests/fixtures/claude/credentials_empty.json\n   {}\n   ```\n\n2. **CLI limits output samples**\n   ```text\n   // tests/fixtures/claude/cli_output_v0.2.105.txt\n   Session limit: 70% remaining\n   Weekly limit: 85% remaining\n   Opus/Sonnet: 92% remaining\n   // tests/fixtures/claude/cli_output_legacy.txt\n   Rate limit: 45% remaining (resets in 2h)\n   ```\n\n3. **ClaudeRateLimitResponse JSON**\n   ```json\n   // tests/fixtures/claude/rate_limit_full.json\n   {\"rate_limit\": {\"remaining_percent\": 70, \"resets_at\": \"...\"}, \"credits\": {...}}\n   // tests/fixtures/claude/rate_limit_partial.json\n   // tests/fixtures/claude/rate_limit_empty.json\n   ```\n\n## Codex Provider Fixtures (CRITICAL for 2k1)\n1. **auth.json with JWT**\n   ```json\n   // tests/fixtures/codex/auth_oauth.json\n   {\n     \"tokens\": {\n       \"id_token\": \"\u003cbase64-jwt-with-openai-claims\u003e\",\n       \"access_token\": \"...\",\n       \"account_id\": \"acct_xxx\"\n     }\n   }\n   // tests/fixtures/codex/auth_api_key.json\n   {\"OPENAI_API_KEY\": \"sk-xxx\"}\n   // tests/fixtures/codex/auth_both.json\n   ```\n\n2. **Sample JWT payload (sanitized)**\n   ```json\n   // tests/fixtures/codex/jwt_claims_sample.json\n   {\n     \"email\": \"user@example.com\",\n     \"email_verified\": true,\n     \"https://api.openai.com/auth\": {\n       \"chatgpt_plan_type\": \"pro\",\n       \"chatgpt_subscription_active_until\": \"2026-02-01\",\n       \"organizations\": [{\"title\": \"Personal\", \"is_default\": true}]\n     }\n   }\n   ```\n\n3. **CodexRateLimitResponse variants**\n   ```json\n   // tests/fixtures/codex/rate_limit_full.json\n   // tests/fixtures/codex/rate_limit_credits_only.json\n   // tests/fixtures/codex/rate_limit_user_only.json\n   ```\n\n## Status Page Fixtures\n```\ntests/fixtures/status/\n‚îú‚îÄ‚îÄ statuspage_operational.json\n‚îú‚îÄ‚îÄ statuspage_minor.json\n‚îú‚îÄ‚îÄ statuspage_major.json\n‚îú‚îÄ‚îÄ statuspage_critical.json\n‚îî‚îÄ‚îÄ statuspage_maintenance.json\n```\n\n## Cost Scanner Fixtures\n```\ntests/fixtures/cost/\n‚îú‚îÄ‚îÄ claude_stats_cache.json      # ClaudeStatsCache format\n‚îú‚îÄ‚îÄ codex_event_log.json         # CodexEvent format\n‚îú‚îÄ‚îÄ daily_breakdown.json\n‚îî‚îÄ‚îÄ monthly_totals.json\n```\n\n## Token Account Fixtures\n```\ntests/fixtures/token_accounts/\n‚îú‚îÄ‚îÄ single_account.json\n‚îú‚îÄ‚îÄ multi_account.json\n‚îú‚îÄ‚îÄ empty.json\n‚îî‚îÄ‚îÄ edge_cases.json              # missing fields, invalid indices\n```\n\n## Error Response Fixtures\n```\ntests/fixtures/errors/\n‚îú‚îÄ‚îÄ network_timeout.json\n‚îú‚îÄ‚îÄ http_401.json\n‚îú‚îÄ‚îÄ http_403.json\n‚îú‚îÄ‚îÄ http_500.json\n‚îú‚îÄ‚îÄ malformed_json.txt\n‚îî‚îÄ‚îÄ empty_response.json\n```\n\n## Rust Factory Functions\n```rust\n// tests/common/fixtures.rs\n\n// Provider fixtures\npub fn claude_rate_limit_response(remaining_pct: f64) -\u003e ClaudeRateLimitResponse;\npub fn codex_auth_json(auth_type: AuthType) -\u003e CodexAuthJson;\npub fn jwt_claims(email: \u0026str, plan: \u0026str) -\u003e JwtClaims;\n\n// Usage fixtures  \npub fn usage_snapshot(primary_pct: f64, secondary_pct: Option\u003cf64\u003e) -\u003e UsageSnapshot;\npub fn provider_payload(provider: Provider, usage: UsageSnapshot) -\u003e ProviderPayload;\n\n// Cost fixtures\npub fn cost_payload(today: f64, monthly: f64, tokens: i64) -\u003e CostPayload;\n\n// Status fixtures\npub fn status_payload(indicator: StatusIndicator, desc: \u0026str) -\u003e StatusPayload;\n\n// Token fixtures\npub fn token_accounts(count: usize) -\u003e TokenAccountsFile;\n\n// Utility for loading JSON fixtures\npub fn load_fixture\u003cT: DeserializeOwned\u003e(path: \u0026str) -\u003e T;\n```\n\n## Acceptance Criteria\n- [ ] All Claude provider fixtures created (credentials, CLI output, API response)\n- [ ] All Codex provider fixtures created (auth.json, JWT samples, API response)\n- [ ] Status page fixtures for all indicators\n- [ ] Cost scanner fixtures for both providers\n- [ ] Token account fixtures with edge cases\n- [ ] Error response fixtures\n- [ ] Rust factory functions implemented\n- [ ] Fixture loading utility\n- [ ] README documenting all fixtures","status":"closed","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:12:05.154621492-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:36:21.883827832-05:00","closed_at":"2026-01-18T04:36:21.883827832-05:00","close_reason":"All acceptance criteria verified: Complete fixtures directory with Claude, Codex, status, cost, token_accounts, and error fixtures. Factory functions in tests/common/fixtures.rs with load_fixture/load_fixture_text/load_fixture_json utilities. All 35 fixture tests pass.","dependencies":[{"issue_id":"coding_agent_usage_tracker-32d","depends_on_id":"coding_agent_usage_tracker-u5h","type":"blocks","created_at":"2026-01-18T02:18:15.325667561-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-36t","title":"[EPIC] Graphical TUI Dashboard for Watch Mode","description":"## Overview\n\nTransform the existing watch mode into a rich, real-time terminal dashboard with charts, sparklines, and visual status indicators using **ratatui** (the actively maintained TUI library for Rust).\n\n## Strategic Importance (Why P2)\n\n- **Visual appeal matters**: For adoption and demos\n- **Enhances existing feature**: Watch mode already exists, this makes it great\n- **Proven ecosystem**: ratatui is the standard Rust TUI library\n- **Differentiates**: Most CLI tools have boring output\n\n## User Value Proposition\n\n**Current watch mode**: Basic text refresh, functional but uninspiring.\n\n**Target state**:\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  caut watch                                    Updated: 12:34:56 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ                                                                  ‚îÇ\n‚îÇ  CLAUDE                           CODEX                          ‚îÇ\n‚îÇ  ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ ‚îÇ\n‚îÇ  Primary:  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 78%         Primary:  ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 42%       ‚îÇ\n‚îÇ  Weekly:   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 61%         Credits:  $87.50 remaining     ‚îÇ\n‚îÇ                                                                  ‚îÇ\n‚îÇ  Trend (1h): ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà ‚Üó +23%     Trend (1h): ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ ‚Üí stable  ‚îÇ\n‚îÇ  ETA limit: ~45m ‚ö†Ô∏è               ETA limit: sustainable ‚úì       ‚îÇ\n‚îÇ                                                                  ‚îÇ\n‚îÇ  Cost today: $12.34               Cost today: $3.21              ‚îÇ\n‚îÇ  Cost MTD:   $156.78              Cost MTD:   $45.67             ‚îÇ\n‚îÇ                                                                  ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ  [q] quit  [r] refresh  [p] pause  [1-4] focus provider         ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n## Technical Approach\n\n### Dependencies\n```toml\n[dependencies]\nratatui = \"0.26\"\ncrossterm = \"0.27\"\n```\n\n### Architecture\n```rust\nuse ratatui::{\n    backend::CrosstermBackend,\n    layout::{Constraint, Direction, Layout},\n    widgets::{Block, Borders, Gauge, Sparkline, Paragraph},\n    Terminal,\n};\n\nstruct DashboardApp {\n    providers: Vec\u003cProviderState\u003e,\n    history: HashMap\u003cString, Vec\u003cf64\u003e\u003e,\n    focused_panel: usize,\n    paused: bool,\n}\n\nimpl DashboardApp {\n    fn render(\u0026self, frame: \u0026mut Frame) {\n        let chunks = Layout::default()\n            .direction(Direction::Vertical)\n            .constraints([\n                Constraint::Length(3),  // Header\n                Constraint::Min(0),     // Main content\n                Constraint::Length(3),  // Footer\n            ])\n            .split(frame.size());\n        \n        self.render_header(frame, chunks[0]);\n        self.render_providers(frame, chunks[1]);\n        self.render_footer(frame, chunks[2]);\n    }\n}\n```\n\n### Sparkline Implementation\n```rust\nfn render_sparkline(history: \u0026[f64]) -\u003e Sparkline {\n    let data: Vec\u003cu64\u003e = history.iter()\n        .map(|v| (v * 100.0) as u64)\n        .collect();\n    \n    Sparkline::default()\n        .data(\u0026data)\n        .style(Style::default().fg(Color::Cyan))\n}\n```\n\n### Keyboard Interactions\n- `q` - Quit\n- `r` - Force refresh\n- `p` - Pause/resume updates\n- `1-9` - Focus specific provider\n- `h` - Toggle help panel\n- `j/k` or `‚Üë/‚Üì` - Navigate providers\n\n## Layout Modes\n\n1. **Dashboard** (default): All providers in grid\n2. **Focus**: Single provider detailed view\n3. **Compact**: Minimal, single-line per provider\n\n## Success Criteria\n\n- [ ] Rich visual dashboard renders correctly\n- [ ] Sparklines show recent trend from history\n- [ ] Keyboard navigation works smoothly\n- [ ] Responsive layout adapts to terminal size\n- [ ] Color themes work (and can be disabled with NO_COLOR)\n- [ ] Performance: Smooth updates at 1-second intervals\n- [ ] Accessibility: Works without colors, high contrast mode\n\n## Dependencies\n\n- **REQUIRES**: Historical Usage Tracking (EPIC 1) - for sparklines\n- **Uses**: ratatui, crossterm\n\n## Considerations\n\n- Terminal compatibility: Test across terminals (iTerm2, Windows Terminal, Linux)\n- SSH performance: Don't assume fast connection\n- Color blindness: Ensure info conveyed without color alone\n- Small terminals: Graceful degradation to simpler view (min 60x20)","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:12:32.268132538-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:02:33.019959814-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-36t","depends_on_id":"coding_agent_usage_tracker-smv","type":"blocks","created_at":"2026-01-18T14:21:34.385667007-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-36t","depends_on_id":"coding_agent_usage_tracker-d3a","type":"blocks","created_at":"2026-01-18T15:16:39.118986188-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-36t","depends_on_id":"coding_agent_usage_tracker-109","type":"blocks","created_at":"2026-01-18T15:16:39.165953833-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-36t","depends_on_id":"coding_agent_usage_tracker-oq1","type":"blocks","created_at":"2026-01-18T15:16:39.211963684-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-36t","depends_on_id":"coding_agent_usage_tracker-v7m","type":"blocks","created_at":"2026-01-18T15:16:39.260110559-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-36t","depends_on_id":"coding_agent_usage_tracker-1wb","type":"blocks","created_at":"2026-01-18T15:16:39.305963505-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-37k","title":"Integration tests: Storage layer round-trips","description":"## Overview\nTest storage layer with real filesystem operations.\n\n## Scope\nCache + State + Paths integration\n\n## Test Scenarios\n1. **Cache Lifecycle**\n   - Write to cache\n   - Read back from cache\n   - Verify TTL expiration\n   - Test eviction\n\n2. **State Persistence**\n   - Save state to file\n   - Restart (new instance)\n   - Load state back\n   - Verify data integrity\n\n3. **Path Resolution Chain**\n   - Resolve provider paths\n   - Create directories if needed\n   - Write files\n   - Read back\n\n## Test Infrastructure\n- Use tempdir for isolation\n- Real filesystem operations\n- Logging of all file operations\n\n## Acceptance Criteria\n- [ ] Cache round-trip works\n- [ ] State persists across \"restarts\"\n- [ ] Path resolution creates structure\n- [ ] Cleanup removes temp files","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:15:23.15012504-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:15:23.15012504-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-37k","depends_on_id":"coding_agent_usage_tracker-4eu","type":"blocks","created_at":"2026-01-18T02:18:30.063606577-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-37k","depends_on_id":"coding_agent_usage_tracker-att","type":"blocks","created_at":"2026-01-18T02:18:30.118221537-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-37k","depends_on_id":"coding_agent_usage_tracker-fd9","type":"blocks","created_at":"2026-01-18T02:18:30.173927632-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-3hg","title":"[EPIC] Watch Mode - Continuous Usage Monitoring","description":"## Overview\nImplement a watch mode (`caut usage --watch`) that continuously monitors usage and updates the display at configurable intervals.\n\n## Background \u0026 Rationale\n\n### The Problem\nAI coding agents operate in extended sessions (minutes to hours). Users currently must manually run `caut usage` to check their rate limits. This is:\n- Disruptive to workflow\n- Easy to forget until hitting a rate limit\n- Not proactive about warning of approaching limits\n\n### The Solution\nA watch mode that:\n```bash\ncaut usage --watch                    # Default 30s interval\ncaut usage --watch --interval 60      # Custom interval\ncaut usage --watch --alert-threshold 20  # Alert at 20% remaining\n```\n\nDisplay stays on screen, updates in place, and alerts when approaching limits.\n\n### Use Cases\n1. **Developer Dashboard**: Leave running in a terminal tab while working\n2. **AI Agent Monitor**: Track usage during automated sessions\n3. **Team Visibility**: Show on a shared screen/dashboard\n4. **Proactive Alerts**: Get notified before hitting rate limits\n\n### Why Watch Mode\n- Common pattern in CLI tools (watch, htop, docker stats)\n- Zero additional configuration for users\n- Natural extension of existing usage command\n- Can evolve to include more monitoring features\n\n## Key Features\n1. **In-place updates**: Clear and redraw, no scrolling history\n2. **Configurable interval**: Balance freshness vs API load\n3. **Alert thresholds**: Highlight and/or notify when low\n4. **Graceful degradation**: Continue showing stale data if fetch fails\n5. **Clean exit**: Ctrl+C shows final snapshot and exits cleanly\n\n## Subtasks\n1. Core watch loop and state management\n2. Terminal UI with in-place updates\n3. Alert thresholds and notifications\n4. Graceful error handling in watch mode\n\n## Technical Considerations\n- Use tokio interval for scheduling\n- Need terminal handling for clearing/redrawing\n- Consider SIGWINCH for terminal resize\n- Handle TTY vs non-TTY (non-TTY could output NDJSON)\n- Memory: avoid accumulating state across iterations\n\n## Success Metrics\n- Watch mode runs stably for hours\n- Updates are smooth (no flicker)\n- Alerts are visible and timely\n- Memory usage stays flat over time\n- Clean shutdown on Ctrl+C","status":"open","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:57:50.165194927-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:57:50.165194927-05:00"}
{"id":"coding_agent_usage_tracker-40y","title":"Watch: Core loop and state management","description":"## Overview\nImplement the core watch loop that periodically fetches usage data and manages state across iterations.\n\n## Background \u0026 Rationale\nThe watch loop is the engine of watch mode. It needs to:\n- Fetch data at configurable intervals\n- Track state changes between iterations (for delta display)\n- Handle errors gracefully without crashing\n- Support clean shutdown\n\n## Technical Approach\n\n### 1. Watch State\n```rust\n// In cli/watch.rs or core/watch.rs\npub struct WatchState {\n    pub last_results: Option\u003cVec\u003cProviderPayload\u003e\u003e,\n    pub last_fetch_at: Option\u003cchrono::DateTime\u003cUtc\u003e\u003e,\n    pub fetch_count: u64,\n    pub error_count: u64,\n    pub last_error: Option\u003cCautError\u003e,\n}\n\nimpl WatchState {\n    pub fn new() -\u003e Self {\n        Self {\n            last_results: None,\n            last_fetch_at: None,\n            fetch_count: 0,\n            error_count: 0,\n            last_error: None,\n        }\n    }\n    \n    pub fn update(\u0026mut self, results: Result\u003cVec\u003cProviderPayload\u003e\u003e) {\n        self.fetch_count += 1;\n        match results {\n            Ok(payloads) =\u003e {\n                self.last_results = Some(payloads);\n                self.last_fetch_at = Some(Utc::now());\n                self.last_error = None;\n            }\n            Err(e) =\u003e {\n                self.error_count += 1;\n                self.last_error = Some(e);\n                // Keep last_results for display (stale data better than nothing)\n            }\n        }\n    }\n}\n```\n\n### 2. Watch Loop\n```rust\npub async fn run_watch(\n    args: \u0026UsageArgs,\n    config: \u0026ResolvedConfig,\n    interval: Duration,\n) -\u003e Result\u003c()\u003e {\n    let mut state = WatchState::new();\n    let mut interval_timer = tokio::time::interval(interval);\n    \n    // Set up Ctrl+C handler\n    let (shutdown_tx, mut shutdown_rx) = tokio::sync::oneshot::channel();\n    tokio::spawn(async move {\n        tokio::signal::ctrl_c().await.ok();\n        let _ = shutdown_tx.send(());\n    });\n    \n    loop {\n        tokio::select! {\n            _ = interval_timer.tick() =\u003e {\n                // Fetch and update state\n                let results = fetch_usage(args, config).await;\n                state.update(results);\n                \n                // Render (will be handled by UI subtask)\n                render_watch_frame(\u0026state, config)?;\n            }\n            _ = \u0026mut shutdown_rx =\u003e {\n                // Clean shutdown\n                render_final_snapshot(\u0026state)?;\n                break;\n            }\n        }\n    }\n    \n    Ok(())\n}\n```\n\n### 3. CLI Args Extension\n```rust\n// In cli/args.rs, UsageArgs\n#[derive(Debug, Args)]\npub struct UsageArgs {\n    // ... existing args ...\n    \n    /// Run in watch mode, continuously updating display.\n    #[arg(long, short = w)]\n    pub watch: bool,\n    \n    /// Interval between updates in seconds (default: 30).\n    #[arg(long, default_value = \"30\")]\n    pub interval: u64,\n}\n```\n\n### 4. Integration Point\n```rust\n// In cli/usage.rs\npub async fn execute(args: \u0026UsageArgs, ...) -\u003e Result\u003c()\u003e {\n    if args.watch {\n        let interval = Duration::from_secs(args.interval);\n        run_watch(args, \u0026config, interval).await\n    } else {\n        // Existing one-shot behavior\n        fetch_and_display(args, ...).await\n    }\n}\n```\n\n## Files to Create/Modify\n- `src/cli/watch.rs`: New file for watch mode\n- `src/cli/args.rs`: Add --watch and --interval flags\n- `src/cli/usage.rs`: Dispatch to watch mode\n- `src/cli/mod.rs`: Export watch module\n\n## Dependencies\n- None (foundational for watch mode)\n- Benefits from parallel fetch (h2s) for faster updates\n\n## Acceptance Criteria\n- [ ] Watch loop runs at specified interval\n- [ ] State tracks results across iterations\n- [ ] Errors dont crash loop (graceful handling)\n- [ ] Ctrl+C triggers clean shutdown\n- [ ] Last results preserved when fetch fails\n- [ ] Fetch count and error count tracked\n\n## Testing Strategy\n- Test state updates with success/failure\n- Test interval timing\n- Test shutdown signal handling\n- Test stale data preservation on error","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:58:09.921917939-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T10:37:04.842467015-05:00","closed_at":"2026-01-18T10:37:04.842467015-05:00","close_reason":"Completed"}
{"id":"coding_agent_usage_tracker-453","title":"Doctor: Output formatting and rendering","description":"## Purpose\n\nImplement the visual rendering of doctor command output, creating a clear and scannable display of diagnostic results that works in both color and no-color modes.\n\n## Background\n\nThe doctor output must be:\n1. **Scannable**: Users should immediately see what's working (‚úì) and what needs attention (‚úó)\n2. **Informative**: Show relevant details without overwhelming\n3. **Actionable**: Fix suggestions should be clearly visible\n4. **Accessible**: Work with --no-color flag and screen readers\n\n## Design Reference\n\n```\n$ caut doctor\n\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n‚îÇ caut doctor - System Diagnostic Report                      ‚îÇ\n‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n\nInstallation\n  ‚úì caut v0.1.0 (a999778)\n  ‚úì Config: ~/.config/caut/config.toml\n\nProviders                                              Status\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nClaude\n  ‚úì CLI installed      claude v1.0.30\n  ‚úì Authenticated      user@example.com\n  ‚úì API reachable      142ms\n\nCodex\n  ‚úì CLI installed      codex-cli v0.87.0\n  ‚úì Authenticated      user@example.com (Pro)\n  ‚úì API reachable      89ms\n\nGemini\n  ‚úó CLI not found\n    ‚Üí Install: npm install -g @google/gemini-cli\n\nCursor\n  ‚úì CLI installed      cursor v0.45.2\n  ‚úó Not authenticated\n    ‚Üí Run: cursor auth login\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nSummary: 2 ready, 2 need attention                    [1.2s]\n```\n\n## Implementation Details\n\n### New file: src/render/doctor.rs\n\n```rust\nuse crate::core::doctor::{CheckStatus, DiagnosticCheck, DoctorReport, ProviderHealth};\nuse rich_rust::prelude::*;\n\npub fn render_doctor_report(report: \u0026DoctorReport, no_color: bool) -\u003e String {\n    let mut output = String::new();\n    \n    // Header panel\n    output.push_str(\u0026render_header(report, no_color));\n    \n    // Installation section\n    output.push_str(\u0026render_installation_section(report, no_color));\n    \n    // Providers section\n    for provider_health in \u0026report.providers {\n        output.push_str(\u0026render_provider_health(provider_health, no_color));\n    }\n    \n    // Summary footer\n    output.push_str(\u0026render_summary(report, no_color));\n    \n    output\n}\n\nfn render_check_status(check: \u0026DiagnosticCheck, no_color: bool) -\u003e String {\n    let (icon, color) = match \u0026check.status {\n        CheckStatus::Pass { .. } =\u003e (\"‚úì\", \"green\"),\n        CheckStatus::Fail { .. } =\u003e (\"‚úó\", \"red\"),\n        CheckStatus::Skipped { .. } =\u003e (\"‚óã\", \"yellow\"),\n        CheckStatus::Timeout { .. } =\u003e (\"‚è±\", \"yellow\"),\n    };\n    \n    // Format with optional color\n    if no_color {\n        format!(\"{} {}\", icon, check.name)\n    } else {\n        format!(\"\\x1b[{}m{}\\x1b[0m {}\", color_code(color), icon, check.name)\n    }\n}\n```\n\n## JSON Output\n\nAlso support --json flag for machine-readable output:\n\n```json\n{\n  \"caut_version\": \"0.1.0\",\n  \"providers\": [\n    {\n      \"name\": \"claude\",\n      \"cli_installed\": true,\n      \"cli_version\": \"1.0.30\",\n      \"authenticated\": true,\n      \"api_reachable\": true,\n      \"status\": \"ready\"\n    }\n  ],\n  \"summary\": {\n    \"ready\": 2,\n    \"needs_attention\": 2\n  }\n}\n```\n\n## Testing Strategy\n\n- Snapshot tests for output formatting\n- Test both color and no-color modes\n- Test JSON output structure\n- Test with various failure combinations\n\n## Acceptance Criteria\n\n- [ ] Output is clear and scannable\n- [ ] Icons render correctly (‚úì ‚úó ‚óã ‚è±)\n- [ ] Colors work and can be disabled\n- [ ] Suggestions are indented and clearly marked with ‚Üí\n- [ ] Summary shows accurate counts\n- [ ] JSON output is valid and complete\n- [ ] Works in terminals with limited Unicode support (fallback ASCII)","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:49:07.691120792-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T05:00:00.035329881-05:00","closed_at":"2026-01-18T05:00:00.035329881-05:00","close_reason":"Implemented doctor output rendering in src/render/doctor.rs. Features: Human output with rich formatting (header panel, status icons, color coding, suggestions with arrows), JSON output via serde, Markdown output with tables, ASCII fallback for no-color mode. 13 rendering tests added. All 107 tests pass.","dependencies":[{"issue_id":"coding_agent_usage_tracker-453","depends_on_id":"coding_agent_usage_tracker-4yc","type":"blocks","created_at":"2026-01-18T02:49:14.796385147-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-47q","title":"Session: Implement pricing data storage and updates","description":"## Summary\nMaintain model pricing data for cost calculations with staleness warnings.\n\n## Pricing Table Structure\n```rust\npub struct ModelPricing {\n    pub model_pattern: String,  // Regex pattern (e.g., \"claude-.*-opus\")\n    pub input_per_mtok: f64,    // Cost per million input tokens\n    pub output_per_mtok: f64,   // Cost per million output tokens\n    pub cache_read_per_mtok: Option\u003cf64\u003e,\n    pub cache_write_per_mtok: Option\u003cf64\u003e,\n    pub effective_date: NaiveDate,\n}\n\npub struct PricingTable {\n    pub models: Vec\u003cModelPricing\u003e,\n    pub last_updated: DateTime\u003cUtc\u003e,\n    pub source: String,  // \"builtin\" or \"user-config\"\n}\n```\n\n## Built-in Pricing (as of 2024)\n- Claude Opus 4: $15/$75 per M tokens\n- Claude Sonnet 4: $3/$15 per M tokens\n- GPT-4: $30/$60 per M tokens\n- GPT-4-turbo: $10/$30 per M tokens\n\n## Staleness Warnings\n- \u003e30 days old: INFO level warning\n- \u003e90 days old: WARN level, suggest update\n- User can override with config file\n\n## Custom Pricing Config\n```toml\n# ~/.config/caut/pricing.toml\n[[model]]\npattern = \"claude-opus-4\"\ninput_per_mtok = 15.0\noutput_per_mtok = 75.0\n```\n\n## Acceptance Criteria\n- [ ] Built-in pricing for major models\n- [ ] Pattern matching for model variants\n- [ ] Staleness warnings at appropriate thresholds\n- [ ] User override via config file\n- [ ] Unknown model falls back to conservative estimate","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:01:22.381002103-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:01:22.381002103-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-47q","depends_on_id":"coding_agent_usage_tracker-7zh","type":"blocks","created_at":"2026-01-18T15:03:54.52852388-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-4a2","title":"Implement cost command JSONL scanning","description":"The cost command in src/cli/cost.rs is currently a stub. Need to implement: JSONL file discovery for Claude and Codex logs, JSON parsing, date windowing for 30-day rolling stats, and cache invalidation logic.","status":"closed","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T00:46:59.420046066-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T01:09:16.310680435-05:00","closed_at":"2026-01-18T01:09:16.310680435-05:00","close_reason":"Implemented cost command with JSONL scanning for Claude and Codex. Scans ~/.claude/stats-cache.json and ~/.codex/sessions for activity data."}
{"id":"coding_agent_usage_tracker-4eu","title":"Unit tests for storage/paths.rs (path resolution)","description":"## Overview\nTest the path resolution logic for various providers and platforms.\n\n## Target: src/storage/paths.rs\nCritical for: Config discovery, credentials location, cache paths\n\n## Test Cases\n1. **Provider Config Paths**\n   - Claude Code: ~/.config/claude-code/ or platform equivalent\n   - Cursor: ~/.cursor/ and variants\n   - Codex: OpenAI config locations\n\n2. **Platform Variations**\n   - Linux XDG paths\n   - macOS ~/Library paths  \n   - Windows AppData paths\n   - Honor XDG_CONFIG_HOME override\n\n3. **Edge Cases**\n   - Missing directories\n   - Permission errors (read-only)\n   - Symlink handling\n   - Relative vs absolute paths\n\n## Acceptance Criteria\n- [ ] All provider paths tested\n- [ ] Platform-specific logic verified (use cfg attributes)\n- [ ] XDG compliance tested\n- [ ] Error cases for missing/inaccessible paths","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:12:35.888159341-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:12:35.888159341-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-4eu","depends_on_id":"coding_agent_usage_tracker-u5h","type":"blocks","created_at":"2026-01-18T02:18:17.812577756-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-4n4","title":"Prediction: Add time-to-limit display in usage output","description":"## Task Overview\n\nIntegrate time-to-limit predictions into the standard `caut usage` output, showing users when they'll hit their limit at current pace.\n\n## Parent EPIC\n[EPIC] Time-to-Limit Prediction (coding_agent_usage_tracker-swp)\n\n## Display Design\n\n### Human Output\n```\nClaude: 65% used\n        ‚îú‚îÄ Resets in: 2h 30m\n        ‚îú‚îÄ At current pace: ~1h 45m until limit ‚ö†Ô∏è\n        ‚îî‚îÄ Recommendation: Slow down to avoid hitting limit\n\nCodex: 45% used\n       ‚îú‚îÄ Resets in: 2h 30m\n       ‚îî‚îÄ At current pace: Sustainable ‚úì\n```\n\n### Warning Levels\n\n```rust\nenum PredictionStatus {\n    /// Will hit limit before reset - urgent\n    WillHitLimit { minutes: i32 },\n    /// Close to hitting limit (within 20% of reset time)\n    MayHitLimit { minutes: i32 },\n    /// Sustainable - won't hit limit before reset\n    Sustainable,\n    /// Usage decreasing\n    Decreasing,\n    /// Insufficient data to predict\n    Unknown,\n}\n```\n\n### Visual Indicators\n\n- üî¥ `‚ö†Ô∏è ~45m until limit` - Will definitely hit\n- üü° `~2h until limit` - May hit, close call\n- üü¢ `Sustainable ‚úì` - Safe\n- ‚¨áÔ∏è `‚Üò Decreasing` - Usage going down\n- ‚ùì `Unknown` - Insufficient data\n\n## Implementation\n\n```rust\n// src/render/prediction.rs\n\npub fn render_prediction(\n    usage: \u0026UsageSnapshot,\n    velocity: Option\u003cf64\u003e,\n) -\u003e Vec\u003cString\u003e {\n    let mut lines = vec![];\n    \n    // Get reset time\n    let reset_minutes = usage.primary\n        .as_ref()\n        .and_then(|p| p.resets_at)\n        .map(|t| (t - Utc::now()).num_minutes() as i32)\n        .unwrap_or(0);\n    \n    let current_pct = usage.primary\n        .as_ref()\n        .map(|p| p.used_percent)\n        .unwrap_or(0.0);\n    \n    // Calculate prediction\n    let prediction = match velocity {\n        Some(v) if v \u003c= 0.0 =\u003e PredictionStatus::Decreasing,\n        Some(v) =\u003e {\n            let remaining = 100.0 - current_pct;\n            let minutes_to_limit = (remaining / v * 60.0) as i32;\n            \n            if minutes_to_limit \u003c reset_minutes {\n                if minutes_to_limit \u003c reset_minutes / 5 {\n                    PredictionStatus::WillHitLimit { minutes: minutes_to_limit }\n                } else {\n                    PredictionStatus::MayHitLimit { minutes: minutes_to_limit }\n                }\n            } else {\n                PredictionStatus::Sustainable\n            }\n        }\n        None =\u003e PredictionStatus::Unknown,\n    };\n    \n    // Format output\n    lines.push(format!(\"‚îú‚îÄ Resets in: {}\", format_duration(reset_minutes)));\n    \n    match prediction {\n        PredictionStatus::WillHitLimit { minutes } =\u003e {\n            lines.push(format!(\n                \"‚îú‚îÄ At current pace: ~{} until limit ‚ö†Ô∏è\",\n                format_duration(minutes)\n            ));\n            lines.push(\"‚îî‚îÄ Recommendation: Slow down to avoid hitting limit\".into());\n        }\n        PredictionStatus::MayHitLimit { minutes } =\u003e {\n            lines.push(format!(\n                \"‚îî‚îÄ At current pace: ~{} until limit\",\n                format_duration(minutes)\n            ));\n        }\n        PredictionStatus::Sustainable =\u003e {\n            lines.push(\"‚îî‚îÄ At current pace: Sustainable ‚úì\".into());\n        }\n        PredictionStatus::Decreasing =\u003e {\n            lines.push(\"‚îî‚îÄ Trend: ‚Üò Usage decreasing\".into());\n        }\n        PredictionStatus::Unknown =\u003e {\n            lines.push(\"‚îî‚îÄ Prediction: Insufficient data\".into());\n        }\n    }\n    \n    lines\n}\n\nfn format_duration(minutes: i32) -\u003e String {\n    if minutes \u003c 60 {\n        format!(\"{}m\", minutes)\n    } else if minutes \u003c 1440 {\n        format!(\"{}h {}m\", minutes / 60, minutes % 60)\n    } else {\n        format!(\"{}d {}h\", minutes / 1440, (minutes % 1440) / 60)\n    }\n}\n```\n\n### JSON Output\n\n```json\n{\n  \"provider\": \"claude\",\n  \"primary\": {\n    \"used_percent\": 65.0,\n    \"resets_at\": \"2026-01-18T15:00:00Z\",\n    \"resets_in_minutes\": 150\n  },\n  \"prediction\": {\n    \"velocity_pct_per_hour\": 10.5,\n    \"minutes_to_limit\": 105,\n    \"status\": \"will_hit_limit\",\n    \"sustainable\": false\n  }\n}\n```\n\n## Integration\n\nModify `render/human.rs` and `render/robot.rs` to include prediction data when available.\n\n## Deliverables\n\n- [ ] `PredictionStatus` enum and logic\n- [ ] Human-readable formatting\n- [ ] JSON output schema\n- [ ] Integration with usage renderer\n- [ ] Duration formatting helper\n- [ ] Unit tests for all prediction states\n\n## Acceptance Criteria\n\n- [ ] Prediction shown in `caut usage` output\n- [ ] Visual indicators match warning level\n- [ ] JSON includes prediction data\n- [ ] Graceful handling of missing data\n- [ ] Duration formatting human-friendly","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:09:34.744014613-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:09:34.744014613-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-4n4","depends_on_id":"coding_agent_usage_tracker-smt","type":"blocks","created_at":"2026-01-18T14:21:45.246561344-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-4yc","title":"Doctor: Core diagnostic framework and data structures","description":"## Purpose\n\nCreate the foundational data structures and traits for the doctor command diagnostic system. This establishes the contract that all provider health checks will implement.\n\n## Background\n\nThe doctor command needs a consistent way to:\n1. Represent the health status of any checkable component\n2. Aggregate multiple checks into a report\n3. Associate suggestions with failures\n4. Support both human and machine-readable output\n\n## Implementation Details\n\n### New file: src/core/doctor.rs\n\n```rust\n//! Doctor command diagnostic framework.\n\nuse crate::core::provider::Provider;\nuse std::time::Duration;\n\n/// Result of a single diagnostic check.\n#[derive(Debug, Clone)]\npub enum CheckStatus {\n    /// Check passed with optional details\n    Pass { details: Option\u003cString\u003e },\n    /// Check failed with reason and optional fix suggestion\n    Fail { reason: String, suggestion: Option\u003cString\u003e },\n    /// Check was skipped (e.g., not applicable on this platform)\n    Skipped { reason: String },\n    /// Check timed out\n    Timeout { after: Duration },\n}\n\n/// A single diagnostic check result.\n#[derive(Debug, Clone)]\npub struct DiagnosticCheck {\n    pub name: String,\n    pub status: CheckStatus,\n    pub duration: Option\u003cDuration\u003e,\n}\n\n/// Health status for a single provider.\n#[derive(Debug)]\npub struct ProviderHealth {\n    pub provider: Provider,\n    pub cli_installed: DiagnosticCheck,\n    pub cli_version: Option\u003cString\u003e,\n    pub authenticated: DiagnosticCheck,\n    pub api_reachable: DiagnosticCheck,\n}\n\n/// Complete diagnostic report.\n#[derive(Debug)]\npub struct DoctorReport {\n    pub caut_version: String,\n    pub caut_git_sha: String,\n    pub config_status: DiagnosticCheck,\n    pub providers: Vec\u003cProviderHealth\u003e,\n    pub total_duration: Duration,\n}\n\nimpl DoctorReport {\n    pub fn summary(\u0026self) -\u003e (usize, usize) {\n        // Returns (ready_count, needs_attention_count)\n    }\n}\n```\n\n### Integration point\n\nAdd to src/core/mod.rs:\n```rust\npub mod doctor;\n```\n\n## Testing Strategy\n\n- Unit tests for CheckStatus display formatting\n- Unit tests for DoctorReport summary calculation\n- Test serialization to JSON for machine-readable output\n\n## Acceptance Criteria\n\n- [ ] DiagnosticCheck can represent pass/fail/skip/timeout states\n- [ ] ProviderHealth captures all relevant provider status info\n- [ ] DoctorReport aggregates all checks with timing\n- [ ] All types implement Debug and Clone where appropriate\n- [ ] Types support serde serialization for JSON output","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:48:06.318040056-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:02:19.177863654-05:00","closed_at":"2026-01-18T04:02:19.177863654-05:00","close_reason":"Completed"}
{"id":"coding_agent_usage_tracker-525","title":"History: Implement automatic retention policy and pruning","description":"Add to src/storage/history.rs: RetentionPolicy struct with detailed_retention_days (default 30), aggregate_retention_days (default 365), max_size_bytes (100MB), prune_interval. prune() method: Phase 1 aggregate old detailed data to daily summaries, Phase 2 delete very old aggregates, Phase 3 check size limit, Phase 4 vacuum if significant data removed. maybe_prune() for periodic auto-trigger. CLI command 'caut history prune --dry-run --keep-days N'.","status":"in_progress","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:16:08.136262012-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T21:28:28.581780044-05:00"}
{"id":"coding_agent_usage_tracker-54y","title":"Watch: Alert thresholds and notifications","description":"## Overview\nImplement alert thresholds that highlight or notify users when usage approaches limits.\n\n## Background \u0026 Rationale\nThe key value of watch mode is proactive alerting. Users want to know BEFORE they hit a rate limit, not after. Alert thresholds let users configure when they want to be warned.\n\n## Technical Approach\n\n### 1. Alert Configuration\n```rust\n// CLI args\n#[derive(Debug, Args)]\npub struct UsageArgs {\n    // ... existing ...\n    \n    /// Alert when any providers remaining percent drops below this threshold.\n    #[arg(long, default_value = \"20\")]\n    pub alert_threshold: f64,\n    \n    /// Play terminal bell on alert (BEL character).\n    #[arg(long)]\n    pub alert_bell: bool,\n    \n    /// Run command when alert threshold crossed.\n    #[arg(long)]\n    pub alert_command: Option\u003cString\u003e,\n}\n```\n\n### 2. Alert State Tracking\n```rust\n// In cli/watch.rs\npub struct AlertState {\n    /// Providers that have crossed alert threshold.\n    pub alerted_providers: HashSet\u003cProvider\u003e,\n    /// Last alert time (for rate limiting).\n    pub last_alert_at: Option\u003cchrono::DateTime\u003cUtc\u003e\u003e,\n}\n\nimpl AlertState {\n    pub fn check_alerts(\n        \u0026mut self,\n        results: \u0026[ProviderPayload],\n        threshold: f64,\n    ) -\u003e Vec\u003cAlert\u003e {\n        let mut alerts = Vec::new();\n        \n        for payload in results {\n            let provider = Provider::from_cli_name(\u0026payload.provider).ok();\n            \n            // Check primary window\n            if let Some(primary) = \u0026payload.usage.primary {\n                let remaining = primary.remaining_percent();\n                if remaining \u003c threshold {\n                    if let Some(p) = provider {\n                        if !self.alerted_providers.contains(\u0026p) {\n                            alerts.push(Alert {\n                                provider: p,\n                                window: \"primary\",\n                                remaining_percent: remaining,\n                                reset_description: primary.reset_description.clone(),\n                            });\n                            self.alerted_providers.insert(p);\n                        }\n                    }\n                }\n            }\n            // Similar for secondary, tertiary...\n        }\n        \n        alerts\n    }\n    \n    pub fn clear_recovered(\u0026mut self, results: \u0026[ProviderPayload], threshold: f64) {\n        // Remove providers from alerted set if they have recovered above threshold\n        // This allows re-alerting if they drop below again\n    }\n}\n```\n\n### 3. Alert Display\n```rust\nfn format_alert(alert: \u0026Alert, no_color: bool) -\u003e String {\n    let icon = if no_color { \"!\" } else { \"üö®\" };\n    format!(\n        \"{} {} is at {:.0}% remaining ({})\",\n        icon,\n        alert.provider.display_name(),\n        alert.remaining_percent,\n        alert.reset_description.as_deref().unwrap_or(\"unknown reset\")\n    )\n}\n```\n\n### 4. Terminal Bell\n```rust\nfn play_bell() {\n    print!(\"\\x07\"); // BEL character\n    io::stdout().flush().ok();\n}\n```\n\n### 5. Alert Command Execution\n```rust\nasync fn run_alert_command(command: \u0026str, alert: \u0026Alert) -\u003e Result\u003c()\u003e {\n    // Environment variables for the command\n    let output = tokio::process::Command::new(\"sh\")\n        .arg(\"-c\")\n        .arg(command)\n        .env(\"CAUT_ALERT_PROVIDER\", alert.provider.cli_name())\n        .env(\"CAUT_ALERT_REMAINING\", alert.remaining_percent.to_string())\n        .env(\"CAUT_ALERT_WINDOW\", alert.window)\n        .output()\n        .await?;\n    \n    if !output.status.success() {\n        tracing::warn!(\"Alert command failed: {}\", String::from_utf8_lossy(\u0026output.stderr));\n    }\n    \n    Ok(())\n}\n```\n\n### 6. Alert Rate Limiting\n```rust\nimpl AlertState {\n    /// Minimum time between alerts (avoid spam).\n    const ALERT_COOLDOWN: Duration = Duration::from_secs(60);\n    \n    pub fn should_alert(\u0026self) -\u003e bool {\n        match self.last_alert_at {\n            Some(t) =\u003e Utc::now() - t \u003e chrono::Duration::from_std(Self::ALERT_COOLDOWN).unwrap(),\n            None =\u003e true,\n        }\n    }\n}\n```\n\n## Files to Modify\n- `src/cli/watch.rs`: Add AlertState and alert checking\n- `src/cli/args.rs`: Add alert-related flags\n- `src/render/watch_ui.rs`: Alert display formatting\n\n## Dependencies\n- Requires core watch loop (40y) to be complete\n\n## Acceptance Criteria\n- [ ] --alert-threshold sets the warning level\n- [ ] Alerts shown prominently in watch output\n- [ ] --alert-bell triggers terminal bell\n- [ ] --alert-command runs custom command on alert\n- [ ] Alert cooldown prevents spam\n- [ ] Recovery clears alert state (can re-alert)\n\n## Testing Strategy\n- Test threshold detection at various levels\n- Test bell character output\n- Test custom command with env vars\n- Test cooldown rate limiting\n- Test recovery and re-alert","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:59:04.213374014-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:59:04.213374014-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-54y","depends_on_id":"coding_agent_usage_tracker-40y","type":"blocks","created_at":"2026-01-18T02:59:24.377457876-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-5b7","title":"Create test logging infrastructure with detailed output","description":"## Overview\n**OPTIONAL ENHANCEMENT**: Build comprehensive test logging infrastructure for debugging and CI visibility.\n\n‚ö†Ô∏è **This is a nice-to-have, not a blocker.** Tests can run without this infrastructure using Rust's built-in test output (`--nocapture`). This bead adds structured logging for better debugging of complex test failures.\n\n## Requirements\n- Structured log format with timestamps, test names, and phases\n- Log levels: DEBUG, INFO, WARN, ERROR\n- Output to both console and file (test-results.log)\n- Capture setup/teardown phases separately\n- Include request/response details for HTTP tests\n- Duration tracking per test\n\n## Implementation Details\n- Create `tests/common/logger.rs` module\n- Use `env_logger` or `tracing` crate\n- Support `TEST_LOG_LEVEL` env var\n- JSON output option for CI parsing\n- Color support (respects NO_COLOR)\n\n## Structured Log Format\n```\n[2026-01-18T14:30:22.123Z] [INFO] [test_usage_basic] Test starting\n[2026-01-18T14:30:22.234Z] [DEBUG] [test_usage_basic] Executing command: caut usage\n[2026-01-18T14:30:22.456Z] [DEBUG] [test_usage_basic] Exit code: 0\n[2026-01-18T14:30:22.457Z] [INFO] [test_usage_basic] Test passed (duration: 334ms)\n```\n\n## JSON Log Format (for CI)\n```json\n{\n  \"timestamp\": \"2026-01-18T14:30:22.123Z\",\n  \"level\": \"INFO\",\n  \"test\": \"test_usage_basic\",\n  \"message\": \"Test starting\",\n  \"phase\": \"setup\",\n  \"duration_ms\": null\n}\n```\n\n## Usage in Tests\n```rust\nuse crate::common::logger::{TestLogger, LogLevel};\n\n#[test]\nfn test_example() {\n    let log = TestLogger::new(\"test_example\");\n    log.info(\"Starting test\");\n    \n    // ... test code ...\n    \n    log.debug(\"Intermediate result: {:?}\", result);\n    log.info(\"Test complete\");\n}\n```\n\n## Acceptance Criteria\n- [ ] Logger module with structured output\n- [ ] Console + file output support\n- [ ] Duration tracking per test\n- [ ] CI-friendly JSON mode\n- [ ] Easy opt-in for existing tests\n- [ ] Documentation for usage","status":"closed","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:12:03.406969699-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T10:50:18.249895261-05:00","closed_at":"2026-01-18T10:50:18.249895261-05:00","close_reason":"Implemented test logging infrastructure in tests/common/logger.rs with structured logging, console/file output, JSON mode, duration tracking, and phase tracking. All 9 tests pass.","dependencies":[{"issue_id":"coding_agent_usage_tracker-5b7","depends_on_id":"coding_agent_usage_tracker-u5h","type":"blocks","created_at":"2026-01-18T02:18:15.255606478-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-5gn","title":"Creds: Implement JWT expiration and token health checking","description":"## Summary\nImplement detection of expiring, expired, or invalid JWT tokens and OAuth credentials.\n\n## Background\nLLM provider credentials expire silently. Users often don't know their tokens are invalid until fetches fail. We should proactively warn about:\n1. JWT tokens nearing expiration\n2. OAuth refresh tokens expiring\n3. API keys that have been revoked\n4. Cookies/sessions approaching expiry\n\n## Technical Design\n\n### JWT Expiration Checking\n```rust\nuse jsonwebtoken::{decode, DecodingKey, Validation, Algorithm};\n\npub struct JwtHealthChecker;\n\nimpl JwtHealthChecker {\n    /// Check JWT health without validating signature\n    pub fn check(\u0026self, token: \u0026str) -\u003e JwtHealth {\n        // Decode without verification (we just want claims)\n        let mut validation = Validation::default();\n        validation.insecure_disable_signature_validation();\n        validation.validate_exp = false;\n        \n        match decode::\u003cClaims\u003e(token, \u0026DecodingKey::from_secret(\u0026[]), \u0026validation) {\n            Ok(data) =\u003e {\n                let now = Utc::now().timestamp();\n                let exp = data.claims.exp;\n                let remaining = exp - now;\n                \n                if remaining \u003c 0 {\n                    JwtHealth::Expired { expired_at: exp }\n                } else if remaining \u003c 3600 {\n                    JwtHealth::ExpiringSoon { \n                        expires_in: Duration::seconds(remaining),\n                        expires_at: exp,\n                    }\n                } else if remaining \u003c 86400 {\n                    JwtHealth::ExpiringToday {\n                        expires_in: Duration::seconds(remaining),\n                    }\n                } else {\n                    JwtHealth::Valid {\n                        expires_in: Duration::seconds(remaining),\n                    }\n                }\n            }\n            Err(_) =\u003e JwtHealth::Invalid,\n        }\n    }\n}\n\n#[derive(Debug)]\npub enum JwtHealth {\n    Valid { expires_in: Duration },\n    ExpiringToday { expires_in: Duration },\n    ExpiringSoon { expires_in: Duration, expires_at: i64 },\n    Expired { expired_at: i64 },\n    Invalid,\n}\n```\n\n### OAuth Token Health\n```rust\npub struct OAuthHealthChecker;\n\nimpl OAuthHealthChecker {\n    /// Check OAuth token file health\n    pub fn check(\u0026self, auth_file: \u0026Path) -\u003e OAuthHealth {\n        let auth: OAuthAuth = self.read_auth_file(auth_file)?;\n        \n        // Check access token\n        let access_health = self.check_jwt(\u0026auth.access_token);\n        \n        // Check refresh token (usually longer-lived)\n        let refresh_health = auth.refresh_token\n            .as_ref()\n            .map(|t| self.check_jwt(t));\n        \n        OAuthHealth {\n            access: access_health,\n            refresh: refresh_health,\n            can_refresh: matches!(refresh_health, Some(JwtHealth::Valid { .. })),\n        }\n    }\n}\n```\n\n### Cookie Session Health\n```rust\npub struct CookieHealthChecker;\n\nimpl CookieHealthChecker {\n    /// Check browser cookie session health\n    pub fn check(\u0026self, cookie_file: \u0026Path) -\u003e CookieHealth {\n        let cookies = self.read_cookie_file(cookie_file)?;\n        \n        // Find auth cookies\n        let session_cookie = cookies.iter()\n            .find(|c| c.name == \"sessionKey\" || c.name.contains(\"session\"));\n        \n        match session_cookie {\n            Some(cookie) =\u003e {\n                if cookie.expired() {\n                    CookieHealth::Expired\n                } else if cookie.expires_within(Duration::hours(24)) {\n                    CookieHealth::ExpiringSoon { expires_in: cookie.remaining_time() }\n                } else {\n                    CookieHealth::Valid\n                }\n            }\n            None =\u003e CookieHealth::Missing,\n        }\n    }\n}\n```\n\n## Acceptance Criteria\n- [ ] JWT expiration detection works correctly\n- [ ] Handle JWTs without exp claim gracefully\n- [ ] OAuth access/refresh token health checked\n- [ ] Cookie expiration checked where applicable\n- [ ] Handle malformed tokens gracefully\n- [ ] Unit tests with sample tokens at various expiration states\n\n## Token Sources by Provider\n| Provider | Token Type | Location |\n|----------|------------|----------|\n| Claude | OAuth JWT | ~/.config/caut/claude/auth.json |\n| Claude | Cookies | varies by browser |\n| Codex | OAuth JWT | ~/.codex/auth.json |\n| OpenRouter | API Key | env or config (no expiry) |\n\n## Dependencies\n- None (foundational)\n- Used by auth freshness tracking\n\n## Security Notes\n- Never log token values\n- Don't validate signatures (we don't have the keys)\n- Handle errors without leaking token info\n","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:13:19.763380441-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:13:19.763380441-05:00"}
{"id":"coding_agent_usage_tracker-5rv","title":"[EPIC] Shell Prompt Integration","description":"## Overview\n\nShell Prompt Integration fundamentally changes how users interact with caut. Instead of actively running a command to check usage, they **always see it** - usage awareness becomes ambient. Like git branch in prompt, but for AI usage.\n\n## Strategic Importance (Why P1)\n\n- **Perfect fit** for CLI-first tool philosophy\n- **Proven pattern**: git prompt, kubectl context, virtualenv, etc.\n- **Zero-friction awareness**: Users develop intuition for their patterns\n- **Differentiates** from GUI-focused monitoring tools\n\n## User Value Proposition\n\n**Setup once** in .bashrc/.zshrc:\n```bash\nexport PS1='$(caut prompt) \\w $ '\n```\n\n**Then every prompt shows**:\n```\n[claude:45%|$12.34] ~/project $ \n```\n\nNo more \"let me check my usage\" - it's always there. Users naturally become aware of their consumption patterns without any effort.\n\n## Technical Approach\n\n### Core Command\n```bash\n$ caut prompt\nclaude:45%|$12.34\n\n$ caut prompt --format=minimal\n45%\n\n$ caut prompt --format=full\nclaude:45%/67% codex:$12.34\n```\n\n### Critical Requirement: SPEED\n\nThe prompt command **MUST** be fast (\u003c50ms) or it will make the shell feel sluggish. Implementation:\n\n1. **Aggressive caching**: Read from 30-second cache, never live fetch\n2. **Background refresh**: Separate process updates cache periodically\n3. **Stale is OK**: Better to show 30-second-old data than slow down every command\n\n```rust\nfn prompt_output() -\u003e String {\n    // Read from cache file, never network\n    let cached = read_prompt_cache()?;\n    if cached.is_valid() {\n        return format_prompt(\u0026cached);\n    }\n    // Empty string if no cache - don't block\n    String::new()\n}\n```\n\n### Shell Integration Snippets\n\nProvide ready-to-use snippets for:\n- **Bash**: PS1 modification\n- **Zsh**: PROMPT modification  \n- **Fish**: fish_prompt function\n- Include color support via ANSI codes\n\n```bash\n# caut prompt --install-bash\n_caut_prompt() {\n    local usage=$(caut prompt 2\u003e/dev/null)\n    [ -n \"$usage\" ] \u0026\u0026 echo \"[$usage] \"\n}\nPS1='$(_caut_prompt)\\w $ '\n```\n\n## Configuration Options\n\n- `--provider \u003cname\u003e`: Show specific provider (default: all configured)\n- `--format \u003ccompact|full|minimal\u003e`: Output format\n- `--color / --no-color`: ANSI color codes\n- `--cache-max-age \u003cseconds\u003e`: Staleness tolerance (default: 30)\n\n## Success Criteria\n\n- [ ] `caut prompt` returns in \u003c50ms (cache read only)\n- [ ] Background cache refresh mechanism works reliably\n- [ ] Shell snippets provided for bash, zsh, fish\n- [ ] Format options cover common use cases\n- [ ] Graceful degradation: empty output if no data (not error)\n- [ ] Documentation with installation instructions\n\n## Dependencies\n\n- Can be built independently of other features\n- Benefits from history for trend indicators (optional enhancement)\n- Requires basic usage fetching to populate cache\n\n## Considerations\n\n- Some users may not want usage in prompt - make optional/configurable\n- Color codes may not work in all terminals - detect and degrade\n- Multiple shell sessions share cache - concurrent access safe\n- Consider starship/oh-my-zsh plugin for broader adoption","status":"open","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:11:13.185349997-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:11:13.185349997-05:00"}
{"id":"coding_agent_usage_tracker-61s","title":"Implement robot mode Markdown rendering","description":"The render/robot.rs module has JSON output working but Markdown rendering (render_usage_md) is not implemented. Needed for --format md output.","status":"closed","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T00:47:02.612276393-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T01:27:29.432167197-05:00","closed_at":"2026-01-18T01:27:29.432167197-05:00","close_reason":"Markdown rendering already implemented and tested (render_usage_md and render_cost_md both complete, 19 tests pass)"}
{"id":"coding_agent_usage_tracker-64u","title":"Integration tests: HTTP client with mock server","description":"## Overview\nTest HTTP operations against a local mock server.\n\n## Scope\nHTTP client ‚Üí Mock endpoints ‚Üí Response parsing\n\n## Test Scenarios\n1. **Success Responses**\n   - 200 OK with valid JSON\n   - Provider-specific response formats\n   - Rate limit headers\n\n2. **Error Responses**\n   - 401 Unauthorized\n   - 403 Forbidden\n   - 429 Rate Limited\n   - 500 Server Error\n\n3. **Network Conditions**\n   - Timeout handling\n   - Connection refused\n   - Slow responses\n\n4. **Retry Logic**\n   - Retry on transient errors\n   - No retry on auth errors\n   - Backoff timing\n\n## Test Infrastructure\n- Use wiremock-rs or similar\n- Record/replay option for CI\n- Detailed request/response logging\n\n## Acceptance Criteria\n- [ ] All HTTP status codes handled\n- [ ] Retry logic verified\n- [ ] Timeout behavior tested\n- [ ] Headers correctly parsed","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:15:24.368914203-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T11:03:05.757810834-05:00","closed_at":"2026-01-18T11:03:05.757810834-05:00","close_reason":"20 HTTP integration tests passing with wiremock: success responses, error codes (401/403/429/500/502/503), timeout handling, connection refused, user-agent, provider response formats (Claude, OpenAI, StatusPage)","dependencies":[{"issue_id":"coding_agent_usage_tracker-64u","depends_on_id":"coding_agent_usage_tracker-8gp","type":"blocks","created_at":"2026-01-18T02:18:31.294959544-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-64u","depends_on_id":"coding_agent_usage_tracker-2k1","type":"blocks","created_at":"2026-01-18T02:18:31.362731556-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-67u","title":"Status: Add multi-provider status command","description":"Create 'caut status' command in src/cli/status.rs. Show all providers by default or filter with 'caut status claude'. Support --refresh to bypass cache, --quiet for exit code only. Exit codes: 0=ok, 1=minor, 2=major, 3=unknown. Render human-friendly table with indicators. JSON output includes all status fields.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:15:05.356383698-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:15:05.356383698-05:00"}
{"id":"coding_agent_usage_tracker-6bq","title":"Unit tests for CLI command execution (main.rs/cli.rs)","description":"## Overview\nTest CLI entry points and command dispatch.\n\n## Target: src/main.rs, src/cli.rs (or equivalent)\nCritical for: User-facing command correctness\n\n## Test Cases\n1. **Usage Command**\n   - Default behavior (all providers)\n   - Provider filtering\n   - Output format flags\n   - No-color mode\n\n2. **Cost Command**\n   - Default behavior\n   - Date range filtering (if supported)\n   - Provider filtering\n\n3. **Common Flags**\n   - --help output\n   - --version output\n   - --verbose logging\n   - --json vs human output\n\n4. **Error Handling**\n   - Invalid subcommand\n   - Missing required args\n   - Exit codes (0 success, 1 error)\n\n## Implementation Notes\n- Use assert_cmd crate for CLI testing\n- Capture stdout/stderr\n- Test exit codes\n\n## Acceptance Criteria\n- [ ] All commands tested\n- [ ] All flags tested\n- [ ] Exit codes verified\n- [ ] Help text present","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:14:59.361232352-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:14:59.361232352-05:00"}
{"id":"coding_agent_usage_tracker-6dy","title":"History: Comprehensive test suite with E2E scripts","description":"## Summary\nImplement comprehensive test suite for the Historical Usage Tracking system covering all components, edge cases, and performance requirements.\n\n## Parent EPIC\n[EPIC] Historical Usage Tracking with Trend Visualization (coding_agent_usage_tracker-smv)\n\n## Test Categories\n\n### 1. Unit Tests: Schema and Migrations\n```rust\n#[cfg(test)]\nmod schema_tests {\n    use super::*;\n    use tempfile::TempDir;\n    \n    #[test]\n    fn test_fresh_database_creation() {\n        let tmp = TempDir::new().unwrap();\n        let db_path = tmp.path().join(\"test.db\");\n        \n        let store = HistoryStore::open(\u0026db_path).unwrap();\n        \n        // Verify tables exist\n        assert!(store.table_exists(\"usage_snapshots\"));\n        assert!(store.table_exists(\"schema_migrations\"));\n    }\n    \n    #[test]\n    fn test_migration_idempotence() {\n        let tmp = TempDir::new().unwrap();\n        let db_path = tmp.path().join(\"test.db\");\n        \n        // Run migrations multiple times\n        for _ in 0..3 {\n            let store = HistoryStore::open(\u0026db_path).unwrap();\n            assert!(store.is_healthy());\n        }\n    }\n    \n    #[test]\n    fn test_migration_from_v1_to_latest() {\n        // Create v1 database manually\n        // Open with current code\n        // Verify data preserved and schema updated\n    }\n}\n```\n\n### 2. Unit Tests: Storage Layer\n```rust\n#[cfg(test)]\nmod storage_tests {\n    use super::*;\n    use common::fixtures::*;\n    \n    fn setup() -\u003e (TempDir, HistoryStore) {\n        let tmp = TempDir::new().unwrap();\n        let store = HistoryStore::open(tmp.path().join(\"test.db\")).unwrap();\n        (tmp, store)\n    }\n    \n    #[test]\n    fn test_record_and_retrieve_snapshot() {\n        let (_tmp, store) = setup();\n        let snapshot = usage_snapshot(45.0, Some(30.0));\n        \n        let id = store.record_snapshot(\u0026snapshot, \"claude\").unwrap();\n        assert!(id \u003e 0);\n        \n        let retrieved = store.get_latest(\"claude\").unwrap().unwrap();\n        assert!((retrieved.primary_used_pct.unwrap() - 45.0).abs() \u003c f64::EPSILON);\n    }\n    \n    #[test]\n    fn test_time_range_queries() {\n        let (_tmp, store) = setup();\n        \n        // Insert snapshots at different times\n        for i in 0..10 {\n            let mut snapshot = usage_snapshot(i as f64 * 10.0, None);\n            snapshot.updated_at = Utc::now() - Duration::hours(i as i64);\n            store.record_snapshot(\u0026snapshot, \"claude\").unwrap();\n        }\n        \n        // Query last 5 hours\n        let results = store.get_snapshots(\n            \"claude\",\n            Utc::now() - Duration::hours(5),\n            Utc::now(),\n        ).unwrap();\n        \n        assert_eq!(results.len(), 5);\n    }\n    \n    #[test]\n    fn test_multiple_providers() {\n        let (_tmp, store) = setup();\n        \n        store.record_snapshot(\u0026usage_snapshot(30.0, None), \"claude\").unwrap();\n        store.record_snapshot(\u0026usage_snapshot(50.0, None), \"codex\").unwrap();\n        \n        let all = store.get_latest_all().unwrap();\n        assert_eq!(all.len(), 2);\n        assert!(all.contains_key(\"claude\"));\n        assert!(all.contains_key(\"codex\"));\n    }\n    \n    #[test]\n    fn test_data_retention_cleanup() {\n        let (_tmp, store) = setup();\n        \n        // Insert old and new snapshots\n        // ... (insert with backdated timestamps)\n        \n        let deleted = store.cleanup(7).unwrap(); // 7 day retention\n        assert!(deleted \u003e 0);\n        \n        // Verify old data removed, new data preserved\n    }\n    \n    #[test]\n    fn test_concurrent_writes() {\n        let tmp = TempDir::new().unwrap();\n        let db_path = tmp.path().join(\"test.db\");\n        \n        let handles: Vec\u003c_\u003e = (0..10).map(|i| {\n            let path = db_path.clone();\n            std::thread::spawn(move || {\n                let store = HistoryStore::open(\u0026path).unwrap();\n                store.record_snapshot(\u0026usage_snapshot(i as f64 * 10.0, None), \"claude\").unwrap();\n            })\n        }).collect();\n        \n        for h in handles {\n            h.join().unwrap();\n        }\n        \n        let store = HistoryStore::open(\u0026db_path).unwrap();\n        let all = store.get_snapshots(\"claude\", Utc::now() - Duration::hours(1), Utc::now()).unwrap();\n        assert_eq!(all.len(), 10);\n    }\n}\n```\n\n### 3. Unit Tests: Snapshot Capture Pipeline\n```rust\n#[cfg(test)]\nmod capture_tests {\n    #[test]\n    fn test_snapshot_captured_after_fetch() {\n        let logs = TestLogCapture::new();\n        let _guard = logs.init();\n        \n        let store = MockHistoryStore::new();\n        let fetcher = MockFetcher::returning(provider_payload_default(\"claude\", \"oauth\"));\n        \n        let pipeline = FetchPipeline::new(fetcher, store.clone());\n        pipeline.fetch_and_record(\"claude\").unwrap();\n        \n        assert_eq!(store.recorded_count(), 1);\n        logs.assert_logged(\"Snapshot recorded\");\n    }\n    \n    #[test]\n    fn test_fetch_failure_not_recorded() {\n        let store = MockHistoryStore::new();\n        let fetcher = MockFetcher::failing();\n        \n        let pipeline = FetchPipeline::new(fetcher, store.clone());\n        let result = pipeline.fetch_and_record(\"claude\");\n        \n        assert!(result.is_err());\n        assert_eq!(store.recorded_count(), 0);\n    }\n}\n```\n\n### 4. Unit Tests: History CLI\n```rust\n#[cfg(test)]\nmod cli_tests {\n    #[test]\n    fn test_history_command_output_format() {\n        // Setup test database with known data\n        // Run history command\n        // Verify output format\n    }\n    \n    #[test]\n    fn test_history_with_time_range() {\n        // --since and --until flags\n    }\n    \n    #[test]\n    fn test_history_json_output() {\n        // --format json\n    }\n    \n    #[test]\n    fn test_history_empty_database() {\n        // Graceful handling when no data\n    }\n}\n```\n\n### 5. Integration Tests\n```rust\n// tests/history_integration.rs\n\n#[test]\nfn test_full_history_workflow() {\n    // 1. Fresh database\n    // 2. Run fetch (mocked provider)\n    // 3. Verify snapshot recorded\n    // 4. Run history command\n    // 5. Verify output shows recent data\n    // 6. Run with --since filter\n    // 7. Verify filtering works\n}\n\n#[test]\nfn test_history_across_restarts() {\n    // 1. Create database, record snapshots\n    // 2. Close store\n    // 3. Reopen store\n    // 4. Verify data persisted\n}\n```\n\n### 6. E2E Tests\n```bash\n#!/bin/bash\n# tests/e2e/history_e2e.sh\n\nset -euo pipefail\nsource \"$(dirname \"$0\")/helpers.sh\"\n\nlog_section \"History E2E Tests\"\n\n# Setup\nTEMP_DIR=$(mktemp -d)\nexport CAUT_DATA_DIR=\"$TEMP_DIR\"\ntrap \"rm -rf $TEMP_DIR\" EXIT\n\n# Test 1: Fresh database\nlog_test \"Fresh database initializes correctly\"\ncaut history --format json 2\u003e\u00261 | jq -e '.snapshots == []'\nlog_pass\n\n# Test 2: Snapshot recording (mock mode)\nlog_test \"Fetch records snapshot\"\ncaut fetch --mock --provider claude\ncaut history --provider claude --format json | jq -e '.snapshots | length \u003e 0'\nlog_pass\n\n# Test 3: Multiple fetches accumulate\nlog_test \"Multiple fetches create history\"\nfor i in {1..5}; do\n    sleep 1\n    caut fetch --mock --provider claude\ndone\nCOUNT=$(caut history --provider claude --format json | jq '.snapshots | length')\n[[ $COUNT -ge 5 ]] || fail \"Expected at least 5 snapshots, got $COUNT\"\nlog_pass\n\n# Test 4: Time filtering\nlog_test \"Time range filtering works\"\ncaut history --since \"1 hour ago\" --format json | jq -e '.snapshots | length \u003e 0'\nlog_pass\n\n# Test 5: Export functionality\nlog_test \"CSV export works\"\ncaut history export --format csv --output \"$TEMP_DIR/export.csv\"\n[[ -f \"$TEMP_DIR/export.csv\" ]] || fail \"CSV file not created\"\nhead -1 \"$TEMP_DIR/export.csv\" | grep -q \"provider,fetched_at\" || fail \"Invalid CSV header\"\nlog_pass\n\nlog_summary\n```\n\n### 7. Performance Tests\n```rust\n#[test]\nfn bench_snapshot_insert() {\n    let (_tmp, store) = setup();\n    let snapshot = usage_snapshot(50.0, Some(30.0));\n    \n    let start = Instant::now();\n    for _ in 0..1000 {\n        store.record_snapshot(\u0026snapshot, \"claude\").unwrap();\n    }\n    let elapsed = start.elapsed();\n    \n    // Should complete 1000 inserts in \u003c1s\n    assert!(elapsed \u003c Duration::from_secs(1), \"Too slow: {:?}\", elapsed);\n    \n    // Log performance\n    println!(\"1000 inserts: {:?} ({:?}/insert)\", elapsed, elapsed / 1000);\n}\n\n#[test]\nfn bench_time_range_query() {\n    let (_tmp, store) = setup();\n    \n    // Insert 10000 snapshots\n    for i in 0..10000 {\n        let mut snapshot = usage_snapshot((i % 100) as f64, None);\n        store.record_snapshot(\u0026snapshot, \"claude\").unwrap();\n    }\n    \n    let start = Instant::now();\n    let results = store.get_snapshots(\n        \"claude\",\n        Utc::now() - Duration::days(30),\n        Utc::now(),\n    ).unwrap();\n    let elapsed = start.elapsed();\n    \n    // Query should be \u003c100ms even with 10k rows\n    assert!(elapsed \u003c Duration::from_millis(100), \"Query too slow: {:?}\", elapsed);\n    println!(\"Query 10k rows: {:?}\", elapsed);\n}\n```\n\n## Logging Verification\nAll tests should verify appropriate logging:\n```rust\n#[test]\nfn test_logging_on_snapshot_record() {\n    let logs = TestLogCapture::new();\n    let _guard = logs.init();\n    \n    let (_tmp, store) = setup();\n    store.record_snapshot(\u0026usage_snapshot(50.0, None), \"claude\").unwrap();\n    \n    logs.assert_logged(\"Recording usage snapshot\");\n    logs.assert_logged(\"Snapshot recorded successfully\");\n    logs.assert_no_errors();\n}\n```\n\n## Acceptance Criteria\n- [ ] \u003e90% code coverage for history module\n- [ ] All unit tests pass\n- [ ] Integration tests pass\n- [ ] E2E script passes\n- [ ] Performance benchmarks meet targets\n- [ ] Logging verified in tests\n- [ ] Edge cases documented and tested\n\n## Dependencies\n- Requires logging infrastructure (coding_agent_usage_tracker-zev)\n- Depends on all history implementation tasks\n","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:47:47.276145692-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:47:47.276145692-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-6dy","depends_on_id":"coding_agent_usage_tracker-zev","type":"blocks","created_at":"2026-01-18T14:56:56.896002894-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-6dy","depends_on_id":"coding_agent_usage_tracker-smv","type":"blocks","created_at":"2026-01-18T14:56:56.943393489-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-6ih","title":"History: Add ASCII trend visualization with sparklines","description":"## Task Overview\n\nImplement ASCII-based trend visualization including bar charts, sparklines, and trend indicators for the history display.\n\n## Parent EPIC\n[EPIC] Historical Usage Tracking with Trend Visualization (coding_agent_usage_tracker-smv)\n\n## Visualization Components\n\n### Bar Charts (Daily Summary)\n```\nMon: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 78%\nTue: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 62%\nWed: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 91%\nThu: ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 41%\n```\n\n### Sparklines (Compact Trend)\n```\nTrend (24h): ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ ‚Üó +12%\n```\n\n### Trend Indicators\n```\n‚Üó +15%   (increasing)\n‚Üí ~0%    (stable)\n‚Üò -12%   (decreasing)\n‚ö†Ô∏è spike  (unusual activity)\n```\n\n## Implementation\n\n### Bar Chart Renderer\n\n```rust\nconst BAR_CHARS: \u0026[char] = \u0026['‚ñë', '‚ñí', '‚ñì', '‚ñà'];\nconst EMPTY_CHAR: char = '‚ñë';\nconst FULL_CHAR: char = '‚ñà';\n\nfn render_bar(percent: f64, width: usize) -\u003e String {\n    let filled = ((percent / 100.0) * width as f64).round() as usize;\n    let empty = width - filled;\n    \n    format!(\n        \"{}{}\",\n        FULL_CHAR.to_string().repeat(filled),\n        EMPTY_CHAR.to_string().repeat(empty)\n    )\n}\n\nfn render_bar_colored(percent: f64, width: usize) -\u003e String {\n    let bar = render_bar(percent, width);\n    let color = match percent {\n        p if p \u003e= 90.0 =\u003e Color::Red,\n        p if p \u003e= 70.0 =\u003e Color::Yellow,\n        _ =\u003e Color::Green,\n    };\n    colorize(\u0026bar, color)\n}\n```\n\n### Sparkline Renderer\n\n```rust\nconst SPARKLINE_CHARS: \u0026[char] = \u0026[\n    '‚ñÅ', '‚ñÇ', '‚ñÉ', '‚ñÑ', '‚ñÖ', '‚ñÜ', '‚ñá', '‚ñà'\n];\n\nfn render_sparkline(values: \u0026[f64]) -\u003e String {\n    if values.is_empty() {\n        return String::new();\n    }\n    \n    let min = values.iter().cloned().fold(f64::INFINITY, f64::min);\n    let max = values.iter().cloned().fold(f64::NEG_INFINITY, f64::max);\n    let range = max - min;\n    \n    values.iter()\n        .map(|\u0026v| {\n            let normalized = if range \u003e 0.0 { \n                (v - min) / range \n            } else { \n                0.5 \n            };\n            let idx = (normalized * 7.0).round() as usize;\n            SPARKLINE_CHARS[idx.min(7)]\n        })\n        .collect()\n}\n```\n\n### Trend Indicator\n\n```rust\nfn render_trend(current_avg: f64, previous_avg: f64) -\u003e String {\n    let change_pct = ((current_avg - previous_avg) / previous_avg) * 100.0;\n    \n    let (arrow, color) = match change_pct {\n        c if c \u003e 10.0 =\u003e ('‚Üó', Color::Red),      // Bad: usage increasing\n        c if c \u003e 2.0 =\u003e ('‚Üó', Color::Yellow),\n        c if c \u003c -10.0 =\u003e ('‚Üò', Color::Green),   // Good: usage decreasing\n        c if c \u003c -2.0 =\u003e ('‚Üò', Color::Green),\n        _ =\u003e ('‚Üí', Color::White),                // Stable\n    };\n    \n    format!(\"{} {:+.1}%\", colorize(\u0026arrow.to_string(), color), change_pct)\n}\n```\n\n### Integrated Display\n\n```rust\nfn render_history_chart(snapshots: \u0026[DailyAggregate], config: \u0026DisplayConfig) {\n    let terminal_width = term_size::dimensions().map(|(w, _)| w).unwrap_or(80);\n    let bar_width = (terminal_width - 30).min(40);  // Leave room for labels\n    \n    println!(\"{} Usage (Last {} Days)\", provider, snapshots.len());\n    println!(\"{}\", \"‚îÅ\".repeat(terminal_width.min(60)));\n    \n    for day in snapshots {\n        let bar = render_bar_colored(day.avg_primary_pct, bar_width);\n        let cost = day.total_cost.map(|c| format!(\"${:.2}\", c)).unwrap_or_default();\n        let marker = if day.hit_limit { \" ‚Üê Hit limit\" } else { \"\" };\n        \n        println!(\n            \"{}: {} {:\u003e5.1}%  {}{}\",\n            day.date.format(\"%a %m/%d\"),\n            bar,\n            day.avg_primary_pct,\n            cost,\n            marker\n        );\n    }\n    \n    println!();\n    \n    // Summary line with sparkline\n    let values: Vec\u003cf64\u003e = snapshots.iter().map(|d| d.avg_primary_pct).collect();\n    let sparkline = render_sparkline(\u0026values);\n    let trend = render_trend(current_period_avg, previous_period_avg);\n    \n    println!(\"Trend: {}  {}\", sparkline, trend);\n}\n```\n\n## Terminal Compatibility\n\n- Detect terminal capabilities (unicode support)\n- Fallback to ASCII-only if needed\n- Respect NO_COLOR environment variable\n- Handle narrow terminals gracefully\n\n## Deliverables\n\n- [ ] Bar chart renderer with color support\n- [ ] Sparkline renderer\n- [ ] Trend indicator with directional arrows\n- [ ] Terminal width detection and adaptation\n- [ ] Color-blind friendly mode (optional)\n- [ ] ASCII fallback for limited terminals\n- [ ] Unit tests for all renderers\n\n## Acceptance Criteria\n\n- [ ] Bar charts render correctly for all percentages\n- [ ] Sparklines accurately represent trends\n- [ ] Colors convey meaning (red=high, green=low)\n- [ ] Works in narrow terminals (min 60 cols)\n- [ ] NO_COLOR respected\n- [ ] Unicode and ASCII modes both work","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:08:16.259889155-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:08:16.259889155-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-6ih","depends_on_id":"coding_agent_usage_tracker-a90","type":"blocks","created_at":"2026-01-18T14:21:40.658077338-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-6nx","title":"Budget: Implement timezone-aware reset scheduling","description":"## Summary\nHandle budget period boundaries correctly with configurable timezone.\n\n## The Problem\nWhen does \"daily\" reset? Midnight in what timezone?\n\n## Configuration\n```toml\n# ~/.config/caut/budgets.toml\n[settings]\ntimezone = \"America/New_York\"  # Default: local system timezone\nweek_starts_on = \"monday\"      # monday or sunday\n\n[claude]\nmonthly_limit = 75.00\n# Month resets on 1st at midnight in configured timezone\n```\n\n## Implementation\n```rust\npub struct BudgetPeriod {\n    pub period_type: PeriodType,  // Daily, Weekly, Monthly\n    pub timezone: Tz,\n    pub week_start: Weekday,\n}\n\nimpl BudgetPeriod {\n    pub fn current_period_start(\u0026self) -\u003e DateTime\u003cTz\u003e {\n        let now = Utc::now().with_timezone(\u0026self.timezone);\n        match self.period_type {\n            PeriodType::Daily =\u003e now.date().and_hms(0, 0, 0),\n            PeriodType::Weekly =\u003e {\n                let days_since_start = (now.weekday().num_days_from_monday() \n                    - self.week_start.num_days_from_monday() + 7) % 7;\n                (now - Duration::days(days_since_start as i64)).date().and_hms(0, 0, 0)\n            }\n            PeriodType::Monthly =\u003e {\n                now.date().with_day(1).unwrap().and_hms(0, 0, 0)\n            }\n        }\n    }\n    \n    pub fn next_reset(\u0026self) -\u003e DateTime\u003cTz\u003e {\n        // Calculate next period boundary\n    }\n}\n```\n\n## Display\n```\nBudget: $45 of $75 (60%)\nResets: Feb 1 at midnight EST (in 13 days)\n```\n\n## Acceptance Criteria\n- [ ] Timezone configuration works\n- [ ] Daily/weekly/monthly boundaries correct\n- [ ] Week start day configurable\n- [ ] Reset time displayed in user's timezone\n- [ ] Default to system timezone if not configured","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:02:00.264604546-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:02:00.264604546-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-6nx","depends_on_id":"coding_agent_usage_tracker-jkf","type":"blocks","created_at":"2026-01-18T15:03:57.161127307-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-717","title":"Status: Implement Google Cloud status adapter","description":"## Summary\nGoogle Cloud uses a different status page format than Atlassian Statuspage. Implement adapter.\n\n## Google Status API\nURL: https://status.cloud.google.com/incidents.json\n\nResponse format differs from Statuspage:\n```json\n{\n  \"incidents\": [\n    {\n      \"id\": \"abc123\",\n      \"title\": \"Vertex AI API latency\",\n      \"severity\": \"medium\",\n      \"status\": \"resolved\",\n      \"created\": \"2026-01-15T10:00:00Z\",\n      \"modified\": \"2026-01-15T12:00:00Z\",\n      \"service_key\": \"vertex-ai\",\n      \"updates\": [...]\n    }\n  ]\n}\n```\n\n## Adapter Interface\n```rust\npub trait StatusAdapter {\n    fn parse(\u0026self, response: \u0026str) -\u003e Result\u003cProviderStatus\u003e;\n}\n\npub struct GoogleStatusAdapter;\n\nimpl StatusAdapter for GoogleStatusAdapter {\n    fn parse(\u0026self, response: \u0026str) -\u003e Result\u003cProviderStatus\u003e {\n        let google: GoogleIncidents = serde_json::from_str(response)?;\n        \n        // Filter to relevant services (Vertex AI)\n        let relevant = google.incidents.iter()\n            .filter(|i| i.service_key == \"vertex-ai\")\n            .filter(|i| i.status != \"resolved\");\n        \n        // Map severity to StatusIndicator\n        let indicator = match relevant.map(|i| \u0026i.severity).max() {\n            Some(\"high\") =\u003e StatusIndicator::Major,\n            Some(\"medium\") =\u003e StatusIndicator::Minor,\n            _ =\u003e StatusIndicator::None,\n        };\n        \n        Ok(ProviderStatus { indicator, ... })\n    }\n}\n```\n\n## Acceptance Criteria\n- [ ] Parses Google status format correctly\n- [ ] Maps severity levels appropriately\n- [ ] Filters to relevant services (Vertex AI, Gemini)\n- [ ] Handles empty/no incidents case\n- [ ] Falls back gracefully on parse errors","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:02:01.445960554-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:02:01.445960554-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-717","depends_on_id":"coding_agent_usage_tracker-kod","type":"blocks","created_at":"2026-01-18T15:03:57.968370557-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-7ng","title":"API: Create REST endpoints for usage data","description":"Create src/api/handlers.rs. /health returns version, status, uptime_secs. /usage returns all providers with caching (refresh param to bypass). /usage/:provider filters single provider. /history accepts days and resolution params. /history/:provider filters by provider. /budgets returns budget status and alerts. Proper HTTP status codes. All responses include fetched_at and from_cache.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:15:45.320762913-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:15:45.320762913-05:00"}
{"id":"coding_agent_usage_tracker-7qd","title":"Status: Add parallel status fetching alongside usage","description":"## Summary\nImplement parallel fetching of status data alongside usage data without blocking.\n\n## Background\nStatus fetches should not slow down usage fetches. We need:\n1. Parallel execution of status and usage fetches\n2. Independent timeouts (status can fail without affecting usage)\n3. Aggregation of results\n4. Caching to reduce API calls\n\n## Technical Design\n\n### Parallel Fetch Coordinator\n```rust\npub struct ParallelFetcher {\n    usage_fetchers: HashMap\u003cString, Box\u003cdyn UsageFetcher\u003e\u003e,\n    status_registry: StatusRegistry,\n    cache: StatusCache,\n}\n\nimpl ParallelFetcher {\n    /// Fetch usage and status in parallel\n    pub async fn fetch_all(\u0026self, providers: \u0026[String]) -\u003e Vec\u003cFetchResult\u003e {\n        let usage_futures: Vec\u003c_\u003e = providers\n            .iter()\n            .filter_map(|p| self.usage_fetchers.get(p))\n            .map(|f| f.fetch())\n            .collect();\n        \n        let status_futures: Vec\u003c_\u003e = providers\n            .iter()\n            .filter_map(|p| self.status_registry.get(p))\n            .map(|c| self.fetch_status_with_timeout(c))\n            .collect();\n        \n        // Execute in parallel\n        let (usage_results, status_results) = tokio::join!(\n            futures::future::join_all(usage_futures),\n            futures::future::join_all(status_futures),\n        );\n        \n        // Merge results\n        self.merge_results(providers, usage_results, status_results)\n    }\n    \n    async fn fetch_status_with_timeout(\n        \u0026self,\n        client: \u0026dyn StatusPageClient,\n    ) -\u003e Result\u003cStatusPayload\u003e {\n        // Check cache first\n        if let Some(cached) = self.cache.get(client.provider()) {\n            if !cached.is_stale() {\n                return Ok(cached.status.clone());\n            }\n        }\n        \n        // Fetch with aggressive timeout\n        let result = tokio::time::timeout(\n            Duration::from_secs(3),\n            client.fetch_status(),\n        ).await;\n        \n        match result {\n            Ok(Ok(status)) =\u003e {\n                self.cache.set(client.provider(), \u0026status);\n                Ok(status)\n            }\n            Ok(Err(e)) =\u003e {\n                warn!(\"Status fetch failed for {}: {}\", client.provider(), e);\n                Ok(StatusPayload::unknown())\n            }\n            Err(_) =\u003e {\n                warn!(\"Status fetch timed out for {}\", client.provider());\n                Ok(StatusPayload::unknown())\n            }\n        }\n    }\n}\n```\n\n### Status Cache\n```rust\npub struct StatusCache {\n    entries: RwLock\u003cHashMap\u003cString, CachedStatus\u003e\u003e,\n    ttl: Duration,\n}\n\nstruct CachedStatus {\n    status: StatusPayload,\n    fetched_at: Instant,\n}\n\nimpl StatusCache {\n    pub fn new(ttl: Duration) -\u003e Self {\n        Self {\n            entries: RwLock::new(HashMap::new()),\n            ttl,\n        }\n    }\n    \n    pub fn get(\u0026self, provider: \u0026str) -\u003e Option\u003cCachedStatus\u003e {\n        let entries = self.entries.read().unwrap();\n        entries.get(provider).cloned()\n    }\n    \n    pub fn set(\u0026self, provider: \u0026str, status: \u0026StatusPayload) {\n        let mut entries = self.entries.write().unwrap();\n        entries.insert(provider.to_string(), CachedStatus {\n            status: status.clone(),\n            fetched_at: Instant::now(),\n        });\n    }\n    \n    pub fn is_stale(\u0026self, entry: \u0026CachedStatus) -\u003e bool {\n        entry.fetched_at.elapsed() \u003e self.ttl\n    }\n}\n```\n\n### Result Merging\n```rust\nimpl ParallelFetcher {\n    fn merge_results(\n        \u0026self,\n        providers: \u0026[String],\n        usage_results: Vec\u003cResult\u003cProviderPayload\u003e\u003e,\n        status_results: Vec\u003cResult\u003cStatusPayload\u003e\u003e,\n    ) -\u003e Vec\u003cFetchResult\u003e {\n        providers\n            .iter()\n            .enumerate()\n            .map(|(i, provider)| {\n                let mut payload = match \u0026usage_results.get(i) {\n                    Some(Ok(p)) =\u003e p.clone(),\n                    Some(Err(e)) =\u003e {\n                        warn!(\"Usage fetch failed for {}: {}\", provider, e);\n                        ProviderPayload::error(provider, e)\n                    }\n                    None =\u003e ProviderPayload::empty(provider),\n                };\n                \n                // Merge in status\n                if let Some(Ok(status)) = status_results.get(i) {\n                    payload.status = Some(status.clone());\n                }\n                \n                FetchResult {\n                    provider: provider.clone(),\n                    payload,\n                    fetch_time: Instant::now(),\n                }\n            })\n            .collect()\n    }\n}\n```\n\n## Performance Goals\n- Usage fetch: ~500ms typical\n- Status fetch: ~200ms typical (timeout at 3s)\n- Total parallel fetch: ~500ms (not 700ms sequential)\n- Cache TTL: 60 seconds for status\n\n## Acceptance Criteria\n- [ ] Usage and status fetched in parallel\n- [ ] Status timeout does not block usage\n- [ ] Results correctly merged\n- [ ] Cache prevents redundant status fetches\n- [ ] Failed status does not fail overall fetch\n- [ ] Performance meets goals (parallel \u003c sequential)\n\n## Error Handling Strategy\n| Scenario | Behavior |\n|----------|----------|\n| Usage fails | Return error for that provider |\n| Status fails | Return Unknown status, continue |\n| Status times out | Return Unknown status, continue |\n| Both fail | Return error with Unknown status |\n\n## Dependencies\n- Requires status page clients (sibling task)\n- Integrates with existing usage fetchers\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:17:44.6333016-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:17:44.6333016-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-7qd","depends_on_id":"coding_agent_usage_tracker-82s","type":"blocks","created_at":"2026-01-18T14:22:13.918273783-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-7r4","title":"CI workflow: Test result aggregation and badges","description":"## Overview\nAggregate test results and generate status badges.\n\n## File: .github/workflows/badges.yml (or in test.yml)\n\n## Requirements\n1. **Status Badges**\n   - Build status badge\n   - Test pass/fail badge\n   - Coverage percentage badge\n\n2. **Dashboard**\n   - Test trend over time\n   - Coverage trend\n   - Flaky test detection\n\n3. **Notifications**\n   - Slack/Discord on failure (optional)\n   - Email digest\n\n## Implementation\n- Use gist-based badges or shields.io\n- Upload results to external service\n- Generate README badges\n\n## Acceptance Criteria\n- [ ] Badges in README\n- [ ] Badges auto-update\n- [ ] Historical data tracked","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:17:44.636039649-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:17:44.636039649-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-7r4","depends_on_id":"coding_agent_usage_tracker-cqm","type":"blocks","created_at":"2026-01-18T02:18:40.127580696-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-7zh","title":"[EPIC] Session-Aware Cost Attribution","description":"## Overview\n\nSession-Aware Cost Attribution answers THE fundamental question that motivated building caut: **\"What did my coding session just cost me?\"**\n\nThis feature integrates with Claude Code and Codex session logs to show per-session costs, transforming abstract usage numbers into concrete, actionable cost data tied to actual work.\n\n## Strategic Importance (Why P1)\n\n- **Highest differentiation**: No other tool provides this integration\n- **Answers the core question**: Users want to know \"what did THIS cost?\"\n- **Enables cost-conscious development**: Developers can correlate cost with productivity\n- **Foundation for attribution**: Per-project, per-task cost tracking becomes possible\n\n## User Value Proposition\n\n**Current state**: User finishes a coding session, has no idea what it cost.\n\n**Target state**:\n```\n$ caut session\nLast Session Summary (ended 5 minutes ago)\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nDuration: 2h 14m\nTotal Cost: $4.12\n\nBreakdown:\n  Claude (Opus): $2.89 (847K tokens)\n  Claude (Sonnet): $0.91 (312K tokens)  \n  Codex: $0.32 (45K tokens)\n\nEfficiency: $1.84/hour\nCompared to average: 12% higher (heavy Opus usage)\n```\n\nUsers can now:\n- Know exactly what their work cost\n- Identify expensive patterns (e.g., too much Opus)\n- Make informed decisions about model selection\n- Budget time and money for projects\n\n## Technical Approach\n\n### Session Log Sources\n\n**Claude Code** (`~/.claude/`):\n- Session files with timestamps, token counts, model usage\n- Need to parse session boundaries and aggregate\n\n**Codex** (`~/.codex/`):\n- Event logs (JSONL format) with timestamps and usage data\n- Similar parsing needed\n\n### Correlation Logic\n\n1. **Parse session logs**: Extract start/end times, token counts, models\n2. **Apply pricing**: Model-specific pricing (input/output/cache tokens)\n3. **Aggregate**: Sum costs within session boundaries\n4. **Display**: Show breakdown by provider/model\n\n```rust\nstruct SessionCost {\n    start: DateTime\u003cUtc\u003e,\n    end: DateTime\u003cUtc\u003e,\n    duration: Duration,\n    total_cost: f64,\n    breakdown: Vec\u003cProviderCost\u003e,\n}\n\nstruct ProviderCost {\n    provider: Provider,\n    model: Option\u003cString\u003e,\n    input_tokens: i64,\n    output_tokens: i64,\n    cost: f64,\n}\n```\n\n### Pricing Data\n\nNeed to maintain pricing table (updates periodically):\n```rust\nconst PRICING: \u0026[ModelPricing] = \u0026[\n    ModelPricing { model: \"claude-opus-4\", input_per_mtok: 15.0, output_per_mtok: 75.0 },\n    ModelPricing { model: \"claude-sonnet-4\", input_per_mtok: 3.0, output_per_mtok: 15.0 },\n    ModelPricing { model: \"gpt-4\", input_per_mtok: 30.0, output_per_mtok: 60.0 },\n    // ...\n];\n```\n\n## Commands\n\n- `caut session` - Last session summary\n- `caut session --list` - Recent sessions list\n- `caut session --id \u003cid\u003e` - Specific session details\n- `caut session --today` - All sessions today\n- `caut session --json` - Machine-readable output\n\n## Success Criteria\n\n- [ ] Claude Code session logs parsed correctly\n- [ ] Codex event logs parsed correctly\n- [ ] Session boundaries detected accurately\n- [ ] Cost calculation matches actual billing (within 5%)\n- [ ] Multiple concurrent sessions handled\n- [ ] Historical sessions accessible\n- [ ] JSON output for automation\n\n## Dependencies\n\n- **Benefits from**: Historical tracking for trend comparison\n- **Independent of**: Other EPICs (can be built standalone)\n- **External dependency**: Session log format stability\n\n## Risks and Mitigations\n\n- **Risk**: Session log formats change ‚Üí **Mitigation**: Version detection, graceful degradation\n- **Risk**: Pricing data becomes stale ‚Üí **Mitigation**: Warn if pricing \u003e 30 days old, easy update mechanism\n- **Risk**: Session boundaries ambiguous ‚Üí **Mitigation**: Configurable gap threshold, manual override\n\n## Considerations\n\n- Privacy: Session data may contain sensitive info - don't transmit\n- Accuracy: Token counts may not perfectly match billing\n- Complexity: Higher than other features - consider phased rollout","status":"open","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:11:17.018986819-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:11:17.018986819-05:00"}
{"id":"coding_agent_usage_tracker-7zk","title":"API: Add server-side caching layer","description":"Create src/api/cache.rs with ApiCache struct. CacheEntry\u003cT\u003e tracks data, timestamp, age. Usage cache with default TTL. History cache keyed by provider+days with 2x TTL. Budget cache. stats() endpoint returns cache status. clear() endpoint (POST) invalidates all. Thread-safe via RwLock. Memory-bounded (don't store unlimited history).","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:15:46.842031349-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:15:46.842031349-05:00"}
{"id":"coding_agent_usage_tracker-82s","title":"Status: Implement status page API clients","description":"## Summary\nImplement standardized clients for fetching real-time status from provider status pages.\n\n## Background\nLLM providers maintain public status pages that report service health:\n- Anthropic: status.anthropic.com (Atlassian Statuspage)\n- OpenAI: status.openai.com (Atlassian Statuspage)\n- Others: Various formats\n\nWe need to fetch this data reliably and transform it to our common model.\n\n## Technical Design\n\n### Status Page Client Trait\n```rust\n#[async_trait]\npub trait StatusPageClient: Send + Sync {\n    /// Fetch current status from the provider\n    async fn fetch_status(\u0026self) -\u003e Result\u003cStatusPayload\u003e;\n    \n    /// Get the status page URL for display\n    fn status_url(\u0026self) -\u003e \u0026str;\n    \n    /// Provider name\n    fn provider(\u0026self) -\u003e \u0026str;\n}\n```\n\n### Atlassian Statuspage Client\nMost providers use Atlassian Statuspage (status.anthropic.com, status.openai.com).\n\n```rust\npub struct AtlassianStatuspageClient {\n    base_url: String,\n    provider: String,\n    client: reqwest::Client,\n}\n\nimpl AtlassianStatuspageClient {\n    pub fn new(base_url: \u0026str, provider: \u0026str) -\u003e Self {\n        Self {\n            base_url: base_url.to_string(),\n            provider: provider.to_string(),\n            client: reqwest::Client::builder()\n                .timeout(Duration::from_secs(5))\n                .build()\n                .expect(\"Failed to create HTTP client\"),\n        }\n    }\n}\n\n#[async_trait]\nimpl StatusPageClient for AtlassianStatuspageClient {\n    async fn fetch_status(\u0026self) -\u003e Result\u003cStatusPayload\u003e {\n        let url = format!(\"{}/api/v2/status.json\", self.base_url);\n        \n        let response: AtlassianStatusResponse = self.client\n            .get(\u0026url)\n            .header(\"Accept\", \"application/json\")\n            .send()\n            .await?\n            .json()\n            .await?;\n        \n        Ok(StatusPayload {\n            indicator: self.map_indicator(\u0026response.status.indicator),\n            description: Some(response.status.description),\n            updated_at: response.page.updated_at,\n            url: self.base_url.clone(),\n        })\n    }\n    \n    fn status_url(\u0026self) -\u003e \u0026str {\n        \u0026self.base_url\n    }\n    \n    fn provider(\u0026self) -\u003e \u0026str {\n        \u0026self.provider\n    }\n}\n\nimpl AtlassianStatuspageClient {\n    fn map_indicator(\u0026self, indicator: \u0026str) -\u003e StatusIndicator {\n        match indicator.to_lowercase().as_str() {\n            \"none\" =\u003e StatusIndicator::None,\n            \"minor\" =\u003e StatusIndicator::Minor,\n            \"major\" =\u003e StatusIndicator::Major,\n            \"critical\" =\u003e StatusIndicator::Critical,\n            \"maintenance\" =\u003e StatusIndicator::Maintenance,\n            _ =\u003e StatusIndicator::Unknown,\n        }\n    }\n}\n\n#[derive(Debug, Deserialize)]\nstruct AtlassianStatusResponse {\n    page: PageInfo,\n    status: StatusInfo,\n}\n\n#[derive(Debug, Deserialize)]\nstruct StatusInfo {\n    indicator: String,\n    description: String,\n}\n\n#[derive(Debug, Deserialize)]\nstruct PageInfo {\n    updated_at: Option\u003cDateTime\u003cUtc\u003e\u003e,\n}\n```\n\n### Provider Status Registry\n```rust\npub struct StatusRegistry {\n    clients: HashMap\u003cString, Box\u003cdyn StatusPageClient\u003e\u003e,\n}\n\nimpl StatusRegistry {\n    pub fn new() -\u003e Self {\n        let mut registry = Self {\n            clients: HashMap::new(),\n        };\n        \n        // Register known providers\n        registry.register(Box::new(AtlassianStatuspageClient::new(\n            \"https://status.anthropic.com\",\n            \"claude\",\n        )));\n        \n        registry.register(Box::new(AtlassianStatuspageClient::new(\n            \"https://status.openai.com\",\n            \"codex\",\n        )));\n        \n        // Add more as needed\n        registry\n    }\n    \n    pub fn register(\u0026mut self, client: Box\u003cdyn StatusPageClient\u003e) {\n        self.clients.insert(client.provider().to_string(), client);\n    }\n    \n    pub fn get(\u0026self, provider: \u0026str) -\u003e Option\u003c\u0026dyn StatusPageClient\u003e {\n        self.clients.get(provider).map(|c| c.as_ref())\n    }\n    \n    pub fn all(\u0026self) -\u003e impl Iterator\u003cItem = \u0026dyn StatusPageClient\u003e {\n        self.clients.values().map(|c| c.as_ref())\n    }\n}\n```\n\n## Provider Status URLs\n| Provider | Status Page | Format |\n|----------|-------------|--------|\n| Claude | status.anthropic.com | Atlassian |\n| Codex/OpenAI | status.openai.com | Atlassian |\n| OpenRouter | status.openrouter.ai | Atlassian |\n| Cursor | status.cursor.com | Atlassian |\n| Mistral | status.mistral.ai | Custom |\n\n## Acceptance Criteria\n- [ ] Atlassian Statuspage client works\n- [ ] All status indicators mapped correctly\n- [ ] Request timeout is 5 seconds\n- [ ] Errors handled gracefully (return Unknown)\n- [ ] Status URL accessible for display\n- [ ] Registry provides access to all providers\n- [ ] Unit tests with fixture responses\n\n## Test Fixtures\nCreate JSON fixtures for each status page format:\n- `tests/fixtures/status/statuspage_operational.json`\n- `tests/fixtures/status/statuspage_minor.json`\n- `tests/fixtures/status/statuspage_major.json`\n- `tests/fixtures/status/statuspage_maintenance.json`\n\n## Error Handling\n- Network timeout: return Unknown status\n- Parse error: return Unknown status\n- 404/500: return Unknown status\n- Never fail the overall fetch due to status page errors\n\n## Dependencies\n- None (foundational for status integration)\n- Used by parallel fetching task\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:17:23.490155733-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:17:23.490155733-05:00"}
{"id":"coding_agent_usage_tracker-85e","title":"Complete Claude provider implementation","description":"Claude provider needs: web scraping for macOS browser cookies, improved CLI fallback parsing, and better error handling. OAuth works but web dashboard is not implemented.","status":"closed","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T00:47:00.852095763-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T01:14:09.109753643-05:00","closed_at":"2026-01-18T01:14:09.109753643-05:00","close_reason":"Claude provider core infrastructure is complete. OAuth, web, and CLI strategies are implemented. Claude CLI does not expose rate limit commands directly - rate limits are only accessible via OAuth API. Web scraping on macOS is platform-specific and deferred."}
{"id":"coding_agent_usage_tracker-8al","title":"Watch: Terminal UI with in-place updates","description":"## Overview\nImplement the terminal UI for watch mode that clears and redraws in place, providing a smooth dashboard experience.\n\n## Background \u0026 Rationale\nWatch mode needs to update the display without scrolling. This requires terminal control to:\n- Clear previous output\n- Draw new output in same location\n- Handle terminal resize\n- Support both TTY and non-TTY modes\n\n## Technical Approach\n\n### 1. Terminal Control\n```rust\n// In render/watch_ui.rs\nuse std::io::{self, Write};\n\npub struct WatchRenderer {\n    last_lines: usize,\n    is_tty: bool,\n}\n\nimpl WatchRenderer {\n    pub fn new() -\u003e Self {\n        Self {\n            last_lines: 0,\n            is_tty: atty::is(atty::Stream::Stdout),\n        }\n    }\n    \n    /// Clear previous output and move cursor to start.\n    fn clear_previous(\u0026self) {\n        if \\!self.is_tty {\n            return;\n        }\n        \n        // Move cursor up `last_lines` and clear\n        for _ in 0..self.last_lines {\n            // Move up one line and clear it\n            print\\!(\"\\x1b[1A\\x1b[2K\");\n        }\n        io::stdout().flush().ok();\n    }\n    \n    /// Render a frame, tracking line count for next clear.\n    pub fn render_frame(\u0026mut self, state: \u0026WatchState, no_color: bool) -\u003e Result\u003c()\u003e {\n        self.clear_previous();\n        \n        let output = format_watch_output(state, no_color)?;\n        self.last_lines = output.lines().count();\n        \n        print\\!(\"{}\", output);\n        io::stdout().flush()?;\n        \n        Ok(())\n    }\n}\n```\n\n### 2. Watch Output Format\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ caut watch                          Updated: 2025-01-18 14:32 ‚îÇ\n‚îÇ Interval: 30s | Fetches: 42 | Errors: 1                      ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ ‚óè Claude 2.0.1 (oauth)                                       ‚îÇ\n‚îÇ   Session: 45% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë resets in 3h                 ‚îÇ\n‚îÇ   Weekly:  78% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë resets Monday                ‚îÇ\n‚îÇ                                                              ‚îÇ\n‚îÇ ‚óè Codex 0.87.0 (cli)                                        ‚îÇ\n‚îÇ   Pro plan ¬∑ user@example.com                                ‚îÇ\n‚îÇ                                                              ‚îÇ\n‚îÇ ‚ö† Gemini: Network timeout (showing stale data from 2m ago)  ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Press Ctrl+C to exit                                        ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n### 3. Header with Metadata\n```rust\nfn format_header(state: \u0026WatchState) -\u003e String {\n    let updated = state.last_fetch_at\n        .map(|t| t.format(\"%H:%M:%S\").to_string())\n        .unwrap_or_else(|| \"never\".to_string());\n    \n    format\\!(\n        \"caut watch                          Updated: {}\nInterval: {}s | Fetches: {} | Errors: {}\",\n        updated,\n        state.interval.as_secs(),\n        state.fetch_count,\n        state.error_count\n    )\n}\n```\n\n### 4. Stale Data Indication\n```rust\nfn format_stale_indicator(state: \u0026WatchState) -\u003e Option\u003cString\u003e {\n    if let (Some(results), Some(fetch_time)) = (\u0026state.last_results, state.last_fetch_at) {\n        let age = Utc::now() - fetch_time;\n        if age \u003e chrono::Duration::seconds(60) {\n            return Some(format\\!(\n                \"‚ö† Showing stale data from {} ago\",\n                format_duration(age)\n            ));\n        }\n    }\n    None\n}\n```\n\n### 5. Non-TTY Mode (NDJSON)\n```rust\nimpl WatchRenderer {\n    pub fn render_ndjson(\u0026self, state: \u0026WatchState) -\u003e Result\u003c()\u003e {\n        // For piped output, emit newline-delimited JSON\n        let json = serde_json::to_string(\u0026WatchSnapshot::from(state))?;\n        println\\!(\"{}\", json);\n        Ok(())\n    }\n}\n```\n\n### 6. Terminal Resize Handling\n```rust\nuse signal_hook::iterator::Signals;\n\n// In watch loop\nlet mut signals = Signals::new(\u0026[signal_hook::consts::SIGWINCH])?;\n// Check for resize and redraw if needed\n```\n\n## Files to Create/Modify\n- `src/render/watch_ui.rs`: New file for watch terminal UI\n- `src/render/mod.rs`: Export watch_ui module\n- `src/cli/watch.rs`: Use WatchRenderer\n\n## Dependencies\n- Requires core watch loop (40y) to be complete\n\n## Acceptance Criteria\n- [ ] Output clears and redraws without scrolling\n- [ ] Terminal resize is handled gracefully\n- [ ] Non-TTY mode outputs NDJSON\n- [ ] Stale data is clearly indicated\n- [ ] Header shows metadata (time, fetch count, errors)\n- [ ] Footer shows exit instruction\n\n## Testing Strategy\n- Manual testing with various terminal sizes\n- Test TTY vs piped output\n- Verify NDJSON format is valid\n- Test with resize signals","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:58:33.403799196-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:58:33.403799196-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-8al","depends_on_id":"coding_agent_usage_tracker-40y","type":"blocks","created_at":"2026-01-18T02:59:23.21507319-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-8gp","title":"Unit tests for providers/claude.rs (CRITICAL)","description":"## Overview\nüö® CRITICAL: Provider tests have 0% coverage. This is the highest priority.\n\n## Target: src/providers/claude/mod.rs (516 lines)\n\n## Test Cases - Organized by Function\n\n### 1. Fetch Plan Creation\n**`fetch_plan()`**\n- Returns four strategies (oauth-api, web-dashboard, cli-pty, cli-config)\n- Strategy ordering and fallback logic\n- Platform availability checks\n\n### 2. Config Discovery Functions\n**`get_claude_dir()`**\n- Returns ~/.config/claude-code or ~/.claude\n- XDG_CONFIG_HOME override\n- Platform differences\n\n**`has_local_config()`**\n- Returns true when credentials.json exists\n- Returns false when missing\n- Handles permission errors gracefully\n\n**`is_cli_available()`**\n- Returns true when claude binary in PATH\n- Returns false when missing\n\n**`has_oauth_token()`**\n- Checks CLAUDE_OAUTH_TOKEN env var\n- Reads from credentials file\n\n**`get_oauth_token()`**\n- Returns token from env var first\n- Falls back to credentials file\n- Returns None when neither available\n\n### 3. Credential and Identity Handling\n**`read_local_credentials()`**\n- Parse valid credentials.json\n- Handle missing file\n- Handle malformed JSON\n- Handle empty file\n\n**`get_local_identity()`**\n- Extract account_email from credentials\n- Extract organization\n- Handle partial credentials\n- Handle missing fields gracefully\n\n### 4. API Response Parsing (CRITICAL)\n**`parse_api_response()`**\n- Parse ClaudeRateLimitResponse with all fields\n- Handle null/missing rate_limit\n- Handle null/missing credits\n- Calculate remaining_percent from response\n- Parse resets_at timestamps\n- Handle various time formats\n\n**`parse_cli_limits_output()`**\n- Parse multi-line CLI output\n- Extract session rate limit\n- Extract weekly rate limit\n- Extract Opus/Sonnet specific limits (tertiary)\n- Handle various output formats from different CLI versions\n- Handle missing sections\n\n**`extract_percent()`**\n- Extract \"70%\" format\n- Extract \"70.5%\" with decimals\n- Handle \"100%\" edge case\n- Handle \"0%\" edge case\n- Return None for non-matching lines\n- Regex edge cases (multiple numbers in line)\n\n### 5. Async Fetch Functions\n**`fetch_oauth(token)`**\n- Successful API call with valid token\n- HTTP error handling (401, 403, 500)\n- Network timeout handling\n- Invalid response body handling\n- Rate limiting response codes\n\n**`fetch_web()`**\n- Platform check (macOS only)\n- UnsupportedSource error on Linux\n- (macOS tests if applicable)\n\n**`fetch_cli()`**\n- Successful CLI execution\n- CLI not found error\n- CLI timeout handling\n- Parse output integration\n- PTY allocation fallback\n\n**`try_json_rate_limit()`**\n- Test all command variations (limits --json, status --json, etc.)\n- Handle command not found\n- Handle invalid JSON output\n\n**`get_cli_version()`**\n- Parse \"claude-code 0.2.105\" format\n- Parse version only format\n- Handle version parse errors\n\n### 6. Token Storage Functions\n**`store_oauth_token()`**\n- Create config directory if needed\n- Write token to credentials.json\n- Handle permission errors\n\n**`delete_oauth_token()`**\n- Delete credentials file\n- Handle file not found gracefully\n- Handle permission errors\n\n## Fixture Requirements\n- Sample ~/.config/claude-code/credentials.json\n- Sample ClaudeRateLimitResponse JSON (multiple variants)\n- Sample CLI limits output text (multiple CLI versions)\n- Sample OAuth API responses\n\n## Acceptance Criteria\n- [ ] All config discovery paths tested\n- [ ] All parsing functions have edge case tests\n- [ ] OAuth flow tested with mocked HTTP\n- [ ] CLI output parsing tested with real examples\n- [ ] Error handling complete for all fetch methods\n- [ ] Token storage tested (create, read, delete)","status":"closed","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:14:41.597349812-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T10:52:56.993894684-05:00","closed_at":"2026-01-18T10:52:56.993894684-05:00","close_reason":"Added 25 comprehensive unit tests for providers/claude.rs covering fetch plan, API response parsing, CLI output parsing, and percent extraction","dependencies":[{"issue_id":"coding_agent_usage_tracker-8gp","depends_on_id":"coding_agent_usage_tracker-32d","type":"blocks","created_at":"2026-01-18T02:18:16.65349853-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-8gp","depends_on_id":"coding_agent_usage_tracker-5b7","type":"blocks","created_at":"2026-01-18T02:18:16.709835453-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-8rv","title":"Offline: Implement fetch-with-fallback logic","description":"Create src/core/offline_fetcher.rs with OfflineAwareFetcher. FetchResult\u003cT\u003e tracks data, source, staleness, fetch_error. Fresh cache returned without network call. Network failure falls back to cache (even expired). Staleness duration tracked. offline_only() method for forced offline mode. fetch_provider_usage() convenience method.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:15:22.039956966-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:15:22.039956966-05:00"}
{"id":"coding_agent_usage_tracker-90i","title":"Integration tests: Config file handling","description":"## Overview\nTest configuration file discovery and parsing in realistic scenarios.\n\n## Scope\nConfig discovery ‚Üí Parsing ‚Üí Application\n\n## Test Scenarios\n1. **Config File Discovery**\n   - Standard locations found\n   - XDG paths respected\n   - Fallback chain works\n\n2. **Config Parsing**\n   - Valid config loads\n   - Partial config fills defaults\n   - Invalid config errors gracefully\n\n3. **Config Priority**\n   - CLI args override config\n   - Env vars override config\n   - Multiple configs merged\n\n4. **Provider-Specific Configs**\n   - Claude Code config parsed\n   - Codex config parsed\n   - Cursor config parsed\n\n## Test Infrastructure\n- Create temp config directories\n- Write test config files\n- Verify loaded values\n\n## Acceptance Criteria\n- [ ] All config locations tested\n- [ ] Priority chain verified\n- [ ] Provider configs parsed correctly\n- [ ] Error handling for malformed configs","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:15:55.678233405-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:15:55.678233405-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-90i","depends_on_id":"coding_agent_usage_tracker-ggw","type":"blocks","created_at":"2026-01-18T02:18:31.420301011-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-9a9","title":"Offline: Test suite for cache layer and graceful degradation","description":"## Summary\nImplement comprehensive test suite for Offline Mode including cache layer, staleness detection, network failure handling, and graceful degradation.\n\n## Parent EPIC\n[EPIC] Offline Mode (coding_agent_usage_tracker-v3f)\n\n## Test Categories\n\n### 1. Unit Tests: Cache Layer\n```rust\n#[cfg(test)]\nmod cache_layer_tests {\n    use crate::cache::{CacheLayer, CacheEntry, CachePolicy};\n    use std::time::Duration;\n\n    #[test]\n    fn test_cache_write_and_read() {\n        let tmp = TempDir::new().unwrap();\n        let cache = CacheLayer::new(tmp.path());\n\n        let data = mock_provider_payload(\"claude\", 45.0);\n        cache.set(\"claude:usage\", \u0026data, Duration::from_secs(300)).unwrap();\n\n        let cached: ProviderPayload = cache.get(\"claude:usage\").unwrap().unwrap();\n        assert_eq!(cached.provider, \"claude\");\n    }\n\n    #[test]\n    fn test_cache_expiry() {\n        let tmp = TempDir::new().unwrap();\n        let cache = CacheLayer::new(tmp.path());\n\n        let data = mock_provider_payload(\"claude\", 45.0);\n        cache.set(\"claude:usage\", \u0026data, Duration::from_millis(50)).unwrap();\n\n        std::thread::sleep(Duration::from_millis(100));\n\n        let result: Option\u003cProviderPayload\u003e = cache.get(\"claude:usage\").unwrap();\n        assert!(result.is_none());\n    }\n\n    #[test]\n    fn test_cache_returns_stale_data_when_requested() {\n        let tmp = TempDir::new().unwrap();\n        let cache = CacheLayer::new(tmp.path())\n            .with_policy(CachePolicy::ReturnStale);\n\n        let data = mock_provider_payload(\"claude\", 45.0);\n        cache.set(\"claude:usage\", \u0026data, Duration::from_millis(50)).unwrap();\n\n        std::thread::sleep(Duration::from_millis(100));\n\n        let entry: CacheEntry\u003cProviderPayload\u003e = cache.get_with_metadata(\"claude:usage\").unwrap().unwrap();\n        assert!(entry.is_stale);\n        assert!(entry.data.is_some());\n    }\n\n    #[test]\n    fn test_cache_key_namespacing() {\n        let tmp = TempDir::new().unwrap();\n        let cache = CacheLayer::new(tmp.path());\n\n        cache.set(\"claude:usage\", \u0026\"usage_data\", Duration::from_secs(300)).unwrap();\n        cache.set(\"claude:status\", \u0026\"status_data\", Duration::from_secs(300)).unwrap();\n\n        let usage: String = cache.get(\"claude:usage\").unwrap().unwrap();\n        let status: String = cache.get(\"claude:status\").unwrap().unwrap();\n\n        assert_eq!(usage, \"usage_data\");\n        assert_eq!(status, \"status_data\");\n    }\n\n    #[test]\n    fn test_cache_clear_by_prefix() {\n        let tmp = TempDir::new().unwrap();\n        let cache = CacheLayer::new(tmp.path());\n\n        cache.set(\"claude:usage\", \u0026\"data1\", Duration::from_secs(300)).unwrap();\n        cache.set(\"claude:status\", \u0026\"data2\", Duration::from_secs(300)).unwrap();\n        cache.set(\"codex:usage\", \u0026\"data3\", Duration::from_secs(300)).unwrap();\n\n        cache.clear_prefix(\"claude:\").unwrap();\n\n        assert!(cache.get::\u003cString\u003e(\"claude:usage\").unwrap().is_none());\n        assert!(cache.get::\u003cString\u003e(\"claude:status\").unwrap().is_none());\n        assert!(cache.get::\u003cString\u003e(\"codex:usage\").unwrap().is_some());\n    }\n\n    #[test]\n    fn test_cache_size_limit() {\n        let tmp = TempDir::new().unwrap();\n        let cache = CacheLayer::new(tmp.path())\n            .with_max_size(1024); // 1KB limit\n\n        // Write data that exceeds limit\n        let large_data = \"x\".repeat(2000);\n        let result = cache.set(\"large\", \u0026large_data, Duration::from_secs(300));\n\n        // Should either reject or evict older entries\n        assert!(result.is_ok() || matches!(result, Err(CacheError::SizeExceeded)));\n    }\n}\n```\n\n### 2. Unit Tests: Offline Detection\n```rust\n#[cfg(test)]\nmod offline_detection_tests {\n    use crate::network::{NetworkMonitor, NetworkStatus};\n\n    #[test]\n    fn test_detect_offline_state() {\n        let monitor = NetworkMonitor::new();\n\n        // Simulate network check failure\n        monitor.record_failure(\"https://api.anthropic.com\");\n        monitor.record_failure(\"https://api.anthropic.com\");\n        monitor.record_failure(\"https://api.anthropic.com\");\n\n        assert_eq!(monitor.status(), NetworkStatus::Offline);\n    }\n\n    #[test]\n    fn test_detect_online_state() {\n        let monitor = NetworkMonitor::new();\n\n        monitor.record_success(\"https://api.anthropic.com\");\n\n        assert_eq!(monitor.status(), NetworkStatus::Online);\n    }\n\n    #[test]\n    fn test_degraded_state() {\n        let monitor = NetworkMonitor::new();\n\n        // Some failures, some successes\n        monitor.record_success(\"https://api.anthropic.com\");\n        monitor.record_failure(\"https://api.openai.com\");\n        monitor.record_failure(\"https://api.openai.com\");\n\n        assert_eq!(monitor.status(), NetworkStatus::Degraded);\n    }\n\n    #[test]\n    fn test_provider_specific_status() {\n        let monitor = NetworkMonitor::new();\n\n        monitor.record_success(\"https://api.anthropic.com\");\n        monitor.record_failure(\"https://api.openai.com\");\n\n        assert!(monitor.is_reachable(\"anthropic\"));\n        assert!(!monitor.is_reachable(\"openai\"));\n    }\n\n    #[test]\n    fn test_status_recovery() {\n        let monitor = NetworkMonitor::new();\n\n        // Go offline\n        for _ in 0..3 {\n            monitor.record_failure(\"https://api.anthropic.com\");\n        }\n        assert_eq!(monitor.status(), NetworkStatus::Offline);\n\n        // Recover\n        monitor.record_success(\"https://api.anthropic.com\");\n        assert_eq!(monitor.status(), NetworkStatus::Online);\n    }\n}\n```\n\n### 3. Unit Tests: Graceful Degradation\n```rust\n#[cfg(test)]\nmod degradation_tests {\n    #[tokio::test]\n    async fn test_fallback_to_cache_on_network_error() {\n        let tmp = TempDir::new().unwrap();\n        let cache = CacheLayer::new(tmp.path());\n\n        // Pre-populate cache\n        let cached_data = mock_provider_payload(\"claude\", 45.0);\n        cache.set(\"claude:usage\", \u0026cached_data, Duration::from_secs(300)).unwrap();\n\n        // Create fetcher that will fail\n        let fetcher = OfflineAwareFetcher::new(cache)\n            .with_network_simulator(|_| Err(NetworkError::Unreachable));\n\n        let result = fetcher.fetch_usage(\"claude\").await;\n\n        assert!(result.is_ok());\n        let (data, source) = result.unwrap();\n        assert_eq!(data.provider, \"claude\");\n        assert_eq!(source, DataSource::Cache);\n    }\n\n    #[tokio::test]\n    async fn test_fresh_data_preferred_when_online() {\n        let tmp = TempDir::new().unwrap();\n        let cache = CacheLayer::new(tmp.path());\n\n        // Cache has old data\n        let cached_data = mock_provider_payload(\"claude\", 30.0);\n        cache.set(\"claude:usage\", \u0026cached_data, Duration::from_secs(300)).unwrap();\n\n        // Network returns fresh data\n        let fresh_data = mock_provider_payload(\"claude\", 50.0);\n        let fetcher = OfflineAwareFetcher::new(cache)\n            .with_network_simulator(move |_| Ok(fresh_data.clone()));\n\n        let result = fetcher.fetch_usage(\"claude\").await;\n\n        let (data, source) = result.unwrap();\n        assert!((data.usage.primary.unwrap().used_percent - 50.0).abs() \u003c 0.1);\n        assert_eq!(source, DataSource::Network);\n    }\n\n    #[test]\n    fn test_staleness_indicator_in_output() {\n        let tmp = TempDir::new().unwrap();\n        let cache = CacheLayer::new(tmp.path());\n\n        // Cache data that's stale but not expired\n        let data = mock_provider_payload(\"claude\", 45.0);\n        cache.set_with_staleness(\n            \"claude:usage\",\n            \u0026data,\n            Duration::from_secs(300),  // TTL\n            Duration::from_millis(50), // Stale after\n        ).unwrap();\n\n        std::thread::sleep(Duration::from_millis(100));\n\n        let entry = cache.get_with_metadata::\u003cProviderPayload\u003e(\"claude:usage\").unwrap().unwrap();\n        assert!(entry.is_stale);\n        assert!(entry.stale_duration \u003e Duration::from_millis(50));\n    }\n\n    #[tokio::test]\n    async fn test_no_data_available_error() {\n        let tmp = TempDir::new().unwrap();\n        let cache = CacheLayer::new(tmp.path());\n        // Empty cache, no network\n\n        let fetcher = OfflineAwareFetcher::new(cache)\n            .with_network_simulator(|_| Err(NetworkError::Unreachable));\n\n        let result = fetcher.fetch_usage(\"claude\").await;\n\n        assert!(matches!(result, Err(FetchError::NoDataAvailable)));\n    }\n}\n```\n\n### 4. Unit Tests: Cache Persistence\n```rust\n#[cfg(test)]\nmod persistence_tests {\n    #[test]\n    fn test_cache_survives_restart() {\n        let tmp = TempDir::new().unwrap();\n        let cache_path = tmp.path().join(\"cache\");\n\n        // First session: write data\n        {\n            let cache = CacheLayer::new(\u0026cache_path);\n            cache.set(\"claude:usage\", \u0026\"test_data\", Duration::from_secs(3600)).unwrap();\n        }\n\n        // Second session: read data\n        {\n            let cache = CacheLayer::new(\u0026cache_path);\n            let data: String = cache.get(\"claude:usage\").unwrap().unwrap();\n            assert_eq!(data, \"test_data\");\n        }\n    }\n\n    #[test]\n    fn test_cache_migration() {\n        let tmp = TempDir::new().unwrap();\n        let cache_path = tmp.path().join(\"cache\");\n\n        // Create old format cache\n        create_legacy_cache_format(\u0026cache_path);\n\n        // New cache should migrate\n        let cache = CacheLayer::new(\u0026cache_path);\n        let data: Option\u003cString\u003e = cache.get(\"legacy_key\").unwrap();\n\n        assert!(data.is_some() || cache.migration_completed());\n    }\n\n    #[test]\n    fn test_cache_corruption_recovery() {\n        let tmp = TempDir::new().unwrap();\n        let cache_path = tmp.path().join(\"cache\");\n\n        // Create corrupted cache file\n        fs::create_dir_all(\u0026cache_path).unwrap();\n        fs::write(cache_path.join(\"corrupted.cache\"), \"not valid cache data\").unwrap();\n\n        // Cache should handle gracefully\n        let cache = CacheLayer::new(\u0026cache_path);\n        let result: Option\u003cString\u003e = cache.get(\"corrupted\").unwrap();\n\n        assert!(result.is_none());\n        // Should log warning but not panic\n    }\n}\n```\n\n### 5. Integration Tests\n```rust\n#[tokio::test]\nasync fn test_offline_mode_cli_flag() {\n    let tmp = TempDir::new().unwrap();\n    setup_cache_data(\u0026tmp);\n\n    let output = Command::new(\"caut\")\n        .args([\"show\", \"--offline\"])\n        .env(\"HOME\", tmp.path())\n        .output()\n        .unwrap();\n\n    assert!(output.status.success());\n    let stdout = String::from_utf8_lossy(\u0026output.stdout);\n    assert!(stdout.contains(\"cached\") || stdout.contains(\"offline\"));\n}\n\n#[tokio::test]\nasync fn test_automatic_offline_fallback() {\n    let tmp = TempDir::new().unwrap();\n    setup_cache_data(\u0026tmp);\n\n    // Block network access (or use mock)\n    let output = Command::new(\"caut\")\n        .args([\"show\", \"--format\", \"json\"])\n        .env(\"HOME\", tmp.path())\n        .env(\"CAUT_NETWORK_DISABLED\", \"1\") // Test flag\n        .output()\n        .unwrap();\n\n    let result: serde_json::Value = serde_json::from_slice(\u0026output.stdout).unwrap();\n    assert!(result.get(\"from_cache\").is_some());\n}\n```\n\n### 6. E2E Tests\n```bash\n#!/bin/bash\n# tests/e2e/offline_e2e.sh\n\nset -euo pipefail\nsource \"$(dirname \"$0\")/helpers.sh\"\n\nlog_section \"Offline Mode E2E Tests\"\n\nTEMP_DIR=$(mktemp -d)\nexport HOME=\"$TEMP_DIR\"\nexport XDG_CACHE_HOME=\"$TEMP_DIR/.cache\"\ntrap \"rm -rf $TEMP_DIR\" EXIT\n\n# Setup: Create cached data\nsetup_cached_data() {\n    mkdir -p \"$XDG_CACHE_HOME/caut\"\n    cat \u003e \"$XDG_CACHE_HOME/caut/claude_usage.json\" \u003c\u003c 'EOF'\n{\n  \"data\": {\n    \"provider\": \"claude\",\n    \"usage\": {\"primary\": {\"used_percent\": 45.0}}\n  },\n  \"cached_at\": \"2099-12-31T00:00:00Z\",\n  \"expires_at\": \"2099-12-31T23:59:59Z\"\n}\nEOF\n}\n\n# Test 1: Offline flag uses cache\nlog_test \"Offline flag uses cached data\"\nsetup_cached_data\nOUTPUT=$(caut show --offline --format json 2\u003e\u00261)\necho \"$OUTPUT\" | jq -e '.from_cache == true or .source == \"cache\"' \u003e /dev/null \u0026\u0026 log_pass || log_pass \"Offline mode works\"\n\n# Test 2: Cache populated after online fetch\nlog_test \"Cache populated after fetch\"\nrm -rf \"$XDG_CACHE_HOME/caut\"\n# This will fail without network but creates cache structure\ncaut show 2\u003e\u00261 || true\n[[ -d \"$XDG_CACHE_HOME/caut\" ]] \u0026\u0026 log_pass || log_pass \"Cache directory created\"\n\n# Test 3: Stale indicator shown\nlog_test \"Stale data indicated\"\n# Create stale cache\nmkdir -p \"$XDG_CACHE_HOME/caut\"\ncat \u003e \"$XDG_CACHE_HOME/caut/claude_usage.json\" \u003c\u003c 'EOF'\n{\n  \"data\": {\"provider\": \"claude\"},\n  \"cached_at\": \"2020-01-01T00:00:00Z\",\n  \"expires_at\": \"2099-12-31T23:59:59Z\",\n  \"stale_at\": \"2020-01-01T00:05:00Z\"\n}\nEOF\nOUTPUT=$(caut show --offline 2\u003e\u00261)\necho \"$OUTPUT\" | grep -qi \"stale\\|outdated\\|cached\" \u0026\u0026 log_pass || log_pass \"Stale handling works\"\n\n# Test 4: Cache clear command\nlog_test \"Cache clear works\"\nsetup_cached_data\ncaut cache clear 2\u003e\u00261 || fail \"Cache clear failed\"\n[[ ! -f \"$XDG_CACHE_HOME/caut/claude_usage.json\" ]] \u0026\u0026 log_pass || fail \"Cache not cleared\"\n\n# Test 5: Cache stats command\nlog_test \"Cache stats available\"\nsetup_cached_data\nOUTPUT=$(caut cache stats 2\u003e\u00261)\necho \"$OUTPUT\" | grep -qi \"entries\\|size\\|cache\" \u0026\u0026 log_pass || log_pass \"Stats available\"\n\n# Test 6: Network error falls back gracefully\nlog_test \"Network error fallback\"\nsetup_cached_data\nexport CAUT_NETWORK_DISABLED=1\nOUTPUT=$(caut show 2\u003e\u00261)\nunset CAUT_NETWORK_DISABLED\n# Should not error, should show cached or error message\n[[ $? -eq 0 ]] || echo \"$OUTPUT\" | grep -qi \"cached\\|offline\\|unavailable\" \u0026\u0026 log_pass || log_pass \"Fallback works\"\n\nlog_summary\n```\n\n### 7. Logging Verification\n```rust\n#[cfg(test)]\nmod logging_tests {\n    #[test]\n    fn test_cache_hit_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let cache = CacheLayer::new_in_memory();\n        cache.set(\"key\", \u0026\"value\", Duration::from_secs(300)).unwrap();\n        let _: Option\u003cString\u003e = cache.get(\"key\").unwrap();\n\n        capture.assert_logged_at_level(Level::DEBUG, \"cache hit\");\n    }\n\n    #[test]\n    fn test_cache_miss_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let cache = CacheLayer::new_in_memory();\n        let _: Option\u003cString\u003e = cache.get(\"nonexistent\").unwrap();\n\n        capture.assert_logged_at_level(Level::DEBUG, \"cache miss\");\n    }\n\n    #[test]\n    fn test_network_fallback_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let cache = CacheLayer::new_in_memory();\n        cache.set(\"claude:usage\", \u0026mock_provider_payload(\"claude\", 45.0), Duration::from_secs(300)).unwrap();\n\n        let fetcher = OfflineAwareFetcher::new(cache)\n            .with_network_simulator(|_| Err(NetworkError::Unreachable));\n\n        let _ = block_on(fetcher.fetch_usage(\"claude\"));\n\n        capture.assert_logged_at_level(Level::WARN, \"network unreachable\");\n        capture.assert_logged(\"falling back to cache\");\n    }\n\n    #[test]\n    fn test_stale_data_warning_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let cache = CacheLayer::new_in_memory();\n        // Set data that's already stale\n        cache.set_stale(\"key\", \u0026\"value\").unwrap();\n\n        let _ = cache.get_with_metadata::\u003cString\u003e(\"key\");\n\n        capture.assert_logged_at_level(Level::WARN, \"serving stale data\");\n    }\n}\n```\n\n## Acceptance Criteria\n- [ ] Cache layer with TTL works correctly\n- [ ] Offline detection accurate\n- [ ] Graceful fallback to cached data\n- [ ] Staleness indicators shown\n- [ ] Cache persistence across restarts\n- [ ] E2E tests pass\n- [ ] All operations properly logged\n\n## Dependencies\n- Requires logging infrastructure (coding_agent_usage_tracker-zev)\n- Requires offline mode implementation tasks\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:56:29.794753163-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:56:29.794753163-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-9a9","depends_on_id":"coding_agent_usage_tracker-zev","type":"blocks","created_at":"2026-01-18T14:57:04.818026361-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-9a9","depends_on_id":"coding_agent_usage_tracker-v3f","type":"blocks","created_at":"2026-01-18T14:57:04.866223854-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-9ks","title":"Credentials: Test suite for validation, expiry, and refresh","description":"## Summary\nImplement comprehensive test suite for Credential Health Monitoring including validation checks, expiry detection, and E2E verification.\n\n## Parent EPIC\n[EPIC] Credential Health Monitoring (coding_agent_usage_tracker-2tn)\n\n## Test Categories\n\n### 1. Unit Tests: Credential Validation\n```rust\n#[cfg(test)]\nmod credential_validation_tests {\n    use crate::credentials::{CredentialValidator, CredentialHealth, HealthStatus};\n    use crate::test_fixtures::*;\n\n    #[test]\n    fn test_valid_oauth_token() {\n        let validator = CredentialValidator::new();\n        let creds = mock_oauth_credentials(/* expires_in */ 3600);\n\n        let health = validator.check(\u0026creds).unwrap();\n\n        assert_eq!(health.status, HealthStatus::Healthy);\n        assert!(health.expires_in.unwrap() \u003e chrono::Duration::hours(0));\n    }\n\n    #[test]\n    fn test_expired_oauth_token() {\n        let validator = CredentialValidator::new();\n        let creds = mock_oauth_credentials(/* expires_in */ -3600); // Expired 1 hour ago\n\n        let health = validator.check(\u0026creds).unwrap();\n\n        assert_eq!(health.status, HealthStatus::Expired);\n        assert!(health.can_refresh);\n    }\n\n    #[test]\n    fn test_expiring_soon_warning() {\n        let validator = CredentialValidator::new();\n        let creds = mock_oauth_credentials(/* expires_in */ 300); // 5 minutes\n\n        let health = validator.check(\u0026creds).unwrap();\n\n        assert_eq!(health.status, HealthStatus::ExpiringSoon);\n        assert!(health.warning_message.is_some());\n    }\n\n    #[test]\n    fn test_missing_credentials() {\n        let validator = CredentialValidator::new();\n\n        let health = validator.check_path(\"/nonexistent/path\");\n\n        assert!(health.is_err() || health.unwrap().status == HealthStatus::Missing);\n    }\n\n    #[test]\n    fn test_malformed_credentials() {\n        let tmp = TempDir::new().unwrap();\n        let cred_path = tmp.path().join(\"credentials.json\");\n        fs::write(\u0026cred_path, \"not valid json {{{\").unwrap();\n\n        let validator = CredentialValidator::new();\n        let health = validator.check_path(\u0026cred_path);\n\n        assert!(matches!(\n            health.map(|h| h.status),\n            Ok(HealthStatus::Invalid) | Err(_)\n        ));\n    }\n\n    #[test]\n    fn test_api_key_validation() {\n        let validator = CredentialValidator::new();\n\n        // Valid format\n        let valid_key = \"sk-ant-api03-xxxxxxxxxxxxxxxxxxxxx\";\n        assert!(validator.validate_api_key_format(valid_key, \"claude\"));\n\n        // Invalid format\n        let invalid_key = \"not-a-real-key\";\n        assert!(!validator.validate_api_key_format(invalid_key, \"claude\"));\n    }\n}\n```\n\n### 2. Unit Tests: Multi-Provider Health\n```rust\n#[cfg(test)]\nmod multi_provider_tests {\n    #[test]\n    fn test_aggregate_health_all_healthy() {\n        let checker = CredentialHealthChecker::new();\n\n        // Mock all providers healthy\n        let claude = mock_healthy_provider(\"claude\");\n        let codex = mock_healthy_provider(\"codex\");\n\n        let aggregate = checker.aggregate_health(\u0026[claude, codex]);\n\n        assert_eq!(aggregate.overall_status, HealthStatus::Healthy);\n        assert_eq!(aggregate.healthy_count, 2);\n        assert_eq!(aggregate.unhealthy_count, 0);\n    }\n\n    #[test]\n    fn test_aggregate_health_mixed() {\n        let checker = CredentialHealthChecker::new();\n\n        let claude = mock_healthy_provider(\"claude\");\n        let codex = mock_expired_provider(\"codex\");\n\n        let aggregate = checker.aggregate_health(\u0026[claude, codex]);\n\n        // Overall should reflect worst status\n        assert_eq!(aggregate.overall_status, HealthStatus::Degraded);\n        assert!(aggregate.issues.iter().any(|i| i.provider == \"codex\"));\n    }\n\n    #[test]\n    fn test_aggregate_health_all_expired() {\n        let checker = CredentialHealthChecker::new();\n\n        let claude = mock_expired_provider(\"claude\");\n        let codex = mock_expired_provider(\"codex\");\n\n        let aggregate = checker.aggregate_health(\u0026[claude, codex]);\n\n        assert_eq!(aggregate.overall_status, HealthStatus::Critical);\n    }\n}\n```\n\n### 3. Unit Tests: Refresh Logic\n```rust\n#[cfg(test)]\nmod refresh_tests {\n    #[test]\n    fn test_refresh_token_flow() {\n        let mut mocker = MockOAuthServer::new();\n        mocker.expect_refresh().returning(|_| Ok(new_token_response()));\n\n        let refresher = TokenRefresher::new(mocker);\n        let expired_creds = mock_expired_oauth_credentials();\n\n        let result = refresher.refresh(\u0026expired_creds);\n\n        assert!(result.is_ok());\n        let new_creds = result.unwrap();\n        assert!(new_creds.expires_at \u003e Utc::now());\n    }\n\n    #[test]\n    fn test_refresh_token_revoked() {\n        let mut mocker = MockOAuthServer::new();\n        mocker.expect_refresh().returning(|_| Err(OAuthError::TokenRevoked));\n\n        let refresher = TokenRefresher::new(mocker);\n        let expired_creds = mock_expired_oauth_credentials();\n\n        let result = refresher.refresh(\u0026expired_creds);\n\n        assert!(matches!(result, Err(RefreshError::Revoked)));\n    }\n\n    #[test]\n    fn test_no_refresh_for_api_keys() {\n        let refresher = TokenRefresher::new_noop();\n        let api_key_creds = mock_api_key_credentials();\n\n        let result = refresher.refresh(\u0026api_key_creds);\n\n        assert!(matches!(result, Err(RefreshError::NotRefreshable)));\n    }\n}\n```\n\n### 4. Integration Tests\n```rust\n#[test]\nfn test_credential_health_command() {\n    let tmp = TempDir::new().unwrap();\n    setup_mock_credentials(\u0026tmp, \"claude\", CredentialType::OAuth);\n    setup_mock_credentials(\u0026tmp, \"codex\", CredentialType::ApiKey);\n\n    let output = Command::new(\"caut\")\n        .args([\"credentials\", \"health\", \"--format\", \"json\"])\n        .env(\"HOME\", tmp.path())\n        .output()\n        .unwrap();\n\n    assert!(output.status.success());\n\n    let result: CredentialHealthOutput = serde_json::from_slice(\u0026output.stdout).unwrap();\n    assert_eq!(result.providers.len(), 2);\n}\n\n#[test]\nfn test_credential_health_with_warning_threshold() {\n    let tmp = TempDir::new().unwrap();\n    // Token expires in 10 minutes\n    setup_mock_credentials_expiring(\u0026tmp, \"claude\", Duration::minutes(10));\n\n    let output = Command::new(\"caut\")\n        .args([\"credentials\", \"health\", \"--warn-threshold\", \"15m\"])\n        .env(\"HOME\", tmp.path())\n        .output()\n        .unwrap();\n\n    let stdout = String::from_utf8_lossy(\u0026output.stdout);\n    assert!(stdout.contains(\"expiring soon\") || stdout.contains(\"warning\"));\n}\n```\n\n### 5. E2E Tests\n```bash\n#!/bin/bash\n# tests/e2e/credentials_e2e.sh\n\nset -euo pipefail\nsource \"$(dirname \"$0\")/helpers.sh\"\n\nlog_section \"Credential Health E2E Tests\"\n\nTEMP_DIR=$(mktemp -d)\nexport HOME=\"$TEMP_DIR\"\ntrap \"rm -rf $TEMP_DIR\" EXIT\n\n# Setup: Create mock credential files\nsetup_claude_oauth() {\n    mkdir -p \"$TEMP_DIR/.claude\"\n    cat \u003e \"$TEMP_DIR/.claude/credentials.json\" \u003c\u003c 'EOF'\n{\n  \"credentials\": {\n    \"claudeAiOauth\": {\n      \"accessToken\": \"test-access-token\",\n      \"refreshToken\": \"test-refresh-token\",\n      \"expiresAt\": \"2099-12-31T23:59:59Z\"\n    }\n  }\n}\nEOF\n}\n\nsetup_expired_credentials() {\n    mkdir -p \"$TEMP_DIR/.claude\"\n    cat \u003e \"$TEMP_DIR/.claude/credentials.json\" \u003c\u003c 'EOF'\n{\n  \"credentials\": {\n    \"claudeAiOauth\": {\n      \"accessToken\": \"expired-token\",\n      \"refreshToken\": \"expired-refresh\",\n      \"expiresAt\": \"2020-01-01T00:00:00Z\"\n    }\n  }\n}\nEOF\n}\n\n# Test 1: Healthy credentials\nlog_test \"Healthy credentials detected\"\nsetup_claude_oauth\nOUTPUT=$(caut credentials health --format json 2\u003e\u00261)\necho \"$OUTPUT\" | jq -e '.providers[] | select(.provider==\"claude\") | .status == \"healthy\"' || fail \"Claude not healthy\"\nlog_pass\n\n# Test 2: Expired credentials detected\nlog_test \"Expired credentials detected\"\nsetup_expired_credentials\nOUTPUT=$(caut credentials health --format json 2\u003e\u00261)\nSTATUS=$(echo \"$OUTPUT\" | jq -r '.providers[] | select(.provider==\"claude\") | .status')\n[[ \"$STATUS\" == \"expired\" || \"$STATUS\" == \"expiring_soon\" ]] || fail \"Expected expired status, got: $STATUS\"\nlog_pass\n\n# Test 3: Missing credentials handled\nlog_test \"Missing credentials handled gracefully\"\nrm -rf \"$TEMP_DIR/.claude\"\nOUTPUT=$(caut credentials health 2\u003e\u00261)\n# Should not error, should report missing\necho \"$OUTPUT\" | grep -qi \"no credentials\\|missing\\|not found\" \u0026\u0026 log_pass || log_pass \"Missing handled\"\n\n# Test 4: JSON output format\nlog_test \"JSON output format valid\"\nsetup_claude_oauth\nOUTPUT=$(caut credentials health --format json 2\u003e\u00261)\necho \"$OUTPUT\" | jq -e '.providers' \u003e /dev/null || fail \"Invalid JSON\"\nlog_pass\n\n# Test 5: Human-readable output\nlog_test \"Human-readable output works\"\nsetup_claude_oauth\nOUTPUT=$(caut credentials health 2\u003e\u00261)\necho \"$OUTPUT\" | grep -qi \"claude\\|credential\\|health\" || fail \"No credential info in output\"\nlog_pass\n\nlog_summary\n```\n\n### 6. Logging Verification Tests\n```rust\n#[cfg(test)]\nmod logging_tests {\n    use crate::test_logging::TestLogCapture;\n\n    #[test]\n    fn test_credential_check_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let checker = CredentialHealthChecker::new();\n        let _ = checker.check_all();\n\n        capture.assert_logged(\"checking credential health\");\n        capture.assert_logged_at_level(Level::DEBUG, \"provider=\");\n    }\n\n    #[test]\n    fn test_expiry_warning_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let checker = CredentialHealthChecker::new();\n        let _ = checker.check(\u0026mock_expiring_credentials());\n\n        capture.assert_logged_at_level(Level::WARN, \"credential expiring\");\n    }\n\n    #[test]\n    fn test_refresh_attempt_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let refresher = TokenRefresher::new_mock();\n        let _ = refresher.refresh(\u0026mock_expired_oauth_credentials());\n\n        capture.assert_logged(\"attempting token refresh\");\n        capture.assert_logged(\"refresh result\");\n    }\n}\n```\n\n## Acceptance Criteria\n- [ ] All credential types validated correctly\n- [ ] Expiry detection works across providers\n- [ ] Refresh logic tested (success and failure paths)\n- [ ] Multi-provider aggregation correct\n- [ ] E2E tests pass\n- [ ] All operations properly logged\n\n## Dependencies\n- Requires logging infrastructure (coding_agent_usage_tracker-zev)\n- Requires credential health implementation tasks\n","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:56:25.205756758-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:56:25.205756758-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-9ks","depends_on_id":"coding_agent_usage_tracker-zev","type":"blocks","created_at":"2026-01-18T14:57:01.109425843-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-9ks","depends_on_id":"coding_agent_usage_tracker-2tn","type":"blocks","created_at":"2026-01-18T14:57:01.162943949-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-9m6","title":"Implement status page fetching","description":"Add support for fetching provider status pages (statuspage.io API). Include operational status, incident info, and last updated timestamp in usage output when --status flag is passed.","status":"closed","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T01:00:45.917332584-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T01:47:08.745551873-05:00","closed_at":"2026-01-18T01:47:08.745551873-05:00","close_reason":"Already implemented - StatusFetcher in core/status.rs, --status flag in cli/args.rs, wired up in cli/usage.rs lines 43-65"}
{"id":"coding_agent_usage_tracker-9mf","title":"Create test documentation and contribution guide","description":"## Overview\nCreate comprehensive documentation for the test suite.\n\n## Deliverables\n\n### 1. tests/README.md\n```markdown\n# caut Test Suite\n\n## Quick Start\n\\`\\`\\`bash\n# Run all unit tests\ncargo test\n\n# Run with verbose output\ncargo test -- --nocapture\n\n# Run specific test module\ncargo test core::models\n\n# Run E2E tests\n./tests/e2e/run_all.sh\n\\`\\`\\`\n\n## Test Structure\n- `src/**/tests.rs` - Unit tests (inline with code)\n- `tests/` - Integration tests\n- `tests/e2e/` - End-to-end shell scripts\n- `tests/fixtures/` - Test data files\n- `tests/common/` - Shared test utilities\n\n## Writing Tests\n[Guidelines for contributors]\n\n## Coverage\n[How to generate and view coverage reports]\n\\`\\`\\`\n\n### 2. tests/CONTRIBUTING.md\nGuidelines for adding tests:\n- Naming conventions\n- Where to put different types of tests\n- How to use fixtures\n- How to use test utilities\n- How to add logging\n\n### 3. Test Fixture Catalog\nDocument all available fixtures:\n- File location\n- Data format\n- Use cases\n- Example usage\n\n### 4. E2E Test Runner Script\n`tests/e2e/run_all.sh`:\n- Runs all E2E test scripts\n- Aggregates results\n- Generates combined JUnit XML\n- Produces summary report\n\n## Test Categories Documentation\n\n### Unit Tests\n- Pure function tests\n- No I/O, no network\n- Fast (\u003c1s per test)\n- Isolated (no shared state)\n\n### Integration Tests\n- Multiple components\n- Real filesystem (in temp dirs)\n- Mock HTTP servers\n- Medium speed (1-10s per test)\n\n### E2E Tests\n- Full binary execution\n- Real environment\n- Slow (10-60s per test)\n- Requires build\n\n## Environment Variables\nDocument all test-related env vars:\n- `TEST_LOG_LEVEL`\n- `TEST_LOG_DIR`\n- `TEST_KEEP_ARTIFACTS`\n- `CAUT_CONFIG` (override config path)\n- `NO_COLOR` (disable colors)\n\n## Acceptance Criteria\n- [ ] tests/README.md created\n- [ ] tests/CONTRIBUTING.md created\n- [ ] Fixture catalog documented\n- [ ] E2E runner script created\n- [ ] All env vars documented","status":"open","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:56:07.311640857-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:56:07.311640857-05:00"}
{"id":"coding_agent_usage_tracker-9mr","title":"Session: Create 'caut session' CLI command","description":"## Summary\nImplement `caut session` CLI command to display session-level cost attribution and usage analysis.\n\n## Background\nUsers want to understand their costs at the session level, not just aggregate monthly totals. The session command provides:\n1. Today's session costs\n2. Recent session history\n3. Project-level aggregation\n4. Top sessions by cost\n\n## Command Interface\n```\ncaut session [OPTIONS] [COMMAND]\n\nCOMMANDS:\n    today       Show today's sessions (default)\n    list        List recent sessions with costs\n    show        Show detailed session breakdown\n    project     Show costs by project\n\nOPTIONS:\n    -p, --provider \u003cPROVIDER\u003e    Filter by provider\n    -n, --count \u003cN\u003e              Number of sessions to show (default: 10)\n    --since \u003cDATE\u003e               Show sessions since date\n    --format \u003cFORMAT\u003e            Output format: table, json, csv\n```\n\n## Output Formats\n\n### caut session today\n```\nToday's Sessions (3 total)                                    $4.27\n\n  claude-code  ~/.../myproject  2h 15m ago    $2.84  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë\n  claude-code  ~/.../other      45m ago       $1.12  ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\n  codex        ~/.../scripts    20m ago       $0.31  ‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\n\nSession costs calculated from conversation logs.\nConfidence: High (all models recognized)\n```\n\n### caut session list --count=5\n```\nRecent Sessions                                              Provider    Cost\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n2024-01-15 14:30  myproject (2.5h)                          claude     $3.42\n2024-01-15 10:00  other-project (45m)                       claude     $1.15\n2024-01-14 16:00  scripts (1h)                              codex      $0.87\n2024-01-14 09:30  myproject (3h)                            claude     $4.21\n2024-01-13 15:00  testing (30m)                             claude     $0.55\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n                                          5 sessions total:           $10.20\n```\n\n### caut session project\n```\nCost by Project (Last 30 Days)                                    Total\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n~/.../myproject                     15 sessions    42.5h         $45.67\n~/.../other-project                  8 sessions    12.0h         $18.34\n~/.../scripts                        5 sessions     3.5h          $4.21\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n                                    28 sessions    58.0h         $68.22\n```\n\n## Implementation\n```rust\n#[derive(Parser)]\npub struct SessionCommand {\n    #[command(subcommand)]\n    command: Option\u003cSessionSubcommand\u003e,\n    \n    #[arg(short, long)]\n    provider: Option\u003cString\u003e,\n    \n    #[arg(short, long, default_value = \"10\")]\n    count: usize,\n    \n    #[arg(long)]\n    format: Option\u003cOutputFormat\u003e,\n}\n\n#[derive(Subcommand)]\nenum SessionSubcommand {\n    Today,\n    List,\n    Show { session_id: String },\n    Project,\n}\n\nimpl SessionCommand {\n    pub async fn run(\u0026self) -\u003e Result\u003c()\u003e {\n        // 1. Discover and parse session logs\n        let finder = SessionLogFinder::new();\n        let sessions = finder.find_all_sessions()?;\n        \n        // 2. Calculate costs\n        let calculator = SessionCostCalculator::new();\n        let costed: Vec\u003c_\u003e = sessions\n            .iter()\n            .map(|s| (s, calculator.calculate(s)))\n            .collect();\n        \n        // 3. Filter and sort\n        let filtered = self.apply_filters(costed)?;\n        \n        // 4. Render output\n        self.render(\u0026filtered)?;\n        \n        Ok(())\n    }\n}\n```\n\n## Acceptance Criteria\n- [ ] `caut session` shows today's sessions\n- [ ] `caut session list` shows recent sessions with costs\n- [ ] `caut session project` aggregates by project\n- [ ] `caut session show \u003cid\u003e` shows detailed breakdown\n- [ ] Filtering by provider works\n- [ ] Date filtering works\n- [ ] JSON output works\n- [ ] Handles empty session list gracefully\n- [ ] Cost confidence shown when not High\n\n## Dependencies\n- Requires session log parsing\n- Requires cost correlation\n\n## Future Enhancements\n- `caut session compare` to compare session costs\n- Integration with git commits (cost per commit)\n- Session tagging/notes\n","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:12:50.976218711-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:12:50.976218711-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-9mr","depends_on_id":"coding_agent_usage_tracker-kva","type":"blocks","created_at":"2026-01-18T14:21:53.983135147-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-9s0","title":"Config: Init command and config show","description":"## Overview\nImplement `caut config init` to create a starter config file and `caut config show` to display the effective configuration.\n\n## Background \u0026 Rationale\nUsers need easy ways to:\n1. Get started with a config file (not everyone knows TOML syntax)\n2. Debug configuration issues by seeing what settings are active\n3. Understand where settings are coming from (CLI vs env vs file)\n\n## Technical Approach\n\n### 1. Config Init Command\n```bash\n$ caut config init\nCreated config file at: ~/.config/caut/config.toml\n\n# Or with explicit path\n$ caut config init --path /custom/path/config.toml\n```\n\nImplementation:\n```rust\n// In cli/config_cmd.rs\npub async fn init(path: Option\u003cPathBuf\u003e) -\u003e Result\u003c()\u003e {\n    let target = path.unwrap_or_else(|| default_config_path());\n    \n    if target.exists() {\n        return Err(CautError::Config(format\\!(\n            \"Config file already exists: {}. Use --force to overwrite.\",\n            target.display()\n        )));\n    }\n    \n    // Create parent directories\n    if let Some(parent) = target.parent() {\n        fs::create_dir_all(parent)?;\n    }\n    \n    // Write template\n    fs::write(\u0026target, CONFIG_TEMPLATE)?;\n    println\\!(\"Created config file at: {}\", target.display());\n    Ok(())\n}\n\nconst CONFIG_TEMPLATE: \u0026str = r#\"# caut configuration file\n# See: https://github.com/yourrepo/caut#configuration\n\n[defaults]\n# Providers to query by default (comma-separated in CLI: --provider claude,codex)\n# providers = [\"claude\", \"codex\"]\n\n# Default output format: human, json, md\n# format = \"human\"\n\n# Default timeout in seconds\n# timeout_seconds = 10\n\n# Disable colored output\n# no_color = false\n\n[providers.claude]\n# enabled = true\n# priority = 1\n# timeout_seconds = 15\n\n[providers.codex]\n# enabled = true\n# priority = 2\n\n# Add more providers as needed:\n# [providers.gemini]\n# [providers.cursor]\n# [providers.windsurf]\n\"#;\n```\n\n### 2. Config Show Command\n```bash\n$ caut config show\nEffective configuration:\n\nSources:\n  Config file: ~/.config/caut/config.toml\n  Environment: CAUT_FORMAT=json\n\nSettings:\n  providers: [claude, codex] (from: config file)\n  format: json (from: CAUT_FORMAT env var)\n  timeout: 10s (from: default)\n  no_color: false (from: default)\n\nProvider Settings:\n  claude:\n    enabled: true\n    priority: 1\n    timeout: 15s (override)\n  codex:\n    enabled: true\n    priority: 2\n    timeout: 10s (default)\n```\n\nImplementation:\n```rust\npub fn show(cli: \u0026Cli) -\u003e Result\u003c()\u003e {\n    let config = Config::load()?;\n    let resolved = ResolvedConfig::resolve(cli)?;\n    \n    println\\!(\"Effective configuration:\\n\");\n    \n    // Show sources\n    println\\!(\"Sources:\");\n    if let Some(path) = config_path() {\n        println\\!(\"  Config file: {}\", path.display());\n    } else {\n        println\\!(\"  Config file: (none found)\");\n    }\n    \n    // Show active env vars\n    for var in [\"CAUT_FORMAT\", \"CAUT_PROVIDERS\", \"CAUT_TIMEOUT\"] {\n        if let Ok(val) = env::var(var) {\n            println\\!(\"  Environment: {}={}\", var, val);\n        }\n    }\n    \n    println\\!(\"\\nSettings:\");\n    // ... show each setting with source\n    \n    Ok(())\n}\n```\n\n### 3. Config Path Command\n```bash\n$ caut config path\n~/.config/caut/config.toml\n```\n\nSimple utility to show where config would be loaded from.\n\n## Files to Create/Modify\n- `src/cli/config_cmd.rs`: New file for config subcommands\n- `src/cli/args.rs`: Add config subcommand to Commands enum\n- `src/main.rs`: Wire up config commands\n\n## Dependencies\n- Requires core config loading (1n2)\n- Requires precedence system (slz)\n\n## Acceptance Criteria\n- [ ] `caut config init` creates valid starter config\n- [ ] Init fails gracefully if file exists (unless --force)\n- [ ] `caut config show` displays all effective settings\n- [ ] Show indicates source of each setting (cli/env/file/default)\n- [ ] `caut config path` shows config location\n- [ ] Template has helpful comments\n\n## Testing Strategy\n- Test init creates valid TOML\n- Test init with existing file (error)\n- Test init --force overwrites\n- Test show with various config combinations\n- Verify template parses correctly","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:57:22.69998286-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:57:22.69998286-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-9s0","depends_on_id":"coding_agent_usage_tracker-slz","type":"blocks","created_at":"2026-01-18T02:57:28.231572041-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-9ur","title":"Implement Codex CLI fetch - rate limit command parsing","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T01:00:20.329840702-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T01:53:26.932534536-05:00","closed_at":"2026-01-18T01:53:26.932534536-05:00","close_reason":"Implemented JWT extraction from ~/.codex/auth.json for Codex provider. The implementation decodes the JWT id_token to extract: email, plan type (e.g., 'pro'), organization name, and subscription dates. Tested successfully with actual codex CLI - correctly shows Account: email and extracts subscription info."}
{"id":"coding_agent_usage_tracker-a4h","title":"Unit tests for core/cost_scanner.rs (CRITICAL - 13KB)","description":"## Overview\nüö® CRITICAL: cost_scanner.rs is 412 lines with minimal test coverage. This module handles all local cost calculations.\n\n## Target: src/core/cost_scanner.rs (412 lines)\nCritical for: Accurate cost tracking, token counting, daily aggregation\n\n## Test Cases - Organized by Function\n\n### 1. `CostScanner::new()` and `Default::default()`\n- Creates scanner with valid AppPaths\n- Default implementation works\n\n### 2. `scan()` Dispatch\n- Routes Provider::Claude to scan_claude()\n- Routes Provider::Codex to scan_codex()\n- Returns error for unsupported providers\n\n### 3. `scan_claude()` - Claude Stats Cache\n**ClaudeStatsCache parsing:**\n```json\n{\n  \"version\": 1,\n  \"lastComputedDate\": \"2026-01-18\",\n  \"dailyActivity\": [\n    {\"date\": \"2026-01-18\", \"messageCount\": 42, \"sessionCount\": 3, \"toolCallCount\": 15}\n  ]\n}\n```\n\n**Test cases:**\n- Parse valid stats-cache.json with multiple days\n- Missing stats-cache.json ‚Üí empty payload\n- Empty dailyActivity array\n- Filter to last 30 days (cutoff logic)\n- Today detection for session_tokens\n- Sort by date descending\n- Total aggregation (message_count sum)\n- Handle malformed JSON ‚Üí ParseResponse error\n\n### 4. `scan_codex()` - Directory Walking\n**Directory structure:**\n```\n~/.codex/sessions/\n‚îú‚îÄ‚îÄ 2026/\n‚îÇ   ‚îú‚îÄ‚îÄ 01/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 15/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ session_abc.jsonl\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 18/\n‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ session_xyz.jsonl\n```\n\n**Test cases:**\n- Walk year/month/day directory structure\n- Handle missing sessions directory ‚Üí empty payload\n- Handle empty directories at each level\n- Collect .jsonl files only (skip other extensions)\n- Aggregate across multiple session files\n- Also scan history.jsonl in root\n\n### 5. `scan_codex_jsonl()` - JSONL Parsing\n**CodexEvent format:**\n```json\n{\"timestamp\": \"2026-01-18T10:30:00Z\", \"type\": \"message\", \"payload\": {...}}\n```\n\n**Test cases:**\n- Parse valid JSONL lines\n- 100 line limit per file (important!)\n- Skip empty lines\n- Skip malformed JSON lines (graceful failure)\n- Extract date from timestamp first 10 chars\n- Apply cutoff_date filter\n- Aggregate events by date\n\n### 6. `scan_codex_history()` - History File\n**History format:**\n```json\n{\"session_id\": \"xxx\", \"ts\": 1705600000, \"text\": \"...\"}\n```\n\n**Test cases:**\n- Parse history.jsonl\n- Convert Unix timestamp to date\n- Apply cutoff_date filter\n- Handle missing/corrupted file\n- Handle non-existent file\n\n### 7. `empty_cost_payload()`\n- Returns payload with correct provider name\n- Returns \"local\" source\n- Has current timestamp\n- All token/cost fields are None\n- Empty daily array\n\n### 8. Edge Cases\n- Home directory not determinable ‚Üí Config error\n- Clock skew (future dates)\n- Very large token counts (i64 overflow)\n- Unicode in file paths\n- Permission denied on file open\n- Symlinks in directory structure\n\n## Fixture Requirements\n```\ntests/fixtures/cost/\n‚îú‚îÄ‚îÄ claude/\n‚îÇ   ‚îú‚îÄ‚îÄ stats_cache_full.json\n‚îÇ   ‚îú‚îÄ‚îÄ stats_cache_empty.json\n‚îÇ   ‚îú‚îÄ‚îÄ stats_cache_malformed.json\n‚îÇ   ‚îî‚îÄ‚îÄ stats_cache_old_dates.json\n‚îú‚îÄ‚îÄ codex/\n‚îÇ   ‚îú‚îÄ‚îÄ session_valid.jsonl\n‚îÇ   ‚îú‚îÄ‚îÄ session_empty.jsonl\n‚îÇ   ‚îú‚îÄ‚îÄ session_101_lines.jsonl  # Test 100-line limit\n‚îÇ   ‚îú‚îÄ‚îÄ history_valid.jsonl\n‚îÇ   ‚îî‚îÄ‚îÄ history_malformed.jsonl\n```\n\n## Implementation Notes\n- Use tempdir for filesystem tests\n- Mock home directory with test fixtures\n- Test actual date arithmetic (30 day cutoff)\n- Verify sorting is date DESC\n\n## Acceptance Criteria\n- [ ] All public functions tested\n- [ ] ClaudeStatsCache parsing with fixtures\n- [ ] CodexEvent parsing with fixtures\n- [ ] Directory walking logic tested\n- [ ] 100-line limit in scan_codex_jsonl() verified\n- [ ] Date filtering verified (30 day cutoff)\n- [ ] Error handling for all failure modes\n- [ ] Empty payload structure verified","status":"closed","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:50:23.077196164-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:37:50.336455711-05:00","closed_at":"2026-01-18T04:37:50.336455711-05:00","close_reason":"All acceptance criteria verified: 28 unit tests covering CostScanner::new()/default(), scan() dispatch, ClaudeStatsCache parsing (full/empty/malformed), CodexEvent parsing, scan_codex_jsonl() with 100-line limit, scan_codex_history(), date filtering (30 day cutoff), error handling for all failure modes, and empty payload structure. All tests pass.","dependencies":[{"issue_id":"coding_agent_usage_tracker-a4h","depends_on_id":"coding_agent_usage_tracker-32d","type":"blocks","created_at":"2026-01-18T02:53:18.770645188-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-a5q","title":"CI workflow: Integration tests","description":"## Overview\nGitHub Actions workflow for integration test execution.\n\n## File: .github/workflows/integration.yml\n\n## Workflow Steps\n1. **Setup**\n   - Checkout code\n   - Install Rust toolchain\n   - Start mock servers if needed\n\n2. **Run Integration Tests**\n   - cargo test --test '*' --features integration\n   - Separate from unit tests\n   - Longer timeout\n\n3. **Artifacts**\n   - Test logs\n   - Mock server logs\n   - Timing report\n\n## Triggers\n- Push to main\n- Pull requests targeting main\n- Nightly schedule\n\n## Acceptance Criteria\n- [ ] Integration tests isolated\n- [ ] Mock servers managed\n- [ ] Detailed logs available\n- [ ] Failures clearly reported","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:17:41.814923259-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T12:21:10.375871272-05:00","closed_at":"2026-01-18T12:21:10.375871272-05:00","close_reason":"Created .github/workflows/integration.yml with 3 jobs: (1) main integration job running nextest with provider_render_pipeline_test, schema_contract_test, fixtures_test, http_client_test plus E2E tests; (2) mock-server-tests job for wiremock HTTP tests; (3) nightly extended-integration job with coverage. Triggers: push to main, PRs, nightly at 3am UTC, workflow_dispatch. Test artifacts uploaded with 7-14 day retention.","dependencies":[{"issue_id":"coding_agent_usage_tracker-a5q","depends_on_id":"coding_agent_usage_tracker-p8x","type":"blocks","created_at":"2026-01-18T02:18:39.784134758-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-a5q","depends_on_id":"coding_agent_usage_tracker-cqm","type":"blocks","created_at":"2026-01-18T02:18:39.84223905-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-a90","title":"History: Create history CLI command with time range filtering","description":"## Task Overview\n\nImplement the `caut history` command that displays usage history over configurable time periods with filtering and formatting options.\n\n## Parent EPIC\n[EPIC] Historical Usage Tracking with Trend Visualization (coding_agent_usage_tracker-smv)\n\n## Command Design\n\n```bash\n$ caut history --help\nDisplay usage history over time\n\nUsage: caut history [OPTIONS]\n\nOptions:\n  -p, --provider \u003cPROVIDER\u003e  Filter to specific provider\n  -d, --days \u003cDAYS\u003e          Show last N days [default: 7]\n      --from \u003cDATE\u003e          Start date (YYYY-MM-DD)\n      --to \u003cDATE\u003e            End date (YYYY-MM-DD)\n  -f, --format \u003cFORMAT\u003e      Output format: table, chart, json, csv [default: chart]\n      --stats                Show summary statistics\n  -h, --help                 Print help\n```\n\n## Output Formats\n\n### Chart Format (Default)\n```\n$ caut history --days 7\nClaude Usage (Last 7 Days)\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nMon 01/13: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 78%  $12.34\nTue 01/14: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 62%  $9.87\nWed 01/15: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 91%  $15.23  ‚Üê Hit limit\nThu 01/16: ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 41%  $7.45\nFri 01/17: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 65%  $11.20\nSat 01/18: ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 23%  $4.56\nSun 01/19: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 52%  $8.90\n\nAverage: 59%  |  Trend: ‚Üò -8% vs previous week\nTotal Cost: $69.55  |  Peak: Wednesday\n```\n\n### Table Format\n```\n$ caut history --format table --days 3\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Date       ‚îÇ Provider ‚îÇ Primary % ‚îÇ Secondary ‚îÇ Cost     ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ 2026-01-17 ‚îÇ claude   ‚îÇ 65.0%     ‚îÇ 42.0%     ‚îÇ $11.20   ‚îÇ\n‚îÇ 2026-01-17 ‚îÇ codex    ‚îÇ 34.0%     ‚îÇ -         ‚îÇ $3.45    ‚îÇ\n‚îÇ 2026-01-16 ‚îÇ claude   ‚îÇ 41.0%     ‚îÇ 38.0%     ‚îÇ $7.45    ‚îÇ\n‚îÇ ...        ‚îÇ ...      ‚îÇ ...       ‚îÇ ...       ‚îÇ ...      ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n### JSON Format\n```\n$ caut history --format json --days 1\n{\n  \"period\": {\"from\": \"2026-01-18\", \"to\": \"2026-01-18\"},\n  \"snapshots\": [\n    {\n      \"provider\": \"claude\",\n      \"fetched_at\": \"2026-01-18T12:34:56Z\",\n      \"primary_used_pct\": 65.0,\n      \"secondary_used_pct\": 42.0,\n      \"cost_today_usd\": 11.20\n    }\n  ],\n  \"stats\": {\n    \"average_primary_pct\": 65.0,\n    \"total_cost\": 11.20\n  }\n}\n```\n\n### CSV Format\n```\n$ caut history --format csv --days 7 \u003e usage.csv\n```\n\n## Implementation\n\n```rust\n// src/cli/history.rs\n\n#[derive(Parser)]\npub struct HistoryCommand {\n    #[arg(short, long)]\n    provider: Option\u003cProvider\u003e,\n    \n    #[arg(short, long, default_value = \"7\")]\n    days: u32,\n    \n    #[arg(long)]\n    from: Option\u003cNaiveDate\u003e,\n    \n    #[arg(long)]\n    to: Option\u003cNaiveDate\u003e,\n    \n    #[arg(short, long, default_value = \"chart\")]\n    format: OutputFormat,\n    \n    #[arg(long)]\n    stats: bool,\n}\n\nimpl HistoryCommand {\n    pub async fn run(\u0026self, config: \u0026Config) -\u003e Result\u003c()\u003e {\n        let store = HistoryStore::open(\u0026config.history_path())?;\n        \n        let (from, to) = self.resolve_time_range();\n        let snapshots = store.get_snapshots(self.provider.as_ref(), from, to)?;\n        \n        match self.format {\n            OutputFormat::Chart =\u003e render_chart(\u0026snapshots),\n            OutputFormat::Table =\u003e render_table(\u0026snapshots),\n            OutputFormat::Json =\u003e render_json(\u0026snapshots),\n            OutputFormat::Csv =\u003e render_csv(\u0026snapshots),\n        }\n    }\n}\n```\n\n## Statistics Calculation\n\nWhen `--stats` flag is used or in chart mode:\n\n```rust\nstruct HistoryStats {\n    average_primary_pct: f64,\n    max_primary_pct: f64,\n    min_primary_pct: f64,\n    trend_vs_previous: f64,  // % change vs same period before\n    total_cost: f64,\n    peak_day: NaiveDate,\n    sample_count: usize,\n}\n```\n\n## Deliverables\n\n- [ ] `caut history` command implementation\n- [ ] Chart format renderer with ASCII bars\n- [ ] Table format renderer\n- [ ] JSON format output\n- [ ] CSV format output\n- [ ] Statistics calculation\n- [ ] Time range resolution logic\n- [ ] Provider filtering\n- [ ] Unit and integration tests\n\n## Acceptance Criteria\n\n- [ ] Command works with default options\n- [ ] All format options produce valid output\n- [ ] Time range filtering works correctly\n- [ ] Provider filtering works correctly\n- [ ] Statistics are accurate\n- [ ] No data shows appropriate message\n- [ ] Help text is clear and complete","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:08:12.62706557-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:08:12.62706557-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-a90","depends_on_id":"coding_agent_usage_tracker-hws","type":"blocks","created_at":"2026-01-18T14:21:40.611833193-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-ajd","title":"Implement Claude OAuth fetch - core rate limit API integration","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T01:00:18.778554465-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T01:36:10.089439016-05:00","closed_at":"2026-01-18T01:36:10.089439016-05:00","close_reason":"Already implemented - fetch_oauth() exists in src/providers/claude/mod.rs line 212, wired up in pipeline.rs"}
{"id":"coding_agent_usage_tracker-att","title":"Unit tests for storage/state.rs (state persistence)","description":"## Overview\nTest the state file read/write operations for persisted data.\n\n## Target: src/storage/state.rs\nCritical for: Caching, session persistence, cost tracking\n\n## Test Cases\n1. **State File Operations**\n   - Create new state file\n   - Read existing state\n   - Update state atomically\n   - Handle missing state gracefully\n\n2. **Serialization**\n   - JSON round-trip for all state types\n   - Version migration if applicable\n   - Corrupted file handling\n\n3. **Concurrency**\n   - File locking behavior\n   - Race condition handling\n   - Atomic write (temp file + rename)\n\n4. **Cleanup**\n   - Old state pruning\n   - State file size limits\n\n## Acceptance Criteria\n- [ ] CRUD operations tested\n- [ ] Atomic writes verified\n- [ ] Corruption recovery tested\n- [ ] Temp directory isolation for tests","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:12:47.978942651-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:53:11.275522963-05:00","closed_at":"2026-01-18T02:53:11.275522963-05:00","close_reason":"File src/storage/state.rs does not exist - bead created in error","dependencies":[{"issue_id":"coding_agent_usage_tracker-att","depends_on_id":"coding_agent_usage_tracker-u5h","type":"blocks","created_at":"2026-01-18T02:18:17.894318549-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-ayc","title":"[EPIC] Doctor Command - Comprehensive Diagnostic System","description":"## Overview\n\nImplement a `caut doctor` command that provides comprehensive diagnostics for the entire caut setup, helping users understand what's working, what's broken, and exactly how to fix issues.\n\n## Strategic Rationale\n\nThis is the #1 priority improvement for caut because:\n\n1. **Solves the biggest pain point**: New users struggle with 'why isn't this working?' Each provider has different auth flows, CLI names, and config locations. Doctor surfaces all of this clearly.\n\n2. **Self-service troubleshooting**: Instead of filing issues or asking for help, users run `caut doctor` and know exactly what to fix.\n\n3. **Builds trust**: Green checkmarks and precise diagnostics make users trust the tool. Clear fix suggestions empower rather than frustrate.\n\n4. **Foundational**: Once we have provider health checks, we can show status indicators in other commands, skip unavailable providers automatically, and make smart suggestions everywhere.\n\n## User Experience Goal\n\n```\n$ caut doctor\n\nChecking caut installation...\n‚úì caut v0.1.0 (a999778)\n‚úì Configuration loaded from ~/.config/caut/config.toml\n\nChecking providers...\n\nClaude:\n  ‚úì CLI installed: claude v1.0.30\n  ‚úì Authenticated: user@example.com\n  ‚úì API reachable: 142ms\n  \nCodex:\n  ‚úì CLI installed: codex-cli v0.87.0  \n  ‚úì Authenticated: user@example.com (Pro plan)\n  ‚úì API reachable: 89ms\n\nSummary: 2 providers ready, 0 need attention\n```\n\n## Success Criteria\n\n- `caut doctor` runs without errors on fresh install\n- Shows clear status for each provider\n- Provides actionable fix suggestions for every failure type\n- Completes in \u003c5 seconds (parallel checks)\n- Works on Linux, macOS, Windows","status":"closed","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:47:24.999406492-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T05:09:12.121561989-05:00","closed_at":"2026-01-18T05:09:12.121561989-05:00","close_reason":"Doctor command fully implemented: Core diagnostic framework, provider health checks, output rendering (human/JSON/MD), and CLI integration all complete. caut doctor works with parallel provider checks, actionable fix suggestions, and multiple output formats. All 108 tests pass.","dependencies":[{"issue_id":"coding_agent_usage_tracker-ayc","depends_on_id":"coding_agent_usage_tracker-4yc","type":"blocks","created_at":"2026-01-18T02:48:13.49854779-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-ayc","depends_on_id":"coding_agent_usage_tracker-0a0","type":"blocks","created_at":"2026-01-18T02:48:45.32174045-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-ayc","depends_on_id":"coding_agent_usage_tracker-453","type":"blocks","created_at":"2026-01-18T02:49:14.84903029-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-ayc","depends_on_id":"coding_agent_usage_tracker-cek","type":"blocks","created_at":"2026-01-18T02:49:50.869136105-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-b14","title":"Parallel: Per-provider timeout handling","description":"## Overview\nImplement configurable per-provider timeouts with sensible defaults that prevent one slow provider from blocking the entire command.\n\n## Background \u0026 Rationale\nDifferent providers have different response characteristics:\n- CLI commands (like `claude`) may take 2-5 seconds\n- Web scraping may be slow due to rendering\n- API calls are typically fast but can stall\n- PTY operations can hang indefinitely\n\nWithout per-provider timeouts, one stalled provider blocks everything. With parallel fetch, we need individual timeouts so fast providers return quickly even if a slow one is timing out.\n\n## Technical Approach\n\n### 1. Provider Timeout Configuration\n```rust\n// In core/fetch_plan.rs or new core/timeouts.rs\nimpl Provider {\n    pub fn default_timeout(\u0026self) -\u003e Duration {\n        match self {\n            Provider::Claude =\u003e Duration::from_secs(10),\n            Provider::Codex =\u003e Duration::from_secs(10),\n            Provider::Gemini =\u003e Duration::from_secs(15),  // API can be slower\n            Provider::Cursor =\u003e Duration::from_secs(8),\n            Provider::Windsurf =\u003e Duration::from_secs(8),\n        }\n    }\n}\n```\n\n### 2. Timeout Wrapper\n```rust\nasync fn fetch_with_timeout(\n    provider: Provider,\n    strategy: \u0026FetchStrategy,\n    timeout: Duration,\n) -\u003e Result\u003cProviderPayload\u003e {\n    tokio::time::timeout(timeout, execute_fetch(provider, strategy))\n        .await\n        .map_err(|_| CautError::Timeout(timeout.as_secs()))?\n}\n```\n\n### 3. Global vs Per-Provider\n- Default: use provider-specific defaults\n- CLI flag `--timeout \u003csecs\u003e` overrides ALL providers\n- Future: config file can set per-provider values\n\n### 4. Timeout Behavior\n- On timeout, provider is marked as failed (graceful degradation)\n- Error message indicates timeout vs other failures\n- Consider: retry once with shorter timeout? (probably overkill)\n\n## Files to Modify\n- `src/core/http.rs`: Already has DEFAULT_TIMEOUT, extend pattern\n- `src/core/cli_runner.rs`: Already has CLI_TIMEOUT\n- `src/core/pipeline.rs`: Add timeout wrapping to fetch calls\n- `src/cli/args.rs`: Add --timeout flag\n\n## Dependencies  \n- Should be done after graceful degradation (jt0) since timeouts trigger failures\n- Parallel fetch refactor (d30) must be complete\n\n## Acceptance Criteria\n- [ ] Each provider has sensible default timeout\n- [ ] Slow provider times out without blocking fast ones\n- [ ] Timeout errors are distinct from network errors\n- [ ] --timeout flag overrides all defaults\n- [ ] Timeout shows remaining providers results (graceful degradation)\n\n## Testing Strategy\n- Mock provider with artificial delay exceeding timeout\n- Verify fast providers complete while slow one times out\n- Test --timeout flag override\n- Verify error messages indicate timeout specifically","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:53:46.952917114-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:53:46.952917114-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-b14","depends_on_id":"coding_agent_usage_tracker-jt0","type":"blocks","created_at":"2026-01-18T02:54:45.858951424-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-b9i","title":"Session: Implement session log discovery and parsing","description":"## Summary\nImplement parsing of Claude Code and Codex CLI session log files to extract per-session usage data.\n\n## Background\nBoth Claude Code and Codex CLI maintain session logs that contain valuable usage information:\n- Claude Code: `~/.claude/projects/*/conversations/*.jsonl`\n- Codex CLI: `~/.codex/sessions/*.jsonl`\n\nBy parsing these logs, we can attribute costs to specific coding sessions rather than just aggregate monthly totals.\n\n## Technical Design\n\n### Session Log Discovery\n```rust\npub struct SessionLogFinder {\n    claude_base: PathBuf,  // ~/.claude\n    codex_base: PathBuf,   // ~/.codex\n}\n\nimpl SessionLogFinder {\n    /// Find all session logs for a provider\n    pub fn find_sessions(\u0026self, provider: \u0026str) -\u003e Vec\u003cSessionLogPath\u003e {\n        match provider {\n            \"claude\" =\u003e self.find_claude_sessions(),\n            \"codex\" =\u003e self.find_codex_sessions(),\n            _ =\u003e Vec::new(),\n        }\n    }\n    \n    fn find_claude_sessions(\u0026self) -\u003e Vec\u003cSessionLogPath\u003e {\n        // Glob: ~/.claude/projects/*/conversations/*.jsonl\n        // Filter by date range\n        // Sort by modification time\n    }\n}\n```\n\n### Claude Code Log Parsing\n```rust\npub struct ClaudeSessionParser;\n\nimpl ClaudeSessionParser {\n    /// Parse a Claude Code JSONL session file\n    pub fn parse(\u0026self, path: \u0026Path) -\u003e Result\u003cSessionUsage\u003e {\n        let mut usage = SessionUsage::default();\n        \n        for line in BufReader::new(File::open(path)?).lines() {\n            let entry: serde_json::Value = serde_json::from_str(\u0026line?)?;\n            \n            // Extract token counts from different message types\n            if let Some(usage_data) = entry.get(\"usage\") {\n                usage.input_tokens += usage_data[\"input_tokens\"].as_i64().unwrap_or(0);\n                usage.output_tokens += usage_data[\"output_tokens\"].as_i64().unwrap_or(0);\n                usage.cache_read_tokens += usage_data[\"cache_read_input_tokens\"].as_i64().unwrap_or(0);\n            }\n            \n            // Track model used\n            if let Some(model) = entry.get(\"model\").and_then(|m| m.as_str()) {\n                usage.models_used.insert(model.to_string());\n            }\n        }\n        \n        Ok(usage)\n    }\n}\n```\n\n### Codex CLI Log Parsing\n```rust\npub struct CodexSessionParser;\n\nimpl CodexSessionParser {\n    /// Parse a Codex CLI JSONL session file\n    pub fn parse(\u0026self, path: \u0026Path) -\u003e Result\u003cSessionUsage\u003e {\n        // Similar structure but different JSON format\n        // Codex logs may include cost directly\n    }\n}\n```\n\n### Session Usage Model\n```rust\n#[derive(Debug, Default)]\npub struct SessionUsage {\n    pub session_id: String,\n    pub project_path: Option\u003cPathBuf\u003e,\n    pub started_at: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    pub ended_at: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    pub input_tokens: i64,\n    pub output_tokens: i64,\n    pub cache_read_tokens: i64,\n    pub cache_creation_tokens: i64,\n    pub models_used: HashSet\u003cString\u003e,\n    pub message_count: i32,\n}\n```\n\n## Acceptance Criteria\n- [ ] Discover Claude Code session logs correctly\n- [ ] Discover Codex CLI session logs correctly\n- [ ] Parse Claude Code JSONL format accurately\n- [ ] Parse Codex CLI JSONL format accurately\n- [ ] Handle malformed/partial log files gracefully\n- [ ] Extract token counts for all token types\n- [ ] Track models used per session\n- [ ] Unit tests with fixture log files\n\n## Test Fixtures Needed\n- Claude Code session log (various message types)\n- Codex CLI session log\n- Malformed log file (partial writes, corruption)\n- Empty session log\n\n## Dependencies\n- None (foundational for session attribution)\n- Will be used by cost correlation task\n\n## Implementation Notes\n- Use streaming JSON parsing for large files\n- Consider mmap for very large session files\n- Cache parsed results to avoid re-parsing\n- Handle log rotation/cleanup gracefully\n","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:12:08.308157887-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:12:08.308157887-05:00"}
{"id":"coding_agent_usage_tracker-bgy","title":"Parallel: Progress indication during fetch","description":"## Overview\nAdd progress indication during parallel fetch operations so users know the tool is working and can see which providers are being queried.\n\n## Background \u0026 Rationale\nWhen fetching from multiple providers in parallel, there is a noticeable delay (2-15 seconds). Without feedback, users might think the tool is hung. Progress indication improves perceived performance and provides transparency about what is happening.\n\n## Technical Approach\n\n### 1. Progress Model\n```rust\npub struct FetchProgress {\n    pub providers: Vec\u003cProviderProgress\u003e,\n    pub started_at: Instant,\n}\n\npub struct ProviderProgress {\n    pub provider: Provider,\n    pub status: FetchStatus,\n    pub strategy: Option\u003cString\u003e,\n    pub started_at: Option\u003cInstant\u003e,\n    pub completed_at: Option\u003cInstant\u003e,\n}\n\npub enum FetchStatus {\n    Pending,\n    InProgress,\n    Succeeded,\n    Failed(String),\n    Skipped,\n}\n```\n\n### 2. Terminal Output (TTY mode)\nUsing rich_rust spinners and status indicators:\n```\nFetching usage data...\n  ‚óè Claude    [oauth]     ‚úì done (0.8s)\n  ‚óè Codex     [cli-pty]   ‚†ã fetching...\n  ‚óè Gemini    [api]       ‚úì done (1.2s)\n```\n\n### 3. Non-TTY Mode\nWhen piped or redirected, use simple line-based output:\n```\n[claude] fetching via oauth...\n[claude] done (0.8s)\n[codex] fetching via cli-pty...\n```\n\n### 4. JSON Mode\nProgress output should be suppressed in --json mode (only final results).\nOptionally: --json-progress for streaming NDJSON progress updates.\n\n### 5. Implementation Pattern\n```rust\n// In core/pipeline.rs\nasync fn fetch_with_progress(\n    providers: \u0026[Provider],\n    progress_tx: Option\u003cmpsc::Sender\u003cProgressUpdate\u003e\u003e,\n) -\u003e FetchResults {\n    // Send progress updates during fetch\n    // UI layer receives and renders them\n}\n```\n\n### 6. UI Layer (render/progress.rs)\n- New module for progress rendering\n- Use rich_rust spinners for animated feedback\n- Respect --no-color and TTY detection\n- Clean up spinner line before printing results\n\n## Files to Modify\n- `src/render/progress.rs`: New file for progress UI\n- `src/core/pipeline.rs`: Add progress emission\n- `src/cli/usage.rs`: Wire up progress display\n- `src/util/env.rs`: TTY detection helpers\n\n## Dependencies\n- Parallel fetch refactor (d30) must be complete\n- Nice to have after graceful degradation (jt0) for status updates\n\n## Acceptance Criteria\n- [ ] TTY mode shows animated progress with spinners\n- [ ] Non-TTY mode shows simple text updates\n- [ ] JSON mode suppresses progress (clean output)\n- [ ] Each provider shows current strategy being tried\n- [ ] Completion times shown for each provider\n- [ ] Progress cleans up before final output renders\n\n## Testing Strategy\n- Manual testing with TTY vs piped output\n- Verify JSON output is not polluted with progress\n- Test with slow/fast providers to see timing\n- Verify spinner cleanup (no leftover artifacts)\n\n## Priority Note\nThis is P2 (medium) as it is a UX polish feature. The core parallel fetch functionality should work without it.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:54:38.479451196-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:54:38.479451196-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-bgy","depends_on_id":"coding_agent_usage_tracker-d30","type":"blocks","created_at":"2026-01-18T02:54:46.062178314-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-bkz","title":"Offline: Implement cache layer with TTL and staleness tracking","description":"## Summary\nImplement a caching layer that stores fetch results with TTL for offline availability.\n\n## Background\nWhen network is unavailable or providers are down, caut should:\n1. Return cached data with staleness indicator\n2. Not fail or hang\n3. Keep working with whatever data is available\n4. Update cache when network returns\n\n## Technical Design\n\n### Cache Storage\n```rust\nuse std::path::PathBuf;\n\npub struct OfflineCache {\n    cache_dir: PathBuf,\n    default_ttl: Duration,\n}\n\nimpl OfflineCache {\n    pub fn new() -\u003e Self {\n        let cache_dir = dirs::cache_dir()\n            .unwrap_or_else(|| PathBuf::from(\".\"))\n            .join(\"caut\");\n        \n        fs::create_dir_all(\u0026cache_dir).ok();\n        \n        Self {\n            cache_dir,\n            default_ttl: Duration::from_secs(3600), // 1 hour\n        }\n    }\n    \n    fn cache_path(\u0026self, provider: \u0026str) -\u003e PathBuf {\n        self.cache_dir.join(format!(\"{}.json\", provider))\n    }\n}\n```\n\n### Cache Entry\n```rust\n#[derive(Debug, Serialize, Deserialize)]\npub struct CacheEntry {\n    pub payload: ProviderPayload,\n    pub cached_at: DateTime\u003cUtc\u003e,\n    pub ttl_seconds: u64,\n    pub source: CacheSource,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub enum CacheSource {\n    NetworkFetch,      // From actual provider API\n    CliOutput,         // Parsed from CLI output\n    Estimated,         // Calculated/estimated values\n}\n\nimpl CacheEntry {\n    pub fn is_fresh(\u0026self) -\u003e bool {\n        let age = Utc::now() - self.cached_at;\n        age.num_seconds() \u003c self.ttl_seconds as i64\n    }\n    \n    pub fn is_stale(\u0026self) -\u003e bool {\n        !self.is_fresh() \u0026\u0026 !self.is_very_stale()\n    }\n    \n    pub fn is_very_stale(\u0026self) -\u003e bool {\n        let age = Utc::now() - self.cached_at;\n        age.num_seconds() \u003e (self.ttl_seconds * 4) as i64  // 4x TTL\n    }\n    \n    pub fn age(\u0026self) -\u003e Duration {\n        let age = Utc::now() - self.cached_at;\n        Duration::from_secs(age.num_seconds().max(0) as u64)\n    }\n    \n    pub fn staleness(\u0026self) -\u003e Staleness {\n        if self.is_fresh() {\n            Staleness::Fresh\n        } else if self.is_stale() {\n            Staleness::Stale { age: self.age() }\n        } else {\n            Staleness::VeryStale { age: self.age() }\n        }\n    }\n}\n\n#[derive(Debug)]\npub enum Staleness {\n    Fresh,\n    Stale { age: Duration },\n    VeryStale { age: Duration },\n}\n```\n\n### Cache Operations\n```rust\nimpl OfflineCache {\n    /// Read from cache\n    pub fn get(\u0026self, provider: \u0026str) -\u003e Option\u003cCacheEntry\u003e {\n        let path = self.cache_path(provider);\n        \n        let content = fs::read_to_string(\u0026path).ok()?;\n        let entry: CacheEntry = serde_json::from_str(\u0026content).ok()?;\n        \n        Some(entry)\n    }\n    \n    /// Write to cache\n    pub fn set(\u0026self, provider: \u0026str, payload: \u0026ProviderPayload) -\u003e Result\u003c()\u003e {\n        let entry = CacheEntry {\n            payload: payload.clone(),\n            cached_at: Utc::now(),\n            ttl_seconds: self.default_ttl.as_secs(),\n            source: CacheSource::NetworkFetch,\n        };\n        \n        let path = self.cache_path(provider);\n        let content = serde_json::to_string_pretty(\u0026entry)?;\n        \n        // Atomic write\n        let tmp_path = path.with_extension(\"tmp\");\n        fs::write(\u0026tmp_path, content)?;\n        fs::rename(\u0026tmp_path, \u0026path)?;\n        \n        Ok(())\n    }\n    \n    /// Get all cached providers\n    pub fn list_cached(\u0026self) -\u003e Vec\u003cString\u003e {\n        fs::read_dir(\u0026self.cache_dir)\n            .ok()\n            .into_iter()\n            .flatten()\n            .filter_map(|e| e.ok())\n            .filter(|e| e.path().extension() == Some(\"json\".as_ref()))\n            .filter_map(|e| {\n                e.path()\n                    .file_stem()\n                    .and_then(|s| s.to_str())\n                    .map(String::from)\n            })\n            .collect()\n    }\n    \n    /// Clear cache for a provider\n    pub fn clear(\u0026self, provider: \u0026str) -\u003e Result\u003c()\u003e {\n        let path = self.cache_path(provider);\n        if path.exists() {\n            fs::remove_file(path)?;\n        }\n        Ok(())\n    }\n    \n    /// Clear all cache\n    pub fn clear_all(\u0026self) -\u003e Result\u003c()\u003e {\n        for provider in self.list_cached() {\n            self.clear(\u0026provider)?;\n        }\n        Ok(())\n    }\n}\n```\n\n### TTL Configuration\n```toml\n# ~/.config/caut/config.toml\n[cache]\ndefault_ttl_seconds = 3600\nstale_threshold_multiplier = 2.0\nvery_stale_threshold_multiplier = 4.0\n\n[cache.providers]\nclaude = { ttl_seconds = 1800 }   # 30 min for Claude\ncodex = { ttl_seconds = 3600 }    # 1 hour for Codex\n```\n\n## Acceptance Criteria\n- [ ] Cache stores provider payloads correctly\n- [ ] Atomic writes prevent corruption\n- [ ] TTL expiration works correctly\n- [ ] Staleness levels calculated correctly\n- [ ] Cache directory created automatically\n- [ ] List/clear operations work\n- [ ] Per-provider TTL configuration works\n- [ ] Unit tests for all cache operations\n\n## Cache Location\n- Linux: `~/.cache/caut/`\n- macOS: `~/Library/Caches/caut/`\n- Windows: `%LOCALAPPDATA%\\caut\\cache\\`\n\n## Dependencies\n- None (foundational for offline mode)\n- Used by fallback logic task\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:18:39.737560579-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:18:39.737560579-05:00"}
{"id":"coding_agent_usage_tracker-bmz","title":"Budget: Implement budget configuration system","description":"## Summary\nImplement configuration system for usage and cost budgets with daily, weekly, and monthly limits.\n\n## Background\nUsers want to set spending limits to avoid unexpected bills. The budget system should:\n1. Support multiple budget types (usage %, cost $)\n2. Support multiple time windows (daily, weekly, monthly)\n3. Be configurable per provider or globally\n4. Persist across sessions\n\n## Technical Design\n\n### Budget Configuration Schema\n```toml\n# ~/.config/caut/budgets.toml\n\n[global]\ndaily_cost_usd = 10.0\nweekly_cost_usd = 50.0\nmonthly_cost_usd = 150.0\n\n[providers.claude]\ndaily_usage_percent = 80\nweekly_cost_usd = 30.0\nalert_at_percent = [50, 75, 90]\n\n[providers.codex]\nmonthly_cost_usd = 50.0\ndaily_credits = 5.0\n```\n\n### Budget Configuration Types\n```rust\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct BudgetConfig {\n    pub global: Option\u003cGlobalBudget\u003e,\n    pub providers: HashMap\u003cString, ProviderBudget\u003e,\n}\n\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct GlobalBudget {\n    pub daily_cost_usd: Option\u003cf64\u003e,\n    pub weekly_cost_usd: Option\u003cf64\u003e,\n    pub monthly_cost_usd: Option\u003cf64\u003e,\n}\n\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct ProviderBudget {\n    pub daily_usage_percent: Option\u003cf64\u003e,\n    pub weekly_usage_percent: Option\u003cf64\u003e,\n    pub daily_cost_usd: Option\u003cf64\u003e,\n    pub weekly_cost_usd: Option\u003cf64\u003e,\n    pub monthly_cost_usd: Option\u003cf64\u003e,\n    pub daily_credits: Option\u003cf64\u003e,\n    pub alert_at_percent: Option\u003cVec\u003cu8\u003e\u003e,\n}\n\nimpl BudgetConfig {\n    /// Load from config file\n    pub fn load() -\u003e Result\u003cSelf\u003e {\n        let path = config_dir().join(\"caut/budgets.toml\");\n        if path.exists() {\n            let content = fs::read_to_string(\u0026path)?;\n            Ok(toml::from_str(\u0026content)?)\n        } else {\n            Ok(Self::default())\n        }\n    }\n    \n    /// Get effective budget for a provider\n    pub fn for_provider(\u0026self, provider: \u0026str) -\u003e EffectiveBudget {\n        let provider_budget = self.providers.get(provider);\n        EffectiveBudget::merge(\u0026self.global, provider_budget)\n    }\n}\n```\n\n### Budget CLI Commands\n```\ncaut budget [COMMAND]\n\nCOMMANDS:\n    show        Show current budget configuration\n    set         Set a budget limit\n    clear       Remove a budget limit\n    init        Create default budget configuration\n```\n\n### Budget Set Examples\n```bash\n# Set global daily cost limit\ncaut budget set --daily-cost 10\n\n# Set provider-specific limit\ncaut budget set --provider claude --monthly-cost 50\n\n# Set usage percentage alert thresholds\ncaut budget set --provider claude --alert-at 50,75,90\n\n# Clear a budget\ncaut budget clear --provider codex --monthly-cost\n```\n\n## Implementation\n```rust\n#[derive(Parser)]\npub struct BudgetCommand {\n    #[command(subcommand)]\n    command: BudgetSubcommand,\n}\n\n#[derive(Subcommand)]\nenum BudgetSubcommand {\n    Show,\n    Set {\n        #[arg(long)]\n        provider: Option\u003cString\u003e,\n        #[arg(long)]\n        daily_cost: Option\u003cf64\u003e,\n        #[arg(long)]\n        weekly_cost: Option\u003cf64\u003e,\n        #[arg(long)]\n        monthly_cost: Option\u003cf64\u003e,\n        #[arg(long)]\n        daily_usage: Option\u003cf64\u003e,\n        #[arg(long)]\n        alert_at: Option\u003cString\u003e,\n    },\n    Clear {\n        #[arg(long)]\n        provider: Option\u003cString\u003e,\n        #[arg(long)]\n        all: bool,\n    },\n    Init,\n}\n```\n\n## Acceptance Criteria\n- [ ] Budget config file parses correctly\n- [ ] Global budgets work\n- [ ] Provider-specific budgets override global\n- [ ] `caut budget show` displays current config\n- [ ] `caut budget set` modifies config\n- [ ] `caut budget clear` removes limits\n- [ ] `caut budget init` creates default config\n- [ ] Config changes persist across sessions\n- [ ] Invalid config produces helpful errors\n\n## Default Configuration\n```toml\n# Created by 'caut budget init'\n# Customize your usage budgets\n\n# [global]\n# daily_cost_usd = 10.0\n# monthly_cost_usd = 100.0\n\n# [providers.claude]\n# alert_at_percent = [50, 75, 90]\n```\n\n## Dependencies\n- None (foundational for budget system)\n- Used by budget checking task\n","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:14:07.665596407-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:14:07.665596407-05:00"}
{"id":"coding_agent_usage_tracker-bzh","title":"Implement cost command - local JSONL log scanning","status":"closed","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T01:00:21.212309727-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T01:13:21.601554887-05:00","closed_at":"2026-01-18T01:13:21.601554887-05:00","close_reason":"Duplicate of coding_agent_usage_tracker-4a2, already implemented"}
{"id":"coding_agent_usage_tracker-bzy","title":"Status: Enhance StatusFetcher with caching layer","description":"Extend existing StatusFetcher in src/core/status.rs with caching layer using CachedStatus struct that tracks payload, fetched_at, ttl. Implement is_fresh(), is_stale(), age() methods. Create CachedStatusFetcher wrapper with fetch(), fetch_fresh(), and get_cached() methods. Thread-safe via Arc\u003cRwLock\u003e. Debug logging for cache hits/misses.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:15:02.642544295-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:15:02.642544295-05:00"}
{"id":"coding_agent_usage_tracker-c6i","title":"Offline: Implement staleness display formatting","description":"Create src/render/staleness.rs. format_staleness() converts Duration to 'just now', '5 mins ago', '2 hours ago', '1 day ago'. format_cache_badge() shows [cached X ago] yellow or [stale: X ago] red. format_offline_banner() shows header when all data from cache. Update render_usage_human_with_cache() to show badges. Include cache metadata in JSON.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:15:23.446602366-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:15:23.446602366-05:00"}
{"id":"coding_agent_usage_tracker-cbn","title":"[EPIC] Actionable Error Messages with Fix Suggestions","description":"## Overview\nTransform cryptic error messages into actionable guidance with specific fix suggestions and recovery commands.\n\n## Background \u0026 Rationale\n\n### The Problem\nCurrent error messages tell users WHAT went wrong but not HOW to fix it:\n```\nError: Authentication failed for provider: claude\nError: Network timeout\nError: Config file parse error at line 15\n```\n\nUsers (especially AI agents) are left guessing what to do next.\n\n### The Solution\nActionable errors that include specific next steps:\n```\nError: Authentication expired for Claude\n\nüí° How to fix:\n   1. Run: caut auth refresh claude\n   2. If that fails, re-authenticate: caut auth login claude\n   \n‚ÑπÔ∏è Context: Your OAuth token expired 2 hours ago. Claude tokens\n   are valid for 24 hours. Consider using `caut usage --watch`\n   to monitor session health.\n```\n\n### Why This Matters\n1. **Faster resolution**: Users know exactly what to do\n2. **AI-friendly**: Agents can parse and execute fix commands\n3. **Self-service**: Reduces need for documentation lookups\n4. **Better UX**: Errors become teaching moments\n\n### Error Categories to Enhance\n1. **Authentication**: Expired tokens, missing credentials, wrong permissions\n2. **Network**: Timeouts, DNS failures, SSL issues\n3. **Configuration**: Parse errors, invalid values, missing files\n4. **Provider-specific**: Rate limits, service unavailable, API errors\n5. **Environment**: Missing CLI tools, wrong OS, permission issues\n\n## Key Features\n1. **Fix commands**: Copy-paste commands to resolve issue\n2. **Context**: Explain why the error occurred\n3. **Prevention**: Tips to avoid the error in future\n4. **Machine-readable**: JSON includes structured fix information\n\n## Subtasks\n1. Error taxonomy and structured error types\n2. Fix suggestion database\n3. Error rendering with suggestions\n4. Machine-readable error format\n\n## Success Metrics\n- Every common error has at least one fix suggestion\n- Fix commands are copy-paste ready\n- AI agents can parse and execute suggestions\n- Documentation cross-references where appropriate","status":"open","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T03:00:14.622899573-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T03:00:14.622899573-05:00"}
{"id":"coding_agent_usage_tracker-cek","title":"Doctor: CLI subcommand integration","description":"## Purpose\n\nAdd the `doctor` subcommand to the caut CLI, wiring up the diagnostic framework to be user-accessible.\n\n## Background\n\nThe doctor command should be:\n1. Discoverable via `caut --help`\n2. Support common flags: --json, --no-color, --provider (filter)\n3. Have sensible defaults that check all providers\n4. Return appropriate exit codes for scripting\n\n## Implementation Details\n\n### Update src/cli/args.rs\n\n```rust\n#[derive(Subcommand)]\npub enum Commands {\n    /// Show usage for providers\n    Usage(UsageArgs),\n    /// Show local cost usage  \n    Cost(CostArgs),\n    /// Manage token accounts\n    TokenAccounts(TokenAccountsCommand),\n    /// Diagnose caut setup and provider health\n    Doctor(DoctorArgs),\n}\n\n#[derive(Args)]\npub struct DoctorArgs {\n    /// Only check specific provider(s)\n    #[arg(short, long)]\n    pub provider: Option\u003cVec\u003cString\u003e\u003e,\n    \n    /// Output as JSON for scripting\n    #[arg(long)]\n    pub json: bool,\n    \n    /// Disable colored output\n    #[arg(long)]\n    pub no_color: bool,\n    \n    /// Run checks in verbose mode\n    #[arg(short, long)]\n    pub verbose: bool,\n    \n    /// Timeout for each provider check in seconds\n    #[arg(long, default_value = \"5\")]\n    pub timeout: u64,\n}\n```\n\n### New file: src/cli/doctor.rs\n\n```rust\nuse crate::cli::args::DoctorArgs;\nuse crate::core::doctor::{run_doctor_checks, DoctorReport};\nuse crate::render::doctor::render_doctor_report;\nuse crate::error::Result;\n\npub async fn execute(args: \u0026DoctorArgs, no_color: bool) -\u003e Result\u003c()\u003e {\n    let providers = parse_provider_filter(\u0026args.provider)?;\n    let timeout = Duration::from_secs(args.timeout);\n    \n    let report = run_doctor_checks(providers, timeout).await?;\n    \n    if args.json {\n        let json = serde_json::to_string_pretty(\u0026report)?;\n        println!(\"{}\", json);\n    } else {\n        let output = render_doctor_report(\u0026report, no_color);\n        print!(\"{}\", output);\n    }\n    \n    // Exit code: 0 if all ready, 1 if any need attention\n    let (ready, needs_attention) = report.summary();\n    if needs_attention \u003e 0 {\n        std::process::exit(1);\n    }\n    \n    Ok(())\n}\n```\n\n### Update src/main.rs\n\n```rust\nSome(Commands::Doctor(args)) =\u003e {\n    caut::cli::doctor::execute(\u0026args, no_color).await\n}\n```\n\n## Exit Codes\n\n- 0: All providers are ready\n- 1: One or more providers need attention\n- 2: Doctor command itself failed (e.g., couldn't run checks)\n\nThis allows scripting like:\n```bash\nif caut doctor --json \u003e /dev/null 2\u003e\u00261; then\n    echo \"All providers ready\"\nelse\n    echo \"Some providers need attention\"\nfi\n```\n\n## Testing Strategy\n\n- Integration tests running actual doctor command\n- Test exit codes for various scenarios\n- Test --json output is valid JSON\n- Test --provider filtering works\n\n## Acceptance Criteria\n\n- [ ] `caut doctor` runs and shows output\n- [ ] `caut doctor --help` shows usage\n- [ ] `caut doctor --json` outputs valid JSON\n- [ ] `caut doctor --provider claude` filters to one provider\n- [ ] Exit codes are correct (0 for healthy, 1 for issues)\n- [ ] Verbose mode shows additional details","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:49:43.226190629-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T05:08:56.974381624-05:00","closed_at":"2026-01-18T05:08:56.974381624-05:00","close_reason":"Doctor CLI integration complete: Added DoctorArgs to args.rs, created cli/doctor.rs module, updated main.rs command dispatch, added doctor to quickstart help. All 108 tests pass. Binary builds correctly and doctor command works in human, JSON, and MD formats.","dependencies":[{"issue_id":"coding_agent_usage_tracker-cek","depends_on_id":"coding_agent_usage_tracker-4yc","type":"blocks","created_at":"2026-01-18T02:49:50.692239071-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-cek","depends_on_id":"coding_agent_usage_tracker-0a0","type":"blocks","created_at":"2026-01-18T02:49:50.749652735-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-cek","depends_on_id":"coding_agent_usage_tracker-453","type":"blocks","created_at":"2026-01-18T02:49:50.806682307-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-cmr","title":"Complete Codex provider implementation","description":"Codex provider needs: web dashboard scraping (macOS cookies), improved CLI RPC response parsing. Currently the web strategy returns a stub error.","status":"closed","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T00:47:01.526561119-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T01:13:42.882460195-05:00","closed_at":"2026-01-18T01:13:42.882460195-05:00","close_reason":"Closed"}
{"id":"coding_agent_usage_tracker-cn8","title":"E2E test script: caut usage command scenarios","description":"## Overview\nEnd-to-end test suite for the usage command with comprehensive logging.\n\n## Dual Implementation Strategy\nCreate BOTH shell scripts and Rust integration tests for maximum coverage:\n1. **Shell scripts** (`tests/e2e/test_usage.sh`) - CI-friendly, quick iteration\n2. **Rust tests** (`tests/e2e_usage.rs`) - Programmatic, precise assertions\n\n## Shell Script: tests/e2e/test_usage.sh\n\n### Test Scenarios\n```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\n# Logging setup\nLOG_DIR=\"${TEST_LOG_DIR:-./test-logs}\"\nLOG_FILE=\"$LOG_DIR/test_usage_$(date +%Y%m%d_%H%M%S).log\"\nJUNIT_FILE=\"$LOG_DIR/test_usage.xml\"\nmkdir -p \"$LOG_DIR\"\n\nlog() { echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $*\" | tee -a \"$LOG_FILE\"; }\nlog_section() { log \"========== $* ==========\"; }\n\n# Test 1: Basic Invocation\nlog_section \"TEST: Basic usage command\"\nSTART_TIME=$(date +%s.%N)\nif OUTPUT=$(caut usage 2\u003e\u00261); then\n    log \"PASS: Exit code 0\"\n    log \"OUTPUT: $OUTPUT\"\nelse\n    log \"FAIL: Non-zero exit code\"\nfi\nEND_TIME=$(date +%s.%N)\nlog \"Duration: $(echo \"$END_TIME - $START_TIME\" | bc)s\"\n\n# Test 2: Provider Filtering  \nlog_section \"TEST: Provider filtering\"\nOUTPUT=$(caut usage --provider=claude 2\u003e\u00261) || true\nif echo \"$OUTPUT\" | grep -qi \"claude\"; then\n    log \"PASS: Claude provider found\"\nelse\n    log \"WARN: Claude output not found\"\nfi\n\n# Test 3: JSON Output\nlog_section \"TEST: JSON output mode\"\nOUTPUT=$(caut usage --json 2\u003e\u00261)\nif echo \"$OUTPUT\" | jq . \u003e/dev/null 2\u003e\u00261; then\n    log \"PASS: Valid JSON output\"\n    # Verify schema\n    SCHEMA_VERSION=$(echo \"$OUTPUT\" | jq -r '.schemaVersion // empty')\n    log \"Schema version: $SCHEMA_VERSION\"\nelse\n    log \"FAIL: Invalid JSON\"\nfi\n\n# Test 4: No Color Mode\nlog_section \"TEST: No-color mode\"\nOUTPUT=$(caut usage --no-color 2\u003e\u00261)\nif echo \"$OUTPUT\" | grep -qE '\\x1b\\['; then\n    log \"FAIL: ANSI codes found in no-color mode\"\nelse\n    log \"PASS: No ANSI codes\"\nfi\n\n# Test 5: Verbose Mode\nlog_section \"TEST: Verbose mode\"\nOUTPUT=$(caut usage --verbose 2\u003e\u00261)\nif echo \"$OUTPUT\" | grep -qiE 'debug|trace|verbose'; then\n    log \"PASS: Verbose output present\"\nelse\n    log \"INFO: No obvious debug markers (may be OK)\"\nfi\n\n# Generate JUnit XML\ncat \u003e \"$JUNIT_FILE\" \u003c\u003c JUNIT_EOF\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e\n\u003ctestsuite name=\"caut_usage_e2e\" tests=\"5\" failures=\"0\"\u003e\n  \u003c!-- Generated by test_usage.sh --\u003e\n\u003c/testsuite\u003e\nJUNIT_EOF\n\nlog \"Test log saved to: $LOG_FILE\"\nlog \"JUnit XML saved to: $JUNIT_FILE\"\n```\n\n## Rust Tests: tests/e2e_usage.rs\n\n```rust\nuse assert_cmd::Command;\nuse predicates::prelude::*;\n\n#[test]\nfn test_usage_basic() {\n    let mut cmd = Command::cargo_bin(\"caut\").unwrap();\n    cmd.arg(\"usage\")\n        .assert()\n        .success()\n        .stdout(predicate::str::contains(\"Claude\").or(predicate::str::contains(\"Codex\")));\n}\n\n#[test]\nfn test_usage_json_valid() {\n    let mut cmd = Command::cargo_bin(\"caut\").unwrap();\n    let output = cmd.arg(\"usage\").arg(\"--json\").output().unwrap();\n    \n    // Parse JSON\n    let json: serde_json::Value = serde_json::from_slice(\u0026output.stdout)\n        .expect(\"Output should be valid JSON\");\n    \n    // Verify schema\n    assert!(json.get(\"schemaVersion\").is_some());\n    assert!(json.get(\"data\").is_some());\n}\n\n#[test]\nfn test_usage_no_color() {\n    let mut cmd = Command::cargo_bin(\"caut\").unwrap();\n    cmd.arg(\"usage\").arg(\"--no-color\")\n        .assert()\n        .success()\n        .stdout(predicate::str::contains(\"\\x1b[\").not());\n}\n```\n\n## Logging Specification\n\n### Log Format\n```\n[YYYY-MM-DD HH:MM:SS.mmm] [LEVEL] [TEST_NAME] message\n```\n\n### Log Levels\n- `INFO`: Test start/end, basic operations\n- `DEBUG`: Command output, intermediate values\n- `WARN`: Unexpected but non-fatal conditions\n- `ERROR`: Test failures\n- `TRACE`: Full request/response bodies\n\n### Log File Structure\n```\ntest-logs/\n‚îú‚îÄ‚îÄ test_usage_20260118_143022.log     # Timestamped run log\n‚îú‚îÄ‚îÄ test_usage_latest.log              # Symlink to latest\n‚îú‚îÄ‚îÄ test_usage.xml                     # JUnit XML for CI\n‚îî‚îÄ‚îÄ artifacts/                         # Output captures\n    ‚îú‚îÄ‚îÄ usage_basic_stdout.txt\n    ‚îú‚îÄ‚îÄ usage_json_output.json\n    ‚îî‚îÄ‚îÄ usage_error_stderr.txt\n```\n\n### Environment Variables\n- `TEST_LOG_LEVEL` - Log verbosity (info, debug, trace)\n- `TEST_LOG_DIR` - Output directory (default: ./test-logs)\n- `TEST_KEEP_ARTIFACTS` - Don't cleanup temp files\n- `CI` - Running in CI (adjusts output format)\n\n## Acceptance Criteria\n- [ ] Shell script with 5+ scenarios\n- [ ] Rust tests with assert_cmd\n- [ ] Comprehensive logging to file\n- [ ] JUnit XML output for CI\n- [ ] All scenarios documented with expected outcomes\n- [ ] Environment variable configuration\n- [ ] Artifacts preserved on failure","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:16:13.584905545-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T11:33:39.942663312-05:00","closed_at":"2026-01-18T11:33:39.942663312-05:00","close_reason":"Completed: Created both shell script (tests/e2e/test_usage.sh - 15 scenarios) and Rust tests (tests/e2e_usage_test.rs - 22 tests). Added assert_cmd and predicates dependencies. All Rust E2E tests pass (42 total including common module tests). Shell script functional with logging, JUnit XML output, artifact preservation.","dependencies":[{"issue_id":"coding_agent_usage_tracker-cn8","depends_on_id":"coding_agent_usage_tracker-p8x","type":"blocks","created_at":"2026-01-18T02:18:32.742534958-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-cqm","title":"CI workflow: Unit tests with coverage reporting","description":"## Overview\nGitHub Actions workflow for unit test execution with coverage.\n\n## File: .github/workflows/test.yml\n\n## Workflow Steps\n1. **Setup**\n   - Checkout code\n   - Install Rust toolchain\n   - Cache cargo dependencies\n\n2. **Build**\n   - cargo build --all-features\n   - Capture build time\n\n3. **Test**\n   - cargo test --all-features\n   - With coverage (cargo-tarpaulin or llvm-cov)\n   - Capture test results\n\n4. **Report**\n   - Generate coverage report\n   - Upload to codecov/coveralls\n   - Fail if coverage \u003c threshold\n\n## Triggers\n- Push to main\n- Pull requests\n- Manual dispatch\n\n## Artifacts\n- Test results (JUnit XML)\n- Coverage report (HTML + LCOV)\n- Build logs\n\n## Acceptance Criteria\n- [ ] Workflow runs successfully\n- [ ] Coverage reported\n- [ ] Threshold enforced\n- [ ] Results visible in PRs","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:17:24.97863844-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T11:04:15.580827298-05:00","closed_at":"2026-01-18T11:04:15.580827298-05:00","close_reason":"Created .github/workflows/test.yml with 3 jobs: Unit Tests (cargo-llvm-cov coverage, codecov upload), Clippy, Format. Note: rich_rust local path dependency requires resolution for CI to run in GH","dependencies":[{"issue_id":"coding_agent_usage_tracker-cqm","depends_on_id":"coding_agent_usage_tracker-8gp","type":"blocks","created_at":"2026-01-18T02:18:39.673633844-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-cqm","depends_on_id":"coding_agent_usage_tracker-2k1","type":"blocks","created_at":"2026-01-18T02:18:39.72987696-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-cr9","title":"Budget: Implement precedence resolution for conflicts","description":"Create src/core/budgets.rs. BudgetPriority enum: Global(0), ProviderDefault(1), ProviderSpecific(2), Override(3). BudgetConfig with provider, priority, limits. ResolvedBudget with provider and BudgetSources tracking where each value came from. resolve_budget() merges configs by priority (highest wins, first non-None). Alert threshold takes most conservative value. check_budget_violations() returns violations. TOML config format: [global], [claude], [claude.override].","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:16:09.290345834-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:16:09.290345834-05:00"}
{"id":"coding_agent_usage_tracker-d30","title":"Parallel: Refactor fetch orchestration to use join_all","description":"## Purpose\n\nRefactor the provider fetch loop to run all providers concurrently using `futures::future::join_all` instead of sequential awaits.\n\n## Background\n\nCurrently, the usage command fetches providers sequentially:\n```rust\n// Current (sequential)\nfor provider in providers {\n    let result = fetch_provider(provider).await;\n    results.push(result);\n}\n```\n\nThis should become:\n```rust\n// New (parallel)\nlet futures: Vec\u003c_\u003e = providers.iter()\n    .map(|p| fetch_provider_with_timeout(*p, timeout))\n    .collect();\nlet results = futures::future::join_all(futures).await;\n```\n\n## Implementation Details\n\n### Locate current fetch loop\n\nThe main fetch logic is in src/cli/usage.rs and uses the fetch plan system. We need to:\n\n1. Find where providers are iterated\n2. Convert to parallel execution\n3. Handle the timeout per-provider\n\n### Add timeout wrapper\n\n```rust\nuse tokio::time::{timeout, Duration};\n\nasync fn fetch_provider_with_timeout(\n    provider: Provider,\n    timeout_duration: Duration,\n) -\u003e (Provider, Result\u003cProviderPayload\u003e) {\n    let result = timeout(timeout_duration, fetch_provider(provider)).await;\n    \n    match result {\n        Ok(inner) =\u003e (provider, inner),\n        Err(_) =\u003e (provider, Err(CautError::Timeout(timeout_duration.as_secs()))),\n    }\n}\n```\n\n### Update orchestration\n\n```rust\npub async fn fetch_all_providers(\n    providers: \u0026[Provider],\n    timeout_secs: u64,\n) -\u003e FetchResults {\n    let timeout = Duration::from_secs(timeout_secs);\n    \n    let futures: Vec\u003c_\u003e = providers.iter()\n        .map(|\u0026p| fetch_provider_with_timeout(p, timeout))\n        .collect();\n    \n    let all_results = futures::future::join_all(futures).await;\n    \n    // Separate successes and failures\n    let mut successes = Vec::new();\n    let mut failures = Vec::new();\n    \n    for (provider, result) in all_results {\n        match result {\n            Ok(payload) =\u003e successes.push(payload),\n            Err(e) =\u003e failures.push((provider, e)),\n        }\n    }\n    \n    FetchResults { successes, failures }\n}\n```\n\n## Testing Strategy\n\n- Unit test that parallel fetch is faster than sequential (mock providers with sleep)\n- Integration test with real providers\n- Test timeout handling\n\n## Acceptance Criteria\n\n- [ ] All provider fetches run concurrently\n- [ ] Each provider has its own timeout\n- [ ] Total time is ~max(individual times) not sum(individual times)\n- [ ] No race conditions or data races\n- [ ] Existing tests still pass","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:50:47.019010874-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:10:48.438920703-05:00","closed_at":"2026-01-18T04:10:48.438920703-05:00","close_reason":"Completed"}
{"id":"coding_agent_usage_tracker-d3a","title":"TUI: Design component architecture with ratatui","description":"# TUI Dashboard Implementation Tasks\n\n## Task 1: Design TUI Component Architecture\n**ID**: TUI-ARCH\n\n### Summary\nDesign and implement the foundational TUI architecture using ratatui, including the main App struct, event loop, and component trait system.\n\n### Description\nBuild the core TUI infrastructure that all dashboard components will use.\n\n```rust\n// src/tui/mod.rs\nuse crossterm::event::{self, Event, KeyCode, KeyModifiers};\nuse ratatui::{\n    backend::CrosstermBackend,\n    Terminal,\n    Frame,\n};\nuse std::io::Stdout;\nuse std::time::Duration;\n\npub mod app;\npub mod components;\npub mod layout;\npub mod event_handler;\n\n/// Main TUI application state\npub struct DashboardApp {\n    providers: Vec\u003cProviderState\u003e,\n    history_data: HashMap\u003cString, Vec\u003cf64\u003e\u003e,\n    focused_panel: Panel,\n    selected_index: usize,\n    show_help: bool,\n    should_quit: bool,\n    needs_redraw: bool,\n    last_refresh: Option\u003cDateTime\u003cUtc\u003e\u003e,\n}\n\n#[derive(Clone, Copy, PartialEq, Eq)]\npub enum Panel {\n    Providers,\n    History,\n    Status,\n    Help,\n}\n\n/// Component trait for all renderable widgets\npub trait Component {\n    fn render(\u0026self, frame: \u0026mut Frame, area: Rect);\n    fn handle_key(\u0026mut self, key: KeyCode, modifiers: KeyModifiers) -\u003e bool;\n    fn focusable(\u0026self) -\u003e bool { true }\n}\n\n/// Run the TUI application\npub async fn run(config: \u0026Config) -\u003e Result\u003c()\u003e {\n    // Setup terminal\n    crossterm::terminal::enable_raw_mode()?;\n    let mut stdout = std::io::stdout();\n    crossterm::execute!(stdout, EnterAlternateScreen, EnableMouseCapture)?;\n    let backend = CrosstermBackend::new(stdout);\n    let mut terminal = Terminal::new(backend)?;\n\n    // Create app and run event loop\n    let mut app = DashboardApp::new(config).await?;\n    let result = app.run(\u0026mut terminal).await;\n\n    // Restore terminal\n    crossterm::terminal::disable_raw_mode()?;\n    crossterm::execute!(\n        terminal.backend_mut(),\n        LeaveAlternateScreen,\n        DisableMouseCapture\n    )?;\n\n    result\n}\n```\n\n### Acceptance Criteria\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:13:06.680267984-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:13:06.680267984-05:00"}
{"id":"coding_agent_usage_tracker-d9u","title":"Budget: Implement budget checking and threshold tracking","description":"## Summary\nImplement real-time budget checking against configured limits with threshold tracking.\n\n## Background\nWith budget configuration in place, we need to:\n1. Check current usage/costs against limits\n2. Track which alert thresholds have been triggered\n3. Avoid duplicate alerts for the same threshold\n4. Calculate percentage of budget consumed\n\n## Technical Design\n\n### Budget Checker\n```rust\npub struct BudgetChecker {\n    config: BudgetConfig,\n    history: HistoryStore,\n    alert_tracker: AlertTracker,\n}\n\nimpl BudgetChecker {\n    /// Check all budgets for a provider\n    pub fn check(\u0026self, provider: \u0026str, current: \u0026ProviderPayload) -\u003e BudgetStatus {\n        let budget = self.config.for_provider(provider);\n        let mut violations = Vec::new();\n        let mut warnings = Vec::new();\n        \n        // Check usage percentage limits\n        if let Some(daily_limit) = budget.daily_usage_percent {\n            if let Some(usage) = current.usage.primary.as_ref() {\n                let status = self.check_usage_limit(\n                    usage.used_percent,\n                    daily_limit,\n                    \"daily usage\",\n                );\n                self.categorize(status, \u0026mut violations, \u0026mut warnings);\n            }\n        }\n        \n        // Check cost limits (requires history)\n        if let Some(daily_cost_limit) = budget.daily_cost_usd {\n            let today_cost = self.history.get_daily_cost(provider)?;\n            let status = self.check_cost_limit(\n                today_cost,\n                daily_cost_limit,\n                \"daily cost\",\n            );\n            self.categorize(status, \u0026mut violations, \u0026mut warnings);\n        }\n        \n        // Check alert thresholds\n        if let Some(thresholds) = \u0026budget.alert_at_percent {\n            for \u0026threshold in thresholds {\n                if let Some(usage) = current.usage.primary.as_ref() {\n                    if usage.used_percent \u003e= threshold as f64 \n                       \u0026\u0026 !self.alert_tracker.was_triggered(provider, threshold) {\n                        warnings.push(BudgetWarning::ThresholdReached {\n                            threshold,\n                            current: usage.used_percent,\n                        });\n                        self.alert_tracker.mark_triggered(provider, threshold)?;\n                    }\n                }\n            }\n        }\n        \n        BudgetStatus {\n            provider: provider.to_string(),\n            violations,\n            warnings,\n            overall: if !violations.is_empty() {\n                BudgetHealth::Exceeded\n            } else if !warnings.is_empty() {\n                BudgetHealth::Warning\n            } else {\n                BudgetHealth::Ok\n            },\n        }\n    }\n}\n```\n\n### Alert Tracker (Deduplication)\n```rust\npub struct AlertTracker {\n    db: SqliteConnection,\n}\n\nimpl AlertTracker {\n    /// Check if threshold was already triggered this period\n    pub fn was_triggered(\u0026self, provider: \u0026str, threshold: u8) -\u003e bool {\n        let period_start = self.current_period_start();\n        sqlx::query_scalar!(\n            \"SELECT 1 FROM alert_triggers \n             WHERE provider = ? AND threshold = ? AND triggered_at \u003e= ?\",\n            provider, threshold, period_start\n        ).fetch_optional(\u0026self.db).ok().flatten().is_some()\n    }\n    \n    /// Mark threshold as triggered\n    pub fn mark_triggered(\u0026self, provider: \u0026str, threshold: u8) -\u003e Result\u003c()\u003e {\n        sqlx::query!(\n            \"INSERT INTO alert_triggers (provider, threshold, triggered_at)\n             VALUES (?, ?, ?)\",\n            provider, threshold, Utc::now()\n        ).execute(\u0026self.db)?;\n        Ok(())\n    }\n    \n    /// Reset triggers for new period\n    pub fn reset_period(\u0026self, provider: \u0026str) -\u003e Result\u003c()\u003e {\n        let period_start = self.current_period_start();\n        sqlx::query!(\n            \"DELETE FROM alert_triggers WHERE provider = ? AND triggered_at \u003c ?\",\n            provider, period_start\n        ).execute(\u0026self.db)?;\n        Ok(())\n    }\n}\n```\n\n### Budget Status Types\n```rust\n#[derive(Debug)]\npub struct BudgetStatus {\n    pub provider: String,\n    pub violations: Vec\u003cBudgetViolation\u003e,\n    pub warnings: Vec\u003cBudgetWarning\u003e,\n    pub overall: BudgetHealth,\n}\n\n#[derive(Debug)]\npub enum BudgetViolation {\n    DailyUsageExceeded { limit: f64, current: f64 },\n    DailyCostExceeded { limit: f64, current: f64 },\n    WeeklyCostExceeded { limit: f64, current: f64 },\n    MonthlyCostExceeded { limit: f64, current: f64 },\n}\n\n#[derive(Debug)]\npub enum BudgetWarning {\n    ThresholdReached { threshold: u8, current: f64 },\n    ApproachingLimit { limit_type: String, percent_used: f64 },\n}\n\n#[derive(Debug)]\npub enum BudgetHealth {\n    Ok,\n    Warning,\n    Exceeded,\n}\n```\n\n## Acceptance Criteria\n- [ ] Usage percentage limits checked correctly\n- [ ] Cost limits checked against history\n- [ ] Alert thresholds trigger correctly\n- [ ] Duplicate alerts prevented within period\n- [ ] Period resets work (daily/weekly/monthly)\n- [ ] Budget status includes all relevant info\n- [ ] Unit tests for all check scenarios\n\n## Edge Cases\n- No history data: skip cost checks, warn user\n- Partial data: check what we can, note limitations\n- Multiple violations: report all, not just first\n- Threshold order: process in ascending order\n\n## Dependencies\n- Requires budget configuration (sibling task)\n- Requires history storage (EPIC 1) for cost checks\n- Used by alert system\n\n## Database Schema\n```sql\nCREATE TABLE alert_triggers (\n    id INTEGER PRIMARY KEY,\n    provider TEXT NOT NULL,\n    threshold INTEGER NOT NULL,\n    triggered_at TEXT NOT NULL\n);\nCREATE INDEX idx_triggers_provider ON alert_triggers(provider, triggered_at);\n```\n","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:14:30.130434158-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:14:30.130434158-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-d9u","depends_on_id":"coding_agent_usage_tracker-bmz","type":"blocks","created_at":"2026-01-18T14:22:03.402822488-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-d9u","depends_on_id":"coding_agent_usage_tracker-hws","type":"blocks","created_at":"2026-01-18T14:22:03.452279062-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-dbt","title":"Status: Test suite for fetching, parsing, and caching","description":"## Summary\nImplement comprehensive test suite for Provider Health Status including status page fetching, incident detection, caching, and multi-provider aggregation.\n\n## Parent EPIC\n[EPIC] Provider Health Status (coding_agent_usage_tracker-kod)\n\n## Test Categories\n\n### 1. Unit Tests: Status Page Parsing\n```rust\n#[cfg(test)]\nmod parsing_tests {\n    use crate::status::{StatusPageParser, StatusIndicator};\n    use crate::test_fixtures::load_fixture_text;\n\n    #[test]\n    fn test_parse_statuspage_operational() {\n        let html = load_fixture_text(\"status/statuspage_operational.html\");\n        let parser = StatusPageParser::statuspage_io();\n\n        let status = parser.parse(\u0026html).unwrap();\n\n        assert_eq!(status.indicator, StatusIndicator::None);\n        assert!(status.description.unwrap().contains(\"Operational\"));\n    }\n\n    #[test]\n    fn test_parse_statuspage_minor_incident() {\n        let html = load_fixture_text(\"status/statuspage_minor.html\");\n        let parser = StatusPageParser::statuspage_io();\n\n        let status = parser.parse(\u0026html).unwrap();\n\n        assert_eq!(status.indicator, StatusIndicator::Minor);\n        assert!(status.active_incidents.len() \u003e 0);\n    }\n\n    #[test]\n    fn test_parse_statuspage_major_outage() {\n        let html = load_fixture_text(\"status/statuspage_major.html\");\n        let parser = StatusPageParser::statuspage_io();\n\n        let status = parser.parse(\u0026html).unwrap();\n\n        assert_eq!(status.indicator, StatusIndicator::Major);\n    }\n\n    #[test]\n    fn test_parse_statuspage_maintenance() {\n        let html = load_fixture_text(\"status/statuspage_maintenance.html\");\n        let parser = StatusPageParser::statuspage_io();\n\n        let status = parser.parse(\u0026html).unwrap();\n\n        assert_eq!(status.indicator, StatusIndicator::Maintenance);\n        assert!(status.scheduled_maintenances.len() \u003e 0);\n    }\n\n    #[test]\n    fn test_parse_json_api_response() {\n        let json = load_fixture_text(\"status/api_response.json\");\n        let parser = StatusPageParser::json_api();\n\n        let status = parser.parse(\u0026json).unwrap();\n\n        assert!(status.indicator != StatusIndicator::Unknown);\n    }\n\n    #[test]\n    fn test_parse_invalid_html_graceful() {\n        let parser = StatusPageParser::statuspage_io();\n\n        let result = parser.parse(\"\u003chtml\u003e\u003cbody\u003eNot a status page\u003c/body\u003e\u003c/html\u003e\");\n\n        // Should return Unknown, not error\n        assert!(result.is_ok());\n        assert_eq!(result.unwrap().indicator, StatusIndicator::Unknown);\n    }\n}\n```\n\n### 2. Unit Tests: Status Fetching\n```rust\n#[cfg(test)]\nmod fetching_tests {\n    use mockito::Server;\n\n    #[tokio::test]\n    async fn test_fetch_status_success() {\n        let mut server = Server::new_async().await;\n        let mock = server.mock(\"GET\", \"/api/v2/status.json\")\n            .with_status(200)\n            .with_body(r#\"{\"status\":{\"indicator\":\"none\",\"description\":\"All Systems Operational\"}}\"#)\n            .create_async().await;\n\n        let fetcher = StatusFetcher::new();\n        let status = fetcher.fetch(\u0026server.url()).await.unwrap();\n\n        assert_eq!(status.indicator, StatusIndicator::None);\n        mock.assert_async().await;\n    }\n\n    #[tokio::test]\n    async fn test_fetch_status_timeout() {\n        let mut server = Server::new_async().await;\n        let _mock = server.mock(\"GET\", \"/status\")\n            .with_status(200)\n            .with_body_from_fn(|_| {\n                std::thread::sleep(std::time::Duration::from_secs(10));\n                Ok(vec![])\n            })\n            .create_async().await;\n\n        let fetcher = StatusFetcher::new()\n            .with_timeout(Duration::from_millis(100));\n\n        let result = fetcher.fetch(\u0026server.url()).await;\n\n        assert!(matches!(result, Err(StatusError::Timeout)));\n    }\n\n    #[tokio::test]\n    async fn test_fetch_status_not_found() {\n        let mut server = Server::new_async().await;\n        let mock = server.mock(\"GET\", \"/status\")\n            .with_status(404)\n            .create_async().await;\n\n        let fetcher = StatusFetcher::new();\n        let result = fetcher.fetch(\u0026format!(\"{}/status\", server.url())).await;\n\n        assert!(matches!(result, Err(StatusError::NotFound)));\n        mock.assert_async().await;\n    }\n\n    #[tokio::test]\n    async fn test_fetch_with_retry() {\n        let mut server = Server::new_async().await;\n\n        // First two requests fail, third succeeds\n        let fail_mock = server.mock(\"GET\", \"/status\")\n            .with_status(503)\n            .expect(2)\n            .create_async().await;\n\n        let success_mock = server.mock(\"GET\", \"/status\")\n            .with_status(200)\n            .with_body(r#\"{\"status\":{\"indicator\":\"none\"}}\"#)\n            .create_async().await;\n\n        let fetcher = StatusFetcher::new()\n            .with_retries(3);\n\n        let result = fetcher.fetch(\u0026format!(\"{}/status\", server.url())).await;\n\n        assert!(result.is_ok());\n        fail_mock.assert_async().await;\n        success_mock.assert_async().await;\n    }\n}\n```\n\n### 3. Unit Tests: Status Caching\n```rust\n#[cfg(test)]\nmod caching_tests {\n    #[test]\n    fn test_cache_hit() {\n        let cache = StatusCache::new(Duration::from_secs(300));\n\n        let status = StatusPayload {\n            indicator: StatusIndicator::None,\n            description: Some(\"All Operational\".to_string()),\n            updated_at: Some(Utc::now()),\n            url: \"https://status.example.com\".to_string(),\n        };\n\n        cache.set(\"claude\", status.clone());\n\n        let cached = cache.get(\"claude\");\n        assert!(cached.is_some());\n        assert_eq!(cached.unwrap().indicator, StatusIndicator::None);\n    }\n\n    #[test]\n    fn test_cache_expiry() {\n        let cache = StatusCache::new(Duration::from_millis(50));\n\n        let status = StatusPayload {\n            indicator: StatusIndicator::None,\n            description: Some(\"Operational\".to_string()),\n            updated_at: Some(Utc::now()),\n            url: \"https://status.example.com\".to_string(),\n        };\n\n        cache.set(\"claude\", status);\n\n        // Wait for expiry\n        std::thread::sleep(Duration::from_millis(100));\n\n        let cached = cache.get(\"claude\");\n        assert!(cached.is_none());\n    }\n\n    #[test]\n    fn test_cache_staleness_indicator() {\n        let cache = StatusCache::new(Duration::from_secs(300))\n            .with_stale_threshold(Duration::from_millis(50));\n\n        let status = mock_status(StatusIndicator::None);\n        cache.set(\"claude\", status);\n\n        // Initially fresh\n        assert!(!cache.is_stale(\"claude\"));\n\n        std::thread::sleep(Duration::from_millis(100));\n\n        // Now stale but not expired\n        assert!(cache.is_stale(\"claude\"));\n        assert!(cache.get(\"claude\").is_some()); // Still returns data\n    }\n\n    #[test]\n    fn test_cache_per_provider() {\n        let cache = StatusCache::new(Duration::from_secs(300));\n\n        cache.set(\"claude\", mock_status(StatusIndicator::None));\n        cache.set(\"codex\", mock_status(StatusIndicator::Minor));\n\n        assert_eq!(cache.get(\"claude\").unwrap().indicator, StatusIndicator::None);\n        assert_eq!(cache.get(\"codex\").unwrap().indicator, StatusIndicator::Minor);\n    }\n}\n```\n\n### 4. Unit Tests: Multi-Provider Aggregation\n```rust\n#[cfg(test)]\nmod aggregation_tests {\n    #[test]\n    fn test_aggregate_all_operational() {\n        let statuses = vec![\n            (\"claude\", mock_status(StatusIndicator::None)),\n            (\"codex\", mock_status(StatusIndicator::None)),\n            (\"openai\", mock_status(StatusIndicator::None)),\n        ];\n\n        let aggregate = StatusAggregator::aggregate(\u0026statuses);\n\n        assert_eq!(aggregate.overall, StatusIndicator::None);\n        assert_eq!(aggregate.operational_count, 3);\n    }\n\n    #[test]\n    fn test_aggregate_mixed_status() {\n        let statuses = vec![\n            (\"claude\", mock_status(StatusIndicator::None)),\n            (\"codex\", mock_status(StatusIndicator::Minor)),\n            (\"openai\", mock_status(StatusIndicator::None)),\n        ];\n\n        let aggregate = StatusAggregator::aggregate(\u0026statuses);\n\n        // Overall should reflect worst status\n        assert_eq!(aggregate.overall, StatusIndicator::Minor);\n        assert_eq!(aggregate.operational_count, 2);\n        assert!(aggregate.issues.iter().any(|i| i.provider == \"codex\"));\n    }\n\n    #[test]\n    fn test_aggregate_severity_ordering() {\n        // Test that Critical \u003e Major \u003e Minor \u003e Maintenance \u003e None\n        let statuses = vec![\n            (\"a\", mock_status(StatusIndicator::None)),\n            (\"b\", mock_status(StatusIndicator::Minor)),\n            (\"c\", mock_status(StatusIndicator::Major)),\n        ];\n\n        let aggregate = StatusAggregator::aggregate(\u0026statuses);\n        assert_eq!(aggregate.overall, StatusIndicator::Major);\n\n        let statuses_with_critical = vec![\n            (\"a\", mock_status(StatusIndicator::Major)),\n            (\"b\", mock_status(StatusIndicator::Critical)),\n        ];\n\n        let aggregate = StatusAggregator::aggregate(\u0026statuses_with_critical);\n        assert_eq!(aggregate.overall, StatusIndicator::Critical);\n    }\n\n    #[test]\n    fn test_aggregate_with_unknown() {\n        let statuses = vec![\n            (\"claude\", mock_status(StatusIndicator::None)),\n            (\"codex\", mock_status(StatusIndicator::Unknown)),\n        ];\n\n        let aggregate = StatusAggregator::aggregate(\u0026statuses);\n\n        // Unknown should be flagged but not treated as outage\n        assert!(aggregate.unknown_count == 1);\n    }\n}\n```\n\n### 5. Integration Tests\n```rust\n#[tokio::test]\nasync fn test_status_command_all_providers() {\n    let mut server = Server::new_async().await;\n\n    // Mock status endpoints for each provider\n    server.mock(\"GET\", \"/claude/status\")\n        .with_body(r#\"{\"status\":{\"indicator\":\"none\"}}\"#)\n        .create_async().await;\n\n    server.mock(\"GET\", \"/codex/status\")\n        .with_body(r#\"{\"status\":{\"indicator\":\"minor\"}}\"#)\n        .create_async().await;\n\n    let output = Command::new(\"caut\")\n        .args([\"status\", \"--format\", \"json\"])\n        .env(\"CAUT_STATUS_BASE_URL\", server.url())\n        .output()\n        .unwrap();\n\n    assert!(output.status.success());\n\n    let result: StatusOutput = serde_json::from_slice(\u0026output.stdout).unwrap();\n    assert!(result.providers.len() \u003e= 2);\n}\n\n#[tokio::test]\nasync fn test_status_command_single_provider() {\n    let tmp = TempDir::new().unwrap();\n\n    let output = Command::new(\"caut\")\n        .args([\"status\", \"claude\", \"--format\", \"json\"])\n        .env(\"HOME\", tmp.path())\n        .output()\n        .unwrap();\n\n    let result: StatusOutput = serde_json::from_slice(\u0026output.stdout).unwrap();\n    assert_eq!(result.providers.len(), 1);\n    assert_eq!(result.providers[0].provider, \"claude\");\n}\n```\n\n### 6. E2E Tests\n```bash\n#!/bin/bash\n# tests/e2e/status_e2e.sh\n\nset -euo pipefail\nsource \"$(dirname \"$0\")/helpers.sh\"\n\nlog_section \"Provider Status E2E Tests\"\n\nTEMP_DIR=$(mktemp -d)\nexport HOME=\"$TEMP_DIR\"\ntrap \"rm -rf $TEMP_DIR\" EXIT\n\n# Test 1: Status check runs\nlog_test \"Status check runs without error\"\nOUTPUT=$(caut status 2\u003e\u00261) || fail \"Status command failed\"\nlog_pass\n\n# Test 2: JSON format\nlog_test \"Status JSON output valid\"\nOUTPUT=$(caut status --format json 2\u003e\u00261)\necho \"$OUTPUT\" | jq -e '.providers' \u003e /dev/null || fail \"Invalid JSON\"\nlog_pass\n\n# Test 3: Single provider status\nlog_test \"Single provider status\"\nOUTPUT=$(caut status claude --format json 2\u003e\u00261)\nCOUNT=$(echo \"$OUTPUT\" | jq '.providers | length')\n[[ \"$COUNT\" == \"1\" ]] || fail \"Expected 1 provider, got $COUNT\"\nlog_pass\n\n# Test 4: Status with cache\nlog_test \"Status respects cache\"\n# First call\nSTART=$(date +%s%N)\ncaut status \u003e /dev/null 2\u003e\u00261\nFIRST=$(($(date +%s%N) - START))\n\n# Second call should be faster (cached)\nSTART=$(date +%s%N)\ncaut status \u003e /dev/null 2\u003e\u00261\nSECOND=$(($(date +%s%N) - START))\n\n# Second should be faster (at least 50% faster indicates cache hit)\n[[ $SECOND -lt $FIRST ]] \u0026\u0026 log_pass || log_pass \"Cache may not be active (network fast)\"\n\n# Test 5: Force refresh bypasses cache\nlog_test \"Force refresh bypasses cache\"\nOUTPUT=$(caut status --refresh --format json 2\u003e\u00261)\necho \"$OUTPUT\" | jq -e '.providers' \u003e /dev/null || fail \"Refresh failed\"\nlog_pass\n\n# Test 6: Watch mode starts\nlog_test \"Watch mode starts\"\ntimeout 2 caut status --watch 2\u003e\u00261 || [[ $? -eq 124 ]] || fail \"Watch mode failed\"\nlog_pass\n\n# Test 7: Quiet mode for scripts\nlog_test \"Quiet mode returns exit code\"\ncaut status --quiet 2\u003e\u00261 \u0026\u0026 log_pass || log_pass \"Non-zero exit indicates issue (expected)\"\n\nlog_summary\n```\n\n### 7. Logging Verification\n```rust\n#[cfg(test)]\nmod logging_tests {\n    #[test]\n    fn test_status_fetch_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let fetcher = StatusFetcher::new();\n        let _ = block_on(fetcher.fetch(\"https://status.example.com\"));\n\n        capture.assert_logged(\"fetching status\");\n        capture.assert_logged(\"url=\");\n    }\n\n    #[test]\n    fn test_cache_operations_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let cache = StatusCache::new(Duration::from_secs(300));\n        cache.set(\"claude\", mock_status(StatusIndicator::None));\n        let _ = cache.get(\"claude\");\n\n        capture.assert_logged_at_level(Level::DEBUG, \"cache\");\n    }\n\n    #[test]\n    fn test_incident_detection_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let fetcher = StatusFetcher::new();\n        // Simulate incident response\n        let _ = fetcher.parse_response(mock_incident_response());\n\n        capture.assert_logged_at_level(Level::WARN, \"incident detected\");\n    }\n}\n```\n\n## Acceptance Criteria\n- [ ] Status page parsing works for all formats\n- [ ] HTTP fetching with timeout/retry works\n- [ ] Caching with TTL and staleness works\n- [ ] Multi-provider aggregation correct\n- [ ] E2E tests pass\n- [ ] All operations properly logged\n\n## Dependencies\n- Requires logging infrastructure (coding_agent_usage_tracker-zev)\n- Requires status implementation tasks\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:56:28.644220332-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:56:28.644220332-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-dbt","depends_on_id":"coding_agent_usage_tracker-zev","type":"blocks","created_at":"2026-01-18T14:57:04.115282198-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-dbt","depends_on_id":"coding_agent_usage_tracker-kod","type":"blocks","created_at":"2026-01-18T14:57:04.16208633-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-deh","title":"Unit tests for core/status.rs (status page parsing)","description":"## Overview\nTest the status page fetching and parsing logic.\n\n## Target: src/core/status.rs (2.5KB)\nCritical for: Provider status display accuracy\n\n## Test Cases\n\n### 1. StatusIndicator Parsing\n- from_statuspage() for all variants:\n  - \"none\" / \"operational\" ‚Üí None\n  - \"minor\" ‚Üí Minor\n  - \"major\" ‚Üí Major\n  - \"critical\" ‚Üí Critical\n  - \"maintenance\" / \"under_maintenance\" ‚Üí Maintenance\n  - Unknown strings ‚Üí Unknown\n- Case insensitivity testing\n\n### 2. StatusPayload Construction\n- All fields populated correctly\n- Optional description handling\n- URL validation\n- updated_at timestamp handling\n\n### 3. Status Page Response Parsing\n- Parse statuspage.io JSON format\n- Handle missing indicator field\n- Handle missing description field\n- Handle malformed JSON gracefully\n\n### 4. Integration with Providers\n- Claude status page URL\n- Codex/OpenAI status page URL\n- Status caching behavior\n\n## Test Data\n- Real statuspage.io response samples\n- Edge cases: empty response, partial data, invalid JSON\n\n## Acceptance Criteria\n- [ ] All StatusIndicator variants tested\n- [ ] label() function verified for all variants\n- [ ] Response parsing tested with real formats\n- [ ] Error handling for malformed data","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:50:34.202956464-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:50:34.202956464-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-deh","depends_on_id":"coding_agent_usage_tracker-u5h","type":"blocks","created_at":"2026-01-18T02:53:18.825272284-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-dg0","title":"History: Add export functionality (JSON/CSV)","description":"## Task Overview\n\nImplement export functionality for history data in JSON and CSV formats, enabling external analysis in spreadsheets, visualization tools, or custom scripts.\n\n## Parent EPIC\n[EPIC] Historical Usage Tracking with Trend Visualization (coding_agent_usage_tracker-smv)\n\n## Export Formats\n\n### JSON Export\n```bash\n$ caut history --format json --days 30 \u003e usage_history.json\n```\n\n```json\n{\n  \"export_info\": {\n    \"generated_at\": \"2026-01-18T12:34:56Z\",\n    \"caut_version\": \"0.1.0\",\n    \"period\": {\n      \"from\": \"2025-12-19\",\n      \"to\": \"2026-01-18\"\n    }\n  },\n  \"snapshots\": [\n    {\n      \"id\": 1234,\n      \"provider\": \"claude\",\n      \"fetched_at\": \"2026-01-18T12:00:00Z\",\n      \"source\": \"oauth\",\n      \"primary\": {\n        \"used_percent\": 65.0,\n        \"window_minutes\": 180,\n        \"resets_at\": \"2026-01-18T15:00:00Z\"\n      },\n      \"secondary\": {\n        \"used_percent\": 42.0,\n        \"window_minutes\": 10080,\n        \"resets_at\": \"2026-01-25T00:00:00Z\"\n      },\n      \"cost\": {\n        \"today_usd\": 12.34,\n        \"mtd_usd\": 156.78\n      },\n      \"identity\": {\n        \"email\": \"user@example.com\",\n        \"organization\": \"Acme Corp\"\n      }\n    }\n  ],\n  \"aggregates\": {\n    \"by_provider\": {\n      \"claude\": {\n        \"avg_primary_pct\": 58.5,\n        \"max_primary_pct\": 91.0,\n        \"total_cost_usd\": 245.67,\n        \"snapshot_count\": 720\n      }\n    },\n    \"totals\": {\n      \"total_cost_usd\": 312.45,\n      \"snapshot_count\": 1440\n    }\n  }\n}\n```\n\n### CSV Export\n```bash\n$ caut history --format csv --days 30 \u003e usage_history.csv\n```\n\n```csv\nid,provider,fetched_at,source,primary_used_pct,primary_window_min,primary_resets_at,secondary_used_pct,secondary_window_min,cost_today_usd,cost_mtd_usd,credits_remaining,account_email\n1234,claude,2026-01-18T12:00:00Z,oauth,65.0,180,2026-01-18T15:00:00Z,42.0,10080,12.34,156.78,,user@example.com\n1235,codex,2026-01-18T12:01:00Z,cli,34.0,180,,,,3.45,45.67,87.50,\n```\n\n## Implementation\n\n### JSON Exporter\n\n```rust\n#[derive(Serialize)]\nstruct JsonExport {\n    export_info: ExportInfo,\n    snapshots: Vec\u003cSnapshotExport\u003e,\n    aggregates: Aggregates,\n}\n\nfn export_json(snapshots: \u0026[StoredSnapshot], period: \u0026DateRange) -\u003e Result\u003cString\u003e {\n    let export = JsonExport {\n        export_info: ExportInfo {\n            generated_at: Utc::now(),\n            caut_version: env\\!(\"CARGO_PKG_VERSION\").to_string(),\n            period: period.clone(),\n        },\n        snapshots: snapshots.iter().map(SnapshotExport::from).collect(),\n        aggregates: calculate_aggregates(snapshots),\n    };\n    \n    serde_json::to_string_pretty(\u0026export)\n        .map_err(|e| CautError::Serialization(e.to_string()))\n}\n```\n\n### CSV Exporter\n\n```rust\nfn export_csv(snapshots: \u0026[StoredSnapshot], writer: impl Write) -\u003e Result\u003c()\u003e {\n    let mut wtr = csv::Writer::from_writer(writer);\n    \n    // Write header\n    wtr.write_record(\u0026[\n        \"id\", \"provider\", \"fetched_at\", \"source\",\n        \"primary_used_pct\", \"primary_window_min\", \"primary_resets_at\",\n        \"secondary_used_pct\", \"secondary_window_min\",\n        \"cost_today_usd\", \"cost_mtd_usd\", \"credits_remaining\",\n        \"account_email\"\n    ])?;\n    \n    // Write data rows\n    for snap in snapshots {\n        wtr.write_record(\u0026[\n            snap.id.to_string(),\n            snap.provider.to_string(),\n            snap.fetched_at.to_rfc3339(),\n            snap.source.clone(),\n            snap.primary_used_pct.map(|v| v.to_string()).unwrap_or_default(),\n            // ... etc\n        ])?;\n    }\n    \n    wtr.flush()?;\n    Ok(())\n}\n```\n\n### Streaming Export for Large Datasets\n\nFor large history exports, stream data instead of loading all into memory:\n\n```rust\nasync fn export_csv_streaming(\n    store: \u0026HistoryStore,\n    period: \u0026DateRange,\n    writer: impl Write,\n) -\u003e Result\u003c()\u003e {\n    let mut wtr = csv::Writer::from_writer(writer);\n    write_csv_header(\u0026mut wtr)?;\n    \n    // Stream in chunks\n    let mut offset = 0;\n    let chunk_size = 1000;\n    \n    loop {\n        let chunk = store.get_snapshots_paginated(period, offset, chunk_size)?;\n        if chunk.is_empty() {\n            break;\n        }\n        \n        for snap in \u0026chunk {\n            write_csv_row(\u0026mut wtr, snap)?;\n        }\n        \n        offset += chunk.len();\n    }\n    \n    Ok(())\n}\n```\n\n## Deliverables\n\n- [ ] JSON export with full schema\n- [ ] CSV export with proper escaping\n- [ ] Streaming export for large datasets\n- [ ] Aggregate statistics in JSON export\n- [ ] Export metadata (version, timestamp, period)\n- [ ] Documentation of export schemas\n\n## Acceptance Criteria\n\n- [ ] JSON is valid and parseable\n- [ ] CSV imports correctly into Excel/Sheets\n- [ ] Large exports don't run out of memory\n- [ ] All fields properly escaped\n- [ ] Schema documented for external tools","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:08:18.753523221-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:08:18.753523221-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-dg0","depends_on_id":"coding_agent_usage_tracker-hws","type":"blocks","created_at":"2026-01-18T14:21:40.705426483-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-dm0","title":"Prompt: Generate shell integration snippets for bash/zsh/fish","description":"## Summary\nCreate shell-specific integration snippets that users can add to their shell config.\n\n## Commands\n- `caut prompt --install-bash` - Output bash PS1 snippet\n- `caut prompt --install-zsh` - Output zsh PROMPT snippet  \n- `caut prompt --install-fish` - Output fish fish_prompt function\n\n## Snippets to Generate\n\n### Bash\n```bash\n# caut prompt integration\n_caut_prompt() {\n    local usage=\\$(caut prompt 2\u003e/dev/null)\n    [ -n \"\\$usage\" ] \u0026\u0026 echo \"[\\$usage] \"\n}\nPS1='\\$(_caut_prompt)\\w \\$ '\n```\n\n### Zsh\n```zsh\n# caut prompt integration\n_caut_prompt() {\n    local usage=\\$(caut prompt 2\u003e/dev/null)\n    [ -n \"\\$usage\" ] \u0026\u0026 echo \"[\\$usage] \"\n}\nPROMPT='\\$(_caut_prompt)%~ %# '\n```\n\n### Fish\n```fish\n# caut prompt integration\nfunction fish_prompt\n    set -l usage (caut prompt 2\u003e/dev/null)\n    if test -n \"\\$usage\"\n        echo -n \"[\\$usage] \"\n    end\n    echo (prompt_pwd) '\u003e '\nend\n```\n\n## Acceptance Criteria\n- [ ] Each install flag outputs correct snippet\n- [ ] Snippets handle missing/empty output gracefully\n- [ ] ANSI colors work in snippets (configurable)\n- [ ] Documentation explains manual installation steps\n- [ ] Tested in actual shells (bash 4+, zsh 5+, fish 3+)","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:01:21.132909513-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:01:21.132909513-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-dm0","depends_on_id":"coding_agent_usage_tracker-5rv","type":"blocks","created_at":"2026-01-18T15:03:53.829983028-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-dv0","title":"API Server: Test suite for endpoints, SSE, auth, and load","description":"## Summary\nImplement comprehensive test suite for API Server Mode including HTTP endpoints, SSE streaming, authentication, and load testing.\n\n## Parent EPIC\n[EPIC] API Server Mode (coding_agent_usage_tracker-isd)\n\n## Test Categories\n\n### 1. Unit Tests: HTTP Endpoints\n```rust\n#[cfg(test)]\nmod endpoint_tests {\n    use axum::body::Body;\n    use axum::http::{Request, StatusCode};\n    use tower::ServiceExt;\n\n    #[tokio::test]\n    async fn test_health_endpoint() {\n        let app = create_test_app();\n\n        let response = app\n            .oneshot(Request::builder().uri(\"/health\").body(Body::empty()).unwrap())\n            .await\n            .unwrap();\n\n        assert_eq!(response.status(), StatusCode::OK);\n\n        let body = hyper::body::to_bytes(response.into_body()).await.unwrap();\n        let health: HealthResponse = serde_json::from_slice(\u0026body).unwrap();\n        assert_eq!(health.status, \"ok\");\n    }\n\n    #[tokio::test]\n    async fn test_usage_endpoint_all_providers() {\n        let app = create_test_app_with_data(mock_providers());\n\n        let response = app\n            .oneshot(Request::builder().uri(\"/api/v1/usage\").body(Body::empty()).unwrap())\n            .await\n            .unwrap();\n\n        assert_eq!(response.status(), StatusCode::OK);\n\n        let body = hyper::body::to_bytes(response.into_body()).await.unwrap();\n        let usage: UsageResponse = serde_json::from_slice(\u0026body).unwrap();\n        assert!(!usage.providers.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_usage_endpoint_single_provider() {\n        let app = create_test_app_with_data(mock_providers());\n\n        let response = app\n            .oneshot(\n                Request::builder()\n                    .uri(\"/api/v1/usage/claude\")\n                    .body(Body::empty())\n                    .unwrap()\n            )\n            .await\n            .unwrap();\n\n        assert_eq!(response.status(), StatusCode::OK);\n\n        let body = hyper::body::to_bytes(response.into_body()).await.unwrap();\n        let usage: ProviderPayload = serde_json::from_slice(\u0026body).unwrap();\n        assert_eq!(usage.provider, \"claude\");\n    }\n\n    #[tokio::test]\n    async fn test_unknown_provider_404() {\n        let app = create_test_app();\n\n        let response = app\n            .oneshot(\n                Request::builder()\n                    .uri(\"/api/v1/usage/unknown_provider\")\n                    .body(Body::empty())\n                    .unwrap()\n            )\n            .await\n            .unwrap();\n\n        assert_eq!(response.status(), StatusCode::NOT_FOUND);\n    }\n\n    #[tokio::test]\n    async fn test_history_endpoint() {\n        let app = create_test_app_with_history();\n\n        let response = app\n            .oneshot(\n                Request::builder()\n                    .uri(\"/api/v1/history?provider=claude\u0026hours=24\")\n                    .body(Body::empty())\n                    .unwrap()\n            )\n            .await\n            .unwrap();\n\n        assert_eq!(response.status(), StatusCode::OK);\n\n        let body = hyper::body::to_bytes(response.into_body()).await.unwrap();\n        let history: HistoryResponse = serde_json::from_slice(\u0026body).unwrap();\n        assert!(!history.snapshots.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_status_endpoint() {\n        let app = create_test_app();\n\n        let response = app\n            .oneshot(Request::builder().uri(\"/api/v1/status\").body(Body::empty()).unwrap())\n            .await\n            .unwrap();\n\n        assert_eq!(response.status(), StatusCode::OK);\n    }\n}\n```\n\n### 2. Unit Tests: SSE Streaming\n```rust\n#[cfg(test)]\nmod sse_tests {\n    use futures::StreamExt;\n    use tokio_tungstenite::connect_async;\n\n    #[tokio::test]\n    async fn test_sse_stream_connects() {\n        let app = create_test_app();\n        let server = spawn_test_server(app).await;\n\n        let response = reqwest::Client::new()\n            .get(format!(\"{}/api/v1/stream\", server.url()))\n            .header(\"Accept\", \"text/event-stream\")\n            .send()\n            .await\n            .unwrap();\n\n        assert_eq!(response.status(), 200);\n        assert!(response.headers()\n            .get(\"content-type\")\n            .unwrap()\n            .to_str()\n            .unwrap()\n            .contains(\"text/event-stream\"));\n    }\n\n    #[tokio::test]\n    async fn test_sse_receives_updates() {\n        let (app, tx) = create_test_app_with_broadcast();\n        let server = spawn_test_server(app).await;\n\n        let client = eventsource_client::ClientBuilder::for_url(\n            \u0026format!(\"{}/api/v1/stream\", server.url())\n        ).unwrap().build();\n\n        let mut stream = client.stream();\n\n        // Send an update\n        tx.send(UsageUpdate {\n            provider: \"claude\".to_string(),\n            usage: mock_usage(50.0),\n        }).unwrap();\n\n        // Receive the update\n        let event = tokio::time::timeout(\n            Duration::from_secs(5),\n            stream.next()\n        ).await.unwrap().unwrap().unwrap();\n\n        assert_eq!(event.event_type, \"usage\");\n        let data: UsageUpdate = serde_json::from_str(\u0026event.data).unwrap();\n        assert_eq!(data.provider, \"claude\");\n    }\n\n    #[tokio::test]\n    async fn test_sse_heartbeat() {\n        let app = create_test_app();\n        let server = spawn_test_server(app).await;\n\n        let client = eventsource_client::ClientBuilder::for_url(\n            \u0026format!(\"{}/api/v1/stream\", server.url())\n        ).unwrap().build();\n\n        let mut stream = client.stream();\n\n        // Should receive heartbeat within 30 seconds\n        let event = tokio::time::timeout(\n            Duration::from_secs(35),\n            stream.next()\n        ).await.unwrap().unwrap().unwrap();\n\n        assert!(event.event_type == \"heartbeat\" || event.event_type == \"usage\");\n    }\n\n    #[tokio::test]\n    async fn test_sse_reconnection() {\n        let app = create_test_app();\n        let server = spawn_test_server(app).await;\n\n        // First connection\n        let response1 = reqwest::Client::new()\n            .get(format!(\"{}/api/v1/stream\", server.url()))\n            .header(\"Accept\", \"text/event-stream\")\n            .send()\n            .await\n            .unwrap();\n        drop(response1);\n\n        // Second connection should also work\n        let response2 = reqwest::Client::new()\n            .get(format!(\"{}/api/v1/stream\", server.url()))\n            .header(\"Accept\", \"text/event-stream\")\n            .send()\n            .await\n            .unwrap();\n\n        assert_eq!(response2.status(), 200);\n    }\n}\n```\n\n### 3. Unit Tests: Authentication\n```rust\n#[cfg(test)]\nmod auth_tests {\n    #[tokio::test]\n    async fn test_api_key_auth_valid() {\n        let app = create_test_app_with_auth(\"test-api-key\");\n\n        let response = app\n            .oneshot(\n                Request::builder()\n                    .uri(\"/api/v1/usage\")\n                    .header(\"Authorization\", \"Bearer test-api-key\")\n                    .body(Body::empty())\n                    .unwrap()\n            )\n            .await\n            .unwrap();\n\n        assert_eq!(response.status(), StatusCode::OK);\n    }\n\n    #[tokio::test]\n    async fn test_api_key_auth_invalid() {\n        let app = create_test_app_with_auth(\"test-api-key\");\n\n        let response = app\n            .oneshot(\n                Request::builder()\n                    .uri(\"/api/v1/usage\")\n                    .header(\"Authorization\", \"Bearer wrong-key\")\n                    .body(Body::empty())\n                    .unwrap()\n            )\n            .await\n            .unwrap();\n\n        assert_eq!(response.status(), StatusCode::UNAUTHORIZED);\n    }\n\n    #[tokio::test]\n    async fn test_api_key_auth_missing() {\n        let app = create_test_app_with_auth(\"test-api-key\");\n\n        let response = app\n            .oneshot(\n                Request::builder()\n                    .uri(\"/api/v1/usage\")\n                    .body(Body::empty())\n                    .unwrap()\n            )\n            .await\n            .unwrap();\n\n        assert_eq!(response.status(), StatusCode::UNAUTHORIZED);\n    }\n\n    #[tokio::test]\n    async fn test_health_endpoint_no_auth_required() {\n        let app = create_test_app_with_auth(\"test-api-key\");\n\n        let response = app\n            .oneshot(\n                Request::builder()\n                    .uri(\"/health\")\n                    .body(Body::empty())\n                    .unwrap()\n            )\n            .await\n            .unwrap();\n\n        // Health should be accessible without auth\n        assert_eq!(response.status(), StatusCode::OK);\n    }\n\n    #[tokio::test]\n    async fn test_cors_headers() {\n        let app = create_test_app();\n\n        let response = app\n            .oneshot(\n                Request::builder()\n                    .method(\"OPTIONS\")\n                    .uri(\"/api/v1/usage\")\n                    .header(\"Origin\", \"http://localhost:3000\")\n                    .body(Body::empty())\n                    .unwrap()\n            )\n            .await\n            .unwrap();\n\n        assert!(response.headers().contains_key(\"access-control-allow-origin\"));\n    }\n}\n```\n\n### 4. Unit Tests: Rate Limiting\n```rust\n#[cfg(test)]\nmod rate_limit_tests {\n    #[tokio::test]\n    async fn test_rate_limit_not_exceeded() {\n        let app = create_test_app_with_rate_limit(10); // 10 req/sec\n\n        for _ in 0..5 {\n            let response = app.clone()\n                .oneshot(Request::builder().uri(\"/api/v1/usage\").body(Body::empty()).unwrap())\n                .await\n                .unwrap();\n            assert_eq!(response.status(), StatusCode::OK);\n        }\n    }\n\n    #[tokio::test]\n    async fn test_rate_limit_exceeded() {\n        let app = create_test_app_with_rate_limit(2); // 2 req/sec\n\n        // First two should succeed\n        for _ in 0..2 {\n            let response = app.clone()\n                .oneshot(Request::builder().uri(\"/api/v1/usage\").body(Body::empty()).unwrap())\n                .await\n                .unwrap();\n            assert_eq!(response.status(), StatusCode::OK);\n        }\n\n        // Third should be rate limited\n        let response = app\n            .oneshot(Request::builder().uri(\"/api/v1/usage\").body(Body::empty()).unwrap())\n            .await\n            .unwrap();\n        assert_eq!(response.status(), StatusCode::TOO_MANY_REQUESTS);\n    }\n\n    #[tokio::test]\n    async fn test_rate_limit_headers() {\n        let app = create_test_app_with_rate_limit(10);\n\n        let response = app\n            .oneshot(Request::builder().uri(\"/api/v1/usage\").body(Body::empty()).unwrap())\n            .await\n            .unwrap();\n\n        assert!(response.headers().contains_key(\"x-ratelimit-limit\"));\n        assert!(response.headers().contains_key(\"x-ratelimit-remaining\"));\n    }\n}\n```\n\n### 5. Integration Tests\n```rust\n#[tokio::test]\nasync fn test_server_lifecycle() {\n    let tmp = TempDir::new().unwrap();\n\n    // Start server\n    let server = ApiServer::new()\n        .with_port(0) // Random port\n        .with_data_dir(tmp.path())\n        .start()\n        .await\n        .unwrap();\n\n    let port = server.port();\n\n    // Verify it's running\n    let response = reqwest::get(format!(\"http://localhost:{}/health\", port))\n        .await\n        .unwrap();\n    assert_eq!(response.status(), 200);\n\n    // Shutdown\n    server.shutdown().await.unwrap();\n\n    // Verify it's stopped\n    let result = reqwest::get(format!(\"http://localhost:{}/health\", port)).await;\n    assert!(result.is_err());\n}\n\n#[tokio::test]\nasync fn test_server_command() {\n    let tmp = TempDir::new().unwrap();\n\n    // Start server via CLI in background\n    let mut child = Command::new(\"caut\")\n        .args([\"server\", \"--port\", \"0\", \"--background\"])\n        .env(\"HOME\", tmp.path())\n        .spawn()\n        .unwrap();\n\n    // Give it time to start\n    tokio::time::sleep(Duration::from_secs(1)).await;\n\n    // Server should be running\n    // (In real test, would read port from stdout or file)\n\n    child.kill().await.unwrap();\n}\n```\n\n### 6. E2E Tests\n```bash\n#!/bin/bash\n# tests/e2e/api_server_e2e.sh\n\nset -euo pipefail\nsource \"$(dirname \"$0\")/helpers.sh\"\n\nlog_section \"API Server E2E Tests\"\n\nTEMP_DIR=$(mktemp -d)\nexport HOME=\"$TEMP_DIR\"\ntrap \"cleanup\" EXIT\n\nPORT=0  # Will be assigned\nSERVER_PID=\"\"\n\ncleanup() {\n    [[ -n \"$SERVER_PID\" ]] \u0026\u0026 kill \"$SERVER_PID\" 2\u003e/dev/null || true\n    rm -rf \"$TEMP_DIR\"\n}\n\nstart_server() {\n    # Start server and capture port\n    caut server --port 0 --pidfile \"$TEMP_DIR/server.pid\" \u0026\n    SERVER_PID=$!\n    sleep 2\n\n    # Get actual port (implementation dependent)\n    PORT=$(cat \"$TEMP_DIR/server.port\" 2\u003e/dev/null || echo \"8080\")\n}\n\n# Test 1: Server starts\nlog_test \"Server starts successfully\"\nstart_server\ncurl -sf \"http://localhost:$PORT/health\" \u003e /dev/null || fail \"Server not responding\"\nlog_pass\n\n# Test 2: Health endpoint\nlog_test \"Health endpoint returns OK\"\nHEALTH=$(curl -sf \"http://localhost:$PORT/health\")\necho \"$HEALTH\" | jq -e '.status == \"ok\"' \u003e /dev/null || fail \"Health not ok\"\nlog_pass\n\n# Test 3: Usage endpoint\nlog_test \"Usage endpoint returns data\"\nUSAGE=$(curl -sf \"http://localhost:$PORT/api/v1/usage\")\necho \"$USAGE\" | jq -e '.providers' \u003e /dev/null || fail \"No providers in response\"\nlog_pass\n\n# Test 4: Single provider endpoint\nlog_test \"Single provider endpoint\"\nCLAUDE=$(curl -sf \"http://localhost:$PORT/api/v1/usage/claude\" || echo '{\"error\":\"not found\"}')\necho \"$CLAUDE\" | jq -e '.provider == \"claude\" or .error' \u003e /dev/null || fail \"Invalid response\"\nlog_pass\n\n# Test 5: SSE stream connects\nlog_test \"SSE stream connects\"\n# Use timeout to not hang\ntimeout 3 curl -sf -N \"http://localhost:$PORT/api/v1/stream\" \u003e /dev/null 2\u003e\u00261 \u0026\nCURL_PID=$!\nsleep 1\nkill $CURL_PID 2\u003e/dev/null || true\nlog_pass\n\n# Test 6: API key auth (if enabled)\nlog_test \"API key authentication\"\n# Restart server with auth\nkill \"$SERVER_PID\" 2\u003e/dev/null || true\nsleep 1\nexport CAUT_API_KEY=\"test-secret-key\"\ncaut server --port 0 --auth --pidfile \"$TEMP_DIR/server.pid\" \u0026\nSERVER_PID=$!\nsleep 2\nPORT=$(cat \"$TEMP_DIR/server.port\" 2\u003e/dev/null || echo \"8080\")\n\n# Without key should fail\nHTTP_CODE=$(curl -s -o /dev/null -w \"%{http_code}\" \"http://localhost:$PORT/api/v1/usage\")\n[[ \"$HTTP_CODE\" == \"401\" ]] || fail \"Expected 401, got $HTTP_CODE\"\n\n# With key should succeed\nHTTP_CODE=$(curl -s -o /dev/null -w \"%{http_code}\" -H \"Authorization: Bearer test-secret-key\" \"http://localhost:$PORT/api/v1/usage\")\n[[ \"$HTTP_CODE\" == \"200\" ]] || fail \"Expected 200, got $HTTP_CODE\"\nlog_pass\n\n# Test 7: CORS headers\nlog_test \"CORS headers present\"\nHEADERS=$(curl -sI -X OPTIONS \"http://localhost:$PORT/api/v1/usage\" -H \"Origin: http://localhost:3000\")\necho \"$HEADERS\" | grep -qi \"access-control\" \u0026\u0026 log_pass || log_pass \"CORS may not be enabled\"\n\n# Test 8: Graceful shutdown\nlog_test \"Graceful shutdown\"\nkill -TERM \"$SERVER_PID\"\nsleep 2\n# Should have exited cleanly\nwait \"$SERVER_PID\" 2\u003e/dev/null \u0026\u0026 log_pass || log_pass \"Server shut down\"\nSERVER_PID=\"\"\n\nlog_summary\n```\n\n### 7. Load Tests\n```rust\n#[cfg(test)]\nmod load_tests {\n    use std::sync::atomic::{AtomicU64, Ordering};\n\n    #[tokio::test]\n    #[ignore] // Run with --ignored for load tests\n    async fn test_concurrent_requests() {\n        let app = create_test_app();\n        let server = spawn_test_server(app).await;\n\n        let success_count = AtomicU64::new(0);\n        let error_count = AtomicU64::new(0);\n\n        let handles: Vec\u003c_\u003e = (0..100)\n            .map(|_| {\n                let url = server.url();\n                let success = \u0026success_count;\n                let errors = \u0026error_count;\n                tokio::spawn(async move {\n                    for _ in 0..10 {\n                        match reqwest::get(format!(\"{}/api/v1/usage\", url)).await {\n                            Ok(r) if r.status().is_success() =\u003e {\n                                success.fetch_add(1, Ordering::Relaxed);\n                            }\n                            _ =\u003e {\n                                errors.fetch_add(1, Ordering::Relaxed);\n                            }\n                        }\n                    }\n                })\n            })\n            .collect();\n\n        for handle in handles {\n            handle.await.unwrap();\n        }\n\n        let success = success_count.load(Ordering::Relaxed);\n        let errors = error_count.load(Ordering::Relaxed);\n\n        // At least 95% success rate\n        assert!(success as f64 / (success + errors) as f64 \u003e 0.95);\n    }\n\n    #[tokio::test]\n    #[ignore]\n    async fn test_sse_many_clients() {\n        let (app, tx) = create_test_app_with_broadcast();\n        let server = spawn_test_server(app).await;\n\n        // Connect 50 SSE clients\n        let clients: Vec\u003c_\u003e = (0..50)\n            .map(|_| {\n                let url = server.url();\n                tokio::spawn(async move {\n                    let client = eventsource_client::ClientBuilder::for_url(\n                        \u0026format!(\"{}/api/v1/stream\", url)\n                    ).unwrap().build();\n                    let mut stream = client.stream();\n\n                    // Wait for one event\n                    tokio::time::timeout(\n                        Duration::from_secs(10),\n                        stream.next()\n                    ).await\n                })\n            })\n            .collect();\n\n        // Send an update\n        tokio::time::sleep(Duration::from_millis(500)).await;\n        tx.send(mock_update()).unwrap();\n\n        // All clients should receive it\n        let mut received = 0;\n        for client in clients {\n            if client.await.unwrap().is_ok() {\n                received += 1;\n            }\n        }\n\n        // At least 90% of clients should receive\n        assert!(received \u003e= 45);\n    }\n}\n```\n\n### 8. Logging Verification\n```rust\n#[cfg(test)]\nmod logging_tests {\n    #[tokio::test]\n    async fn test_request_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let app = create_test_app();\n        let _ = app\n            .oneshot(Request::builder().uri(\"/api/v1/usage\").body(Body::empty()).unwrap())\n            .await;\n\n        capture.assert_logged(\"incoming request\");\n        capture.assert_logged(\"method=GET\");\n        capture.assert_logged(\"path=/api/v1/usage\");\n    }\n\n    #[tokio::test]\n    async fn test_response_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let app = create_test_app();\n        let _ = app\n            .oneshot(Request::builder().uri(\"/api/v1/usage\").body(Body::empty()).unwrap())\n            .await;\n\n        capture.assert_logged(\"response\");\n        capture.assert_logged(\"status=200\");\n        capture.assert_logged(\"duration_ms=\");\n    }\n\n    #[tokio::test]\n    async fn test_error_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let app = create_test_app();\n        let _ = app\n            .oneshot(Request::builder().uri(\"/nonexistent\").body(Body::empty()).unwrap())\n            .await;\n\n        capture.assert_logged_at_level(Level::WARN, \"not found\");\n    }\n\n    #[tokio::test]\n    async fn test_sse_connection_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let app = create_test_app();\n        let server = spawn_test_server(app).await;\n\n        let _response = reqwest::Client::new()\n            .get(format!(\"{}/api/v1/stream\", server.url()))\n            .header(\"Accept\", \"text/event-stream\")\n            .send()\n            .await;\n\n        capture.assert_logged(\"SSE client connected\");\n    }\n}\n```\n\n## Acceptance Criteria\n- [ ] All HTTP endpoints work correctly\n- [ ] SSE streaming delivers updates\n- [ ] Authentication (when enabled) works\n- [ ] Rate limiting protects server\n- [ ] CORS headers present\n- [ ] Load tests pass (95%+ success)\n- [ ] E2E tests pass\n- [ ] All operations properly logged\n\n## Dependencies\n- Requires logging infrastructure (coding_agent_usage_tracker-zev)\n- Requires offline mode for caching (coding_agent_usage_tracker-v3f)\n- Requires API server implementation tasks\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:56:30.465742946-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:56:30.465742946-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-dv0","depends_on_id":"coding_agent_usage_tracker-zev","type":"blocks","created_at":"2026-01-18T14:57:05.675926372-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-dv0","depends_on_id":"coding_agent_usage_tracker-isd","type":"blocks","created_at":"2026-01-18T14:57:05.725042184-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-dv0","depends_on_id":"coding_agent_usage_tracker-v3f","type":"blocks","created_at":"2026-01-18T14:57:05.774199734-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-e23","title":"TUI: Implement sparkline charts for usage trends","description":"## Summary\nImplement sparkline charts for historical usage trends in the TUI dashboard.\n\n## Background\nVisual trend lines help users understand:\n1. Usage patterns over time\n2. Whether usage is increasing or decreasing\n3. Comparison between providers\n4. Anticipate when limits might be hit\n\n## Technical Design\n\n### Sparkline Widget\n```rust\nuse ratatui::widgets::Sparkline;\n\npub struct HistoryPanel {\n    pub data: HashMap\u003cString, Vec\u003cf64\u003e\u003e,  // provider -\u003e usage percentages\n    pub time_range: Duration,\n    pub selected_provider: Option\u003cString\u003e,\n}\n\nimpl Widget for \u0026HistoryPanel {\n    fn render(self, area: Rect, buf: \u0026mut Buffer) {\n        let block = Block::default()\n            .title(\"History (24h)\")\n            .borders(Borders::ALL);\n        let inner = block.inner(area);\n        block.render(area, buf);\n        \n        // Split area for each provider's sparkline\n        let provider_count = self.data.len();\n        let constraints: Vec\u003c_\u003e = (0..provider_count)\n            .map(|_| Constraint::Ratio(1, provider_count as u32))\n            .collect();\n        \n        let chunks = Layout::default()\n            .direction(Direction::Vertical)\n            .constraints(constraints)\n            .split(inner);\n        \n        for (i, (provider, values)) in self.data.iter().enumerate() {\n            self.render_provider_sparkline(provider, values, chunks[i], buf);\n        }\n    }\n}\n\nimpl HistoryPanel {\n    fn render_provider_sparkline(\n        \u0026self,\n        provider: \u0026str,\n        values: \u0026[f64],\n        area: Rect,\n        buf: \u0026mut Buffer,\n    ) {\n        // Convert f64 percentages to u64 for Sparkline\n        let data: Vec\u003cu64\u003e = values.iter()\n            .map(|\u0026v| (v * 10.0) as u64)  // Scale for precision\n            .collect();\n        \n        let color = self.provider_color(provider);\n        \n        // Render label\n        let label = Span::styled(\n            format!(\"{}: \", provider),\n            Style::default().fg(color),\n        );\n        \n        // Sparkline needs horizontal space\n        let sparkline_area = Rect {\n            x: area.x + provider.len() as u16 + 2,\n            y: area.y,\n            width: area.width.saturating_sub(provider.len() as u16 + 2),\n            height: area.height,\n        };\n        \n        // Render label\n        buf.set_string(area.x, area.y, \u0026label.content, label.style);\n        \n        // Render sparkline\n        let sparkline = Sparkline::default()\n            .data(\u0026data)\n            .style(Style::default().fg(color))\n            .max(1000);  // 100% scaled by 10\n        \n        sparkline.render(sparkline_area, buf);\n    }\n    \n    fn provider_color(\u0026self, provider: \u0026str) -\u003e Color {\n        match provider.to_lowercase().as_str() {\n            \"claude\" =\u003e Color::Cyan,\n            \"codex\" =\u003e Color::Green,\n            \"openrouter\" =\u003e Color::Magenta,\n            \"cursor\" =\u003e Color::Yellow,\n            _ =\u003e Color::White,\n        }\n    }\n}\n```\n\n### Data Preparation\n```rust\nimpl HistoryPanel {\n    /// Load historical data from history store\n    pub fn load_data(history: \u0026HistoryStore, window: Duration) -\u003e Self {\n        let since = Utc::now() - window;\n        let providers = [\"claude\", \"codex\", \"openrouter\", \"cursor\"];\n        \n        let mut data = HashMap::new();\n        \n        for provider in providers {\n            let snapshots = history.query_range(provider, since, Utc::now())\n                .unwrap_or_default();\n            \n            // Resample to fit terminal width (e.g., 60 data points)\n            let values = Self::resample(\u0026snapshots, 60);\n            data.insert(provider.to_string(), values);\n        }\n        \n        Self {\n            data,\n            time_range: window,\n            selected_provider: None,\n        }\n    }\n    \n    /// Resample historical data to target number of points\n    fn resample(snapshots: \u0026[StoredSnapshot], target_points: usize) -\u003e Vec\u003cf64\u003e {\n        if snapshots.is_empty() {\n            return vec![0.0; target_points];\n        }\n        \n        let bucket_size = snapshots.len() / target_points.max(1);\n        \n        snapshots\n            .chunks(bucket_size.max(1))\n            .map(|chunk| {\n                // Average of chunk\n                let sum: f64 = chunk.iter()\n                    .map(|s| s.primary_used_pct.unwrap_or(0.0))\n                    .sum();\n                sum / chunk.len() as f64\n            })\n            .take(target_points)\n            .collect()\n    }\n}\n```\n\n### Trend Indicators\n```rust\nimpl HistoryPanel {\n    /// Calculate trend direction from recent data\n    pub fn trend_indicator(values: \u0026[f64]) -\u003e TrendDirection {\n        if values.len() \u003c 2 {\n            return TrendDirection::Stable;\n        }\n        \n        // Compare last quarter to first quarter\n        let quarter = values.len() / 4;\n        let first_avg: f64 = values[..quarter].iter().sum::\u003cf64\u003e() / quarter as f64;\n        let last_avg: f64 = values[values.len()-quarter..].iter().sum::\u003cf64\u003e() / quarter as f64;\n        \n        let diff = last_avg - first_avg;\n        \n        if diff \u003e 5.0 {\n            TrendDirection::Increasing\n        } else if diff \u003c -5.0 {\n            TrendDirection::Decreasing\n        } else {\n            TrendDirection::Stable\n        }\n    }\n}\n\npub enum TrendDirection {\n    Increasing,  // ‚Üó\n    Decreasing,  // ‚Üò\n    Stable,      // ‚Üí\n}\n```\n\n## Visual Output\n```\n‚îå‚îÄ History (24h) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Claude:   ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ ‚Üó            ‚îÇ\n‚îÇ Codex:    ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ ‚Üí             ‚îÇ\n‚îÇ OpenRouter: ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ ‚Üò             ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n## Acceptance Criteria\n- [ ] Sparklines render for all providers\n- [ ] Colors distinguish providers\n- [ ] Data resamples to terminal width\n- [ ] Trend indicators calculated correctly\n- [ ] Empty data handled gracefully\n- [ ] Legend shows provider names\n- [ ] Time range configurable (1h, 24h, 7d)\n\n## Unicode Sparkline Characters\nUsing block characters for sparklines:\n- ‚ñÅ (U+2581) - 1/8 block\n- ‚ñÇ (U+2582) - 2/8 block\n- ‚ñÉ (U+2583) - 3/8 block\n- ‚ñÑ (U+2584) - 4/8 block\n- ‚ñÖ (U+2585) - 5/8 block\n- ‚ñÜ (U+2586) - 6/8 block\n- ‚ñá (U+2587) - 7/8 block\n- ‚ñà (U+2588) - full block\n\n## Dependencies\n- Requires core TUI layout (sibling task)\n- Requires history storage (EPIC 1) for data\n- Used by dashboard renderer\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:16:25.662262698-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:16:25.662262698-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-e23","depends_on_id":"coding_agent_usage_tracker-i9x","type":"blocks","created_at":"2026-01-18T14:22:09.201918815-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-e23","depends_on_id":"coding_agent_usage_tracker-hws","type":"blocks","created_at":"2026-01-18T14:22:09.248521815-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-e6a","title":"Budgets: Test suite for tracking, alerts, and persistence","description":"## Summary\nImplement comprehensive test suite for Usage Budgets including budget enforcement, alert thresholds, and multi-provider budget tracking.\n\n## Parent EPIC\n[EPIC] Usage Budgets (coding_agent_usage_tracker-jkf)\n\n## Test Categories\n\n### 1. Unit Tests: Budget Configuration\n```rust\n#[cfg(test)]\nmod budget_config_tests {\n    use crate::budgets::{BudgetConfig, BudgetPeriod, BudgetScope};\n\n    #[test]\n    fn test_parse_daily_budget() {\n        let config = BudgetConfig::parse(\"$10/day\").unwrap();\n\n        assert_eq!(config.amount_usd, 10.0);\n        assert_eq!(config.period, BudgetPeriod::Daily);\n    }\n\n    #[test]\n    fn test_parse_monthly_budget() {\n        let config = BudgetConfig::parse(\"$500/month\").unwrap();\n\n        assert_eq!(config.amount_usd, 500.0);\n        assert_eq!(config.period, BudgetPeriod::Monthly);\n    }\n\n    #[test]\n    fn test_parse_weekly_budget() {\n        let config = BudgetConfig::parse(\"$100/week\").unwrap();\n\n        assert_eq!(config.amount_usd, 100.0);\n        assert_eq!(config.period, BudgetPeriod::Weekly);\n    }\n\n    #[test]\n    fn test_parse_per_provider_budget() {\n        let config = BudgetConfig::parse(\"claude:$50/day\").unwrap();\n\n        assert_eq!(config.scope, BudgetScope::Provider(\"claude\".to_string()));\n        assert_eq!(config.amount_usd, 50.0);\n    }\n\n    #[test]\n    fn test_parse_global_budget() {\n        let config = BudgetConfig::parse(\"all:$100/day\").unwrap();\n\n        assert_eq!(config.scope, BudgetScope::Global);\n    }\n\n    #[test]\n    fn test_invalid_budget_format() {\n        assert!(BudgetConfig::parse(\"invalid\").is_err());\n        assert!(BudgetConfig::parse(\"$-10/day\").is_err());\n        assert!(BudgetConfig::parse(\"$/day\").is_err());\n    }\n\n    #[test]\n    fn test_budget_with_decimals() {\n        let config = BudgetConfig::parse(\"$25.50/day\").unwrap();\n        assert!((config.amount_usd - 25.50).abs() \u003c 0.001);\n    }\n}\n```\n\n### 2. Unit Tests: Budget Tracking\n```rust\n#[cfg(test)]\nmod budget_tracking_tests {\n    #[test]\n    fn test_daily_budget_tracking() {\n        let tracker = BudgetTracker::new();\n        let budget = BudgetConfig::daily(10.0, BudgetScope::Global);\n\n        // Record some usage\n        tracker.record_cost(3.0, \"claude\", Utc::now());\n        tracker.record_cost(2.0, \"codex\", Utc::now());\n\n        let status = tracker.check_budget(\u0026budget);\n\n        assert_eq!(status.spent_usd, 5.0);\n        assert_eq!(status.remaining_usd, 5.0);\n        assert_eq!(status.percent_used, 50.0);\n        assert!(!status.exceeded);\n    }\n\n    #[test]\n    fn test_budget_exceeded() {\n        let tracker = BudgetTracker::new();\n        let budget = BudgetConfig::daily(10.0, BudgetScope::Global);\n\n        tracker.record_cost(12.0, \"claude\", Utc::now());\n\n        let status = tracker.check_budget(\u0026budget);\n\n        assert!(status.exceeded);\n        assert!(status.remaining_usd \u003c 0.0);\n        assert!(status.percent_used \u003e 100.0);\n    }\n\n    #[test]\n    fn test_provider_specific_budget() {\n        let tracker = BudgetTracker::new();\n        let claude_budget = BudgetConfig::daily(10.0, BudgetScope::Provider(\"claude\".to_string()));\n\n        tracker.record_cost(5.0, \"claude\", Utc::now());\n        tracker.record_cost(100.0, \"codex\", Utc::now()); // Different provider\n\n        let status = tracker.check_budget(\u0026claude_budget);\n\n        assert_eq!(status.spent_usd, 5.0); // Only claude costs\n        assert!(!status.exceeded);\n    }\n\n    #[test]\n    fn test_budget_period_boundaries() {\n        let tracker = BudgetTracker::new();\n        let budget = BudgetConfig::daily(10.0, BudgetScope::Global);\n\n        // Record cost from yesterday\n        let yesterday = Utc::now() - chrono::Duration::days(1);\n        tracker.record_cost(100.0, \"claude\", yesterday);\n\n        // Record cost from today\n        tracker.record_cost(3.0, \"claude\", Utc::now());\n\n        let status = tracker.check_budget(\u0026budget);\n\n        // Should only count today's costs\n        assert_eq!(status.spent_usd, 3.0);\n    }\n\n    #[test]\n    fn test_monthly_budget_accumulation() {\n        let tracker = BudgetTracker::new();\n        let budget = BudgetConfig::monthly(100.0, BudgetScope::Global);\n\n        // Spread costs across the month\n        for day in 0..15 {\n            let timestamp = Utc::now() - chrono::Duration::days(day);\n            tracker.record_cost(5.0, \"claude\", timestamp);\n        }\n\n        let status = tracker.check_budget(\u0026budget);\n\n        assert_eq!(status.spent_usd, 75.0);\n        assert_eq!(status.remaining_usd, 25.0);\n    }\n}\n```\n\n### 3. Unit Tests: Alert Thresholds\n```rust\n#[cfg(test)]\nmod alert_tests {\n    #[test]\n    fn test_warning_threshold_default() {\n        let tracker = BudgetTracker::new();\n        let budget = BudgetConfig::daily(100.0, BudgetScope::Global);\n\n        tracker.record_cost(79.0, \"claude\", Utc::now());\n        let status = tracker.check_budget(\u0026budget);\n        assert!(status.alerts.is_empty());\n\n        tracker.record_cost(2.0, \"claude\", Utc::now()); // Now at 81%\n        let status = tracker.check_budget(\u0026budget);\n        assert!(status.alerts.iter().any(|a| a.level == AlertLevel::Warning));\n    }\n\n    #[test]\n    fn test_critical_threshold() {\n        let tracker = BudgetTracker::new();\n        let budget = BudgetConfig::daily(100.0, BudgetScope::Global)\n            .with_critical_threshold(95.0);\n\n        tracker.record_cost(96.0, \"claude\", Utc::now());\n\n        let status = tracker.check_budget(\u0026budget);\n        assert!(status.alerts.iter().any(|a| a.level == AlertLevel::Critical));\n    }\n\n    #[test]\n    fn test_custom_thresholds() {\n        let tracker = BudgetTracker::new();\n        let budget = BudgetConfig::daily(100.0, BudgetScope::Global)\n            .with_warning_threshold(50.0)\n            .with_critical_threshold(75.0);\n\n        tracker.record_cost(51.0, \"claude\", Utc::now());\n\n        let status = tracker.check_budget(\u0026budget);\n        assert!(status.alerts.iter().any(|a| a.level == AlertLevel::Warning));\n\n        tracker.record_cost(25.0, \"claude\", Utc::now()); // Now at 76%\n        let status = tracker.check_budget(\u0026budget);\n        assert!(status.alerts.iter().any(|a| a.level == AlertLevel::Critical));\n    }\n\n    #[test]\n    fn test_exceeded_alert() {\n        let tracker = BudgetTracker::new();\n        let budget = BudgetConfig::daily(100.0, BudgetScope::Global);\n\n        tracker.record_cost(110.0, \"claude\", Utc::now());\n\n        let status = tracker.check_budget(\u0026budget);\n        assert!(status.alerts.iter().any(|a| a.level == AlertLevel::Exceeded));\n    }\n}\n```\n\n### 4. Unit Tests: Budget Persistence\n```rust\n#[cfg(test)]\nmod persistence_tests {\n    #[test]\n    fn test_save_and_load_budgets() {\n        let tmp = TempDir::new().unwrap();\n        let config_path = tmp.path().join(\"budgets.toml\");\n\n        let budgets = vec![\n            BudgetConfig::daily(10.0, BudgetScope::Provider(\"claude\".to_string())),\n            BudgetConfig::monthly(500.0, BudgetScope::Global),\n        ];\n\n        BudgetStore::save(\u0026config_path, \u0026budgets).unwrap();\n        let loaded = BudgetStore::load(\u0026config_path).unwrap();\n\n        assert_eq!(loaded.len(), 2);\n        assert_eq!(loaded[0].amount_usd, 10.0);\n    }\n\n    #[test]\n    fn test_budget_history_tracking() {\n        let tmp = TempDir::new().unwrap();\n        let store = BudgetHistoryStore::open(tmp.path().join(\"history.db\")).unwrap();\n\n        let snapshot = BudgetSnapshot {\n            timestamp: Utc::now(),\n            budget_id: \"global-daily\".to_string(),\n            spent_usd: 5.0,\n            limit_usd: 10.0,\n        };\n\n        store.record(\u0026snapshot).unwrap();\n\n        let history = store.get_history(\"global-daily\", 24).unwrap();\n        assert_eq!(history.len(), 1);\n    }\n}\n```\n\n### 5. Integration Tests\n```rust\n#[test]\nfn test_budget_command_set() {\n    let tmp = TempDir::new().unwrap();\n\n    let output = Command::new(\"caut\")\n        .args([\"budget\", \"set\", \"claude\", \"$50/day\"])\n        .env(\"HOME\", tmp.path())\n        .output()\n        .unwrap();\n\n    assert!(output.status.success());\n\n    // Verify it was saved\n    let output = Command::new(\"caut\")\n        .args([\"budget\", \"list\", \"--format\", \"json\"])\n        .env(\"HOME\", tmp.path())\n        .output()\n        .unwrap();\n\n    let budgets: Vec\u003cBudgetConfig\u003e = serde_json::from_slice(\u0026output.stdout).unwrap();\n    assert!(budgets.iter().any(|b| b.scope == BudgetScope::Provider(\"claude\".to_string())));\n}\n\n#[test]\nfn test_budget_status_command() {\n    let tmp = TempDir::new().unwrap();\n    setup_budget(\u0026tmp, \"claude\", 100.0, BudgetPeriod::Daily);\n    setup_usage_history(\u0026tmp, \"claude\", 45.0); // 45% used\n\n    let output = Command::new(\"caut\")\n        .args([\"budget\", \"status\", \"--format\", \"json\"])\n        .env(\"HOME\", tmp.path())\n        .output()\n        .unwrap();\n\n    let status: BudgetStatusOutput = serde_json::from_slice(\u0026output.stdout).unwrap();\n    assert!((status.budgets[0].percent_used - 45.0).abs() \u003c 1.0);\n}\n```\n\n### 6. E2E Tests\n```bash\n#!/bin/bash\n# tests/e2e/budget_e2e.sh\n\nset -euo pipefail\nsource \"$(dirname \"$0\")/helpers.sh\"\n\nlog_section \"Usage Budget E2E Tests\"\n\nTEMP_DIR=$(mktemp -d)\nexport HOME=\"$TEMP_DIR\"\nexport XDG_CONFIG_HOME=\"$TEMP_DIR/.config\"\ntrap \"rm -rf $TEMP_DIR\" EXIT\n\n# Test 1: Set budget\nlog_test \"Set daily budget\"\ncaut budget set claude '$50/day' 2\u003e\u00261 || fail \"Failed to set budget\"\nlog_pass\n\n# Test 2: List budgets\nlog_test \"List budgets\"\nOUTPUT=$(caut budget list --format json 2\u003e\u00261)\necho \"$OUTPUT\" | jq -e '.[] | select(.provider==\"claude\")' \u003e /dev/null || fail \"Budget not found\"\nlog_pass\n\n# Test 3: Set global budget\nlog_test \"Set global budget\"\ncaut budget set all '$100/day' 2\u003e\u00261 || fail \"Failed to set global budget\"\nOUTPUT=$(caut budget list --format json 2\u003e\u00261)\necho \"$OUTPUT\" | jq -e '.[] | select(.scope==\"global\")' \u003e /dev/null || fail \"Global budget not found\"\nlog_pass\n\n# Test 4: Budget status (no usage)\nlog_test \"Budget status with no usage\"\nOUTPUT=$(caut budget status --format json 2\u003e\u00261)\nPERCENT=$(echo \"$OUTPUT\" | jq -r '.[0].percent_used // 0')\n[[ \"$PERCENT\" == \"0\" || \"$PERCENT\" == \"null\" ]] || fail \"Expected 0% used, got $PERCENT\"\nlog_pass\n\n# Test 5: Remove budget\nlog_test \"Remove budget\"\ncaut budget remove claude 2\u003e\u00261 || fail \"Failed to remove budget\"\nOUTPUT=$(caut budget list --format json 2\u003e\u00261)\nCOUNT=$(echo \"$OUTPUT\" | jq '[.[] | select(.provider==\"claude\")] | length')\n[[ \"$COUNT\" == \"0\" ]] || fail \"Budget not removed\"\nlog_pass\n\n# Test 6: Warning threshold\nlog_test \"Custom warning threshold\"\ncaut budget set codex '$10/day' --warn-at 50 --critical-at 80 2\u003e\u00261 || fail \"Failed to set budget with thresholds\"\nOUTPUT=$(caut budget list --format json 2\u003e\u00261)\nWARN=$(echo \"$OUTPUT\" | jq -r '.[] | select(.provider==\"codex\") | .warning_threshold')\n[[ \"$WARN\" == \"50\" ]] || fail \"Warning threshold not set correctly\"\nlog_pass\n\n# Test 7: Monthly budget\nlog_test \"Monthly budget period\"\ncaut budget set claude '$500/month' 2\u003e\u00261 || fail \"Failed to set monthly budget\"\nOUTPUT=$(caut budget list --format json 2\u003e\u00261)\nPERIOD=$(echo \"$OUTPUT\" | jq -r '.[] | select(.provider==\"claude\") | .period')\n[[ \"$PERIOD\" == \"monthly\" ]] || fail \"Expected monthly period, got $PERIOD\"\nlog_pass\n\nlog_summary\n```\n\n### 7. Logging Verification Tests\n```rust\n#[cfg(test)]\nmod logging_tests {\n    #[test]\n    fn test_budget_check_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let tracker = BudgetTracker::new();\n        let budget = BudgetConfig::daily(100.0, BudgetScope::Global);\n        let _ = tracker.check_budget(\u0026budget);\n\n        capture.assert_logged(\"checking budget\");\n        capture.assert_logged(\"budget_id=\");\n    }\n\n    #[test]\n    fn test_threshold_breach_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let tracker = BudgetTracker::new();\n        let budget = BudgetConfig::daily(100.0, BudgetScope::Global);\n        tracker.record_cost(85.0, \"claude\", Utc::now());\n        let _ = tracker.check_budget(\u0026budget);\n\n        capture.assert_logged_at_level(Level::WARN, \"budget threshold breached\");\n    }\n\n    #[test]\n    fn test_budget_exceeded_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let tracker = BudgetTracker::new();\n        let budget = BudgetConfig::daily(100.0, BudgetScope::Global);\n        tracker.record_cost(110.0, \"claude\", Utc::now());\n        let _ = tracker.check_budget(\u0026budget);\n\n        capture.assert_logged_at_level(Level::ERROR, \"budget exceeded\");\n    }\n}\n```\n\n## Acceptance Criteria\n- [ ] Budget configuration parsing complete\n- [ ] Period tracking (daily/weekly/monthly) works correctly\n- [ ] Provider-specific and global budgets work\n- [ ] Alert thresholds trigger correctly\n- [ ] Budget persistence works\n- [ ] E2E tests pass\n- [ ] All operations properly logged\n\n## Dependencies\n- Requires logging infrastructure (coding_agent_usage_tracker-zev)\n- Requires historical data (coding_agent_usage_tracker-smv)\n- Requires budget implementation tasks\n","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:56:26.164917383-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:56:26.164917383-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-e6a","depends_on_id":"coding_agent_usage_tracker-zev","type":"blocks","created_at":"2026-01-18T14:57:02.422506615-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-e6a","depends_on_id":"coding_agent_usage_tracker-jkf","type":"blocks","created_at":"2026-01-18T14:57:02.471397834-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-e6a","depends_on_id":"coding_agent_usage_tracker-smv","type":"blocks","created_at":"2026-01-18T14:57:02.521593147-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-egm","title":"Errors: Machine-readable JSON error format","description":"## Overview\nImplement a structured JSON error format that AI agents can parse and act upon automatically.\n\n## Background \u0026 Rationale\nAI coding agents are a primary user of caut. When errors occur, agents need to:\n1. Understand what went wrong (structured, not just text)\n2. Know what commands could fix it\n3. Decide whether to retry automatically\n4. Report meaningfully to humans\n\nA machine-readable format enables all of this.\n\n## Technical Approach\n\n### 1. JSON Error Structure\n```json\n{\n  \"error\": {\n    \"code\": \"CAUT-A001\",\n    \"category\": \"authentication\",\n    \"message\": \"Authentication expired for Claude\",\n    \"provider\": \"claude\",\n    \"retryable\": false,\n    \"suggestions\": [\n      {\n        \"commands\": [\"caut auth refresh claude\"],\n        \"context\": \"Your OAuth token has expired.\",\n        \"auto_fixable\": false\n      }\n    ],\n    \"metadata\": {\n      \"timestamp\": \"2025-01-18T14:32:00Z\",\n      \"caut_version\": \"0.1.0\"\n    }\n  }\n}\n```\n\n### 2. Serialization Implementation\n- Create JsonError and JsonErrorBody structs with serde Serialize\n- Implement From\u003cCautError\u003e for JsonError conversion\n- Include code, category, message, provider, retryable, suggestions, metadata\n\n### 3. JSON Mode Error Output\n- When --json flag is present, output errors as JSON to stderr\n- Support --pretty for formatted JSON\n- AI agents can parse and act on the structured output\n\n### 4. Key Fields for AI Agents\n- code: Stable error code for programmatic handling\n- category: Error category (authentication, network, etc.)\n- retryable: Boolean flag for retry decisions\n- suggestions.commands: Copy-paste fix commands\n- suggestions.auto_fixable: Whether agent can fix automatically\n\n## Files to Create/Modify\n- src/error/json.rs: New file for JSON error types\n- src/error.rs: Add provider_name() method\n- src/main.rs: Use JSON error output when --json\n- src/cli/usage.rs: Propagate JSON mode for errors\n\n## Dependencies\n- Requires error taxonomy (v53)\n- Requires fix suggestions (1mj)\n\n## Acceptance Criteria\n- [ ] JSON format includes all error metadata\n- [ ] Code, category, retryable are always present\n- [ ] Suggestions serialized correctly\n- [ ] Pretty printing with --pretty flag\n- [ ] AI agents can parse and act on output\n\n## Testing Strategy\n- Test serialization for all error types\n- Validate JSON schema\n- Test parsing in Python/JS (agent simulation)\n- Test --json flag enables JSON errors","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T03:03:13.757632367-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T03:03:13.757632367-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-egm","depends_on_id":"coding_agent_usage_tracker-v53","type":"blocks","created_at":"2026-01-18T03:03:20.380294279-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-egm","depends_on_id":"coding_agent_usage_tracker-1mj","type":"blocks","created_at":"2026-01-18T03:03:20.440241086-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-ek0","title":"Offline: Display staleness indicators in output","description":"## Summary\nImplement visual indicators showing data freshness and source in CLI output.\n\n## Background\nWhen showing cached data, users need to know:\n1. How old the data is\n2. Why it's cached (error vs offline mode)\n3. Whether they should trust it\n\n## Technical Design\n\n### Staleness Display\n```rust\nimpl FetchOutcome {\n    pub fn format_with_staleness(\u0026self) -\u003e String {\n        let mut output = self.payload.format();\n        \n        match (\u0026self.source, \u0026self.staleness) {\n            (DataSource::Live, _) =\u003e {\n                // Fresh data, no indicator needed\n            }\n            (DataSource::Cached, Staleness::Fresh) =\u003e {\n                output.push_str(\u0026format!(\n                    \"\\n{} Cached data (fresh)\",\n                    style(\"‚Ñπ\").cyan()\n                ));\n            }\n            (DataSource::Cached, Staleness::Stale { age }) =\u003e {\n                output.push_str(\u0026format!(\n                    \"\\n{} Cached data ({} ago)\",\n                    style(\"‚ö†\").yellow(),\n                    format_duration(*age)\n                ));\n            }\n            (DataSource::Cached, Staleness::VeryStale { age }) =\u003e {\n                output.push_str(\u0026format!(\n                    \"\\n{} Very stale data ({} ago) - consider refreshing\",\n                    style(\"‚ö†\").red(),\n                    format_duration(*age)\n                ));\n            }\n            (DataSource::None, _) =\u003e {\n                output.push_str(\u0026format!(\n                    \"\\n{} No data available\",\n                    style(\"‚úó\").red()\n                ));\n            }\n        }\n        \n        // Show error if there was one\n        if let Some(error) = \u0026self.error {\n            output.push_str(\u0026format!(\n                \"\\n{} Fetch failed: {}\",\n                style(\"‚Ñπ\").dim(),\n                error\n            ));\n        }\n        \n        output\n    }\n}\n\nfn format_duration(d: Duration) -\u003e String {\n    let secs = d.as_secs();\n    if secs \u003c 60 {\n        format!(\"{}s\", secs)\n    } else if secs \u003c 3600 {\n        format!(\"{}m\", secs / 60)\n    } else if secs \u003c 86400 {\n        format!(\"{}h\", secs / 3600)\n    } else {\n        format!(\"{}d\", secs / 86400)\n    }\n}\n```\n\n### Visual Output Examples\n\n#### Fresh Data (no indicator)\n```\nClaude Code (oauth)                                          ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 62%\n  Primary: 62% used (resets in 2h 15m)\n  Secondary: 28% used (resets in 5d 12h)\n  ‚úì All systems operational\n```\n\n#### Cached Data (stale)\n```\nClaude Code (oauth)                                          ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 62%\n  Primary: 62% used (resets in 2h 15m)\n  Secondary: 28% used (resets in 5d 12h)\n  ‚úì All systems operational\n  ‚ö† Cached data (15m ago)\n  ‚Ñπ Fetch failed: Connection timeout\n```\n\n#### Very Stale Data\n```\nClaude Code (oauth)                                          ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 62%\n  Primary: 62% used (resets in 2h 15m)\n  ‚ö† Very stale data (2h ago) - consider refreshing\n  ‚Ñπ Fetch failed: Network unreachable\n```\n\n#### Offline Mode\n```\nClaude Code (oauth)                                          ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 62%\n  Primary: 62% used (resets in 2h 15m)\n  ‚Ñπ Offline mode - showing cached data (5m ago)\n```\n\n### Prompt Integration\nFor shell prompts, use compact staleness indicators:\n\n```rust\nimpl PromptCache {\n    pub fn format_for_prompt(\u0026self, entry: \u0026CacheEntry) -\u003e String {\n        let value = format!(\"{:.0}%\", entry.payload.usage.primary_percent());\n        \n        match entry.staleness() {\n            Staleness::Fresh =\u003e value,\n            Staleness::Stale { .. } =\u003e format!(\"~{}\", value),  // Tilde for stale\n            Staleness::VeryStale { .. } =\u003e format!(\"?{}\", value),  // Question for very stale\n        }\n    }\n}\n```\n\nPrompt output:\n- Fresh: `C:62%`\n- Stale: `~C:62%`\n- Very stale: `?C:62%`\n\n### Watch Mode Integration\n```rust\nimpl WatchMode {\n    fn render_with_staleness(\u0026self, outcome: \u0026FetchOutcome) {\n        let status_line = match (\u0026outcome.source, \u0026outcome.staleness) {\n            (DataSource::Live, _) =\u003e {\n                format!(\"Last updated: just now\")\n            }\n            (DataSource::Cached, staleness) =\u003e {\n                let age = staleness.age().map(|a| format_duration(a)).unwrap_or_default();\n                format!(\"Last updated: {} ago (cached)\", age)\n            }\n            (DataSource::None, _) =\u003e {\n                \"No data available\".to_string()\n            }\n        };\n        \n        self.render_footer(\u0026status_line);\n    }\n}\n```\n\n### Color Scheme\n| State | Color | Symbol |\n|-------|-------|--------|\n| Fresh | Default | (none) |\n| Cached Fresh | Cyan | ‚Ñπ |\n| Stale | Yellow | ‚ö† |\n| Very Stale | Red | ‚ö† |\n| Unavailable | Red | ‚úó |\n| Offline Mode | Blue | ‚Ñπ |\n\n## Acceptance Criteria\n- [ ] Fresh data has no staleness indicator\n- [ ] Cached data shows age\n- [ ] Stale data shows warning\n- [ ] Very stale data shows strong warning\n- [ ] Fetch errors displayed with cached data\n- [ ] Offline mode indicated\n- [ ] Prompt uses compact indicators (~, ?)\n- [ ] Watch mode shows staleness in footer\n- [ ] Colors appropriate for each state\n\n## Configuration\n```toml\n# ~/.config/caut/config.toml\n[display]\nshow_staleness = true\nshow_cache_source = true\nstaleness_colors = true\n```\n\n## Dependencies\n- Requires cache layer (sibling task)\n- Requires fallback logic (sibling task)\n- Integrates with CLI output\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:19:31.044295461-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:19:31.044295461-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-ek0","depends_on_id":"coding_agent_usage_tracker-0o5","type":"blocks","created_at":"2026-01-18T14:22:18.51096408-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-f9p","title":"Prediction: Handle edge cases (sustainable, no data, resets)","description":"## Task Overview\n\nEnsure prediction logic handles all edge cases gracefully, including sustainable usage, insufficient data, rate limit resets, and unusual patterns.\n\n## Parent EPIC\n[EPIC] Time-to-Limit Prediction (coding_agent_usage_tracker-swp)\n\n## Edge Cases to Handle\n\n### 1. Insufficient Data\nWhen history has fewer than 2 data points:\n\n```rust\nfn handle_insufficient_data() -\u003e PredictionResult {\n    PredictionResult {\n        status: PredictionStatus::Unknown,\n        message: \"Insufficient data for prediction (need more history)\".into(),\n        confidence: Confidence::None,\n    }\n}\n```\n\nDisplay: `\"Prediction: Collecting data... (available after ~5 minutes)\"`\n\n### 2. Zero or Negative Velocity\nUsage is stable or decreasing:\n\n```rust\nfn handle_stable_or_decreasing(velocity: f64) -\u003e PredictionResult {\n    if velocity \u003c -1.0 {\n        // Actively decreasing\n        PredictionResult {\n            status: PredictionStatus::Decreasing,\n            message: format!(\"Usage decreasing at {:.1}%/hour\", velocity.abs()),\n            confidence: Confidence::High,\n        }\n    } else {\n        // Essentially stable\n        PredictionResult {\n            status: PredictionStatus::Sustainable,\n            message: \"Usage stable - sustainable at current pace\".into(),\n            confidence: Confidence::High,\n        }\n    }\n}\n```\n\n### 3. Reset Detection\nUsage dropped suddenly (rate limit reset):\n\n```rust\nfn detect_and_handle_reset(\n    history: \u0026[StoredSnapshot],\n) -\u003e Option\u003cResetInfo\u003e {\n    for window in history.windows(2) {\n        let prev = \u0026window[0];\n        let curr = \u0026window[1];\n        \n        let prev_pct = prev.primary_used_pct.unwrap_or(0.0);\n        let curr_pct = curr.primary_used_pct.unwrap_or(0.0);\n        \n        // Detect reset: significant drop to near-zero\n        if prev_pct \u003e 50.0 \u0026\u0026 curr_pct \u003c 10.0 {\n            return Some(ResetInfo {\n                reset_time: curr.fetched_at,\n                dropped_from: prev_pct,\n                dropped_to: curr_pct,\n            });\n        }\n    }\n    None\n}\n\n// When calculating velocity, only use data since last reset\nfn velocity_since_reset(history: \u0026[StoredSnapshot]) -\u003e Option\u003cf64\u003e {\n    let reset = detect_last_reset(history);\n    let relevant_history = match reset {\n        Some(r) =\u003e history.iter()\n            .filter(|s| s.fetched_at \u003e= r.reset_time)\n            .collect(),\n        None =\u003e history.to_vec(),\n    };\n    \n    calculate_velocity(\u0026relevant_history, Duration::hours(1))\n}\n```\n\n### 4. Very High Velocity (Unusual Activity)\n\n```rust\nfn handle_unusual_velocity(velocity: f64) -\u003e Option\u003cWarning\u003e {\n    // More than 50% per hour is unusual\n    if velocity \u003e 50.0 {\n        Some(Warning {\n            level: WarningLevel::Info,\n            message: format!(\n                \"Unusually high usage rate ({:.0}%/hr) - may indicate batch processing\",\n                velocity\n            ),\n        })\n    } else {\n        None\n    }\n}\n```\n\n### 5. Already At or Near Limit\n\n```rust\nfn handle_at_limit(current_pct: f64, velocity: f64) -\u003e PredictionResult {\n    if current_pct \u003e= 95.0 {\n        PredictionResult {\n            status: PredictionStatus::AtLimit,\n            message: \"At or near limit - wait for reset\".into(),\n            confidence: Confidence::High,\n        }\n    } else if current_pct \u003e= 80.0 \u0026\u0026 velocity \u003e 5.0 {\n        let minutes = ((100.0 - current_pct) / velocity * 60.0) as i32;\n        PredictionResult {\n            status: PredictionStatus::WillHitLimit { minutes },\n            message: format!(\"Will hit limit in ~{}m at current pace\", minutes),\n            confidence: Confidence::Medium,\n        }\n    } else {\n        // Normal case\n        calculate_normal_prediction(current_pct, velocity)\n    }\n}\n```\n\n### 6. Provider Without Rate Limits\n\nSome providers may not have rate limit data:\n\n```rust\nfn handle_no_rate_limit_data(provider: \u0026Provider) -\u003e PredictionResult {\n    PredictionResult {\n        status: PredictionStatus::NotApplicable,\n        message: format!(\"{} does not report rate limit data\", provider),\n        confidence: Confidence::None,\n    }\n}\n```\n\n### 7. Stale History Data\n\n```rust\nfn check_data_freshness(history: \u0026[StoredSnapshot]) -\u003e DataFreshness {\n    let latest = history.first()?;\n    let age = Utc::now() - latest.fetched_at;\n    \n    match age {\n        d if d \u003c Duration::minutes(5) =\u003e DataFreshness::Fresh,\n        d if d \u003c Duration::minutes(30) =\u003e DataFreshness::Stale,\n        _ =\u003e DataFreshness::VeryStale,\n    }\n}\n\nfn prediction_with_freshness_warning(\n    prediction: PredictionResult,\n    freshness: DataFreshness,\n) -\u003e PredictionResult {\n    match freshness {\n        DataFreshness::Fresh =\u003e prediction,\n        DataFreshness::Stale =\u003e prediction.with_warning(\n            \"Based on data from ~30 minutes ago\"\n        ),\n        DataFreshness::VeryStale =\u003e PredictionResult {\n            status: PredictionStatus::Unknown,\n            message: \"Data too old for reliable prediction\".into(),\n            confidence: Confidence::None,\n        },\n    }\n}\n```\n\n## Confidence Levels\n\n```rust\nenum Confidence {\n    High,    // 10+ data points, consistent pattern\n    Medium,  // 5-10 data points, some variation\n    Low,     // 2-5 data points, limited data\n    None,    // Unable to calculate\n}\n```\n\n## Deliverables\n\n- [ ] Insufficient data handling\n- [ ] Stable/decreasing usage handling\n- [ ] Reset detection and handling\n- [ ] Unusual activity detection\n- [ ] At-limit handling\n- [ ] No-rate-limit handling\n- [ ] Stale data warnings\n- [ ] Confidence level calculation\n- [ ] Comprehensive test coverage for all cases\n\n## Acceptance Criteria\n\n- [ ] No panics or crashes for any input\n- [ ] Appropriate message for each edge case\n- [ ] Resets don't corrupt predictions\n- [ ] Confidence reflects data quality\n- [ ] User understands why prediction unavailable","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:09:38.095758487-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:09:38.095758487-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-f9p","depends_on_id":"coding_agent_usage_tracker-4n4","type":"blocks","created_at":"2026-01-18T14:21:45.29867931-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-fd9","title":"Unit tests for storage/cache.rs (caching layer)","description":"## Overview\nTest the caching layer for rate-limited API responses.\n\n## Target: src/storage/cache.rs\nCritical for: Performance, rate limit compliance\n\n## Test Cases\n1. **Cache Operations**\n   - Cache miss behavior\n   - Cache hit behavior\n   - Cache expiration (TTL)\n   - Cache invalidation\n\n2. **Cache Keys**\n   - Key generation for different providers\n   - Key uniqueness guarantees\n   - Account-specific caching\n\n3. **Storage Backend**\n   - File-based cache persistence\n   - Cache directory structure\n   - Size limits and eviction\n\n4. **Edge Cases**\n   - Concurrent access\n   - Partial writes/corruption\n   - Clock skew for TTL\n\n## Acceptance Criteria\n- [ ] Hit/miss/expiry paths tested\n- [ ] Key generation verified\n- [ ] File storage tested\n- [ ] TTL behavior verified with mock time","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:12:59.38228935-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:12:59.38228935-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-fd9","depends_on_id":"coding_agent_usage_tracker-u5h","type":"blocks","created_at":"2026-01-18T02:18:17.979335683-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-g71","title":"Implement rich terminal UI using rich_rust","description":"Replace basic text output in render/human.rs with rich terminal UI using the rich_rust library. Add colored progress bars, panels, tables, and better formatting for usage and cost displays.","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T01:01:18.451086636-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T01:37:51.563955362-05:00","closed_at":"2026-01-18T01:37:51.563955362-05:00","close_reason":"Already implemented - render/human.rs uses rich_rust with Panel, ProgressBar, Color, Style, Segment for full terminal UI"}
{"id":"coding_agent_usage_tracker-ggw","title":"Unit tests for core/config.rs (CLI configuration)","description":"## Overview\nTest the application configuration loading and management.\n\n## Target: src/storage/config.rs (6.6KB)\nCritical for: User settings, provider configuration\n\n## Test Cases\n\n### 1. Config Loading\n- Load from TOML file\n- Load from default location\n- Handle missing config (use defaults)\n- Handle malformed TOML\n\n### 2. Config Structure\n- All fields have sensible defaults\n- Optional fields handled correctly\n- Nested config sections\n\n### 3. Provider Configuration\n- Per-provider enable/disable\n- Provider-specific settings\n- API key configuration (without exposing keys in tests)\n\n### 4. Config Validation\n- Invalid values rejected\n- Type coercion (string to bool, etc.)\n- Path expansion (~ to home)\n\n### 5. Config Persistence\n- Save config to file\n- Round-trip (load ‚Üí modify ‚Üí save ‚Üí load)\n- Preserve unknown fields (forward compat)\n\n### 6. Environment Override\n- Env vars override config file\n- Config file overrides defaults\n- Priority: env \u003e file \u003e defaults\n\n## Existing Tests\nNote: config.rs already has some tests. Verify and extend:\n- default_config_is_valid\n- load_missing_file_returns_default\n- load_valid_toml\n- load_invalid_toml_returns_error\n- roundtrip_save_load\n\n## Acceptance Criteria\n- [ ] All existing tests documented\n- [ ] Missing paths added\n- [ ] Environment override tested\n- [ ] Forward compatibility verified","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:13:47.245153041-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T12:47:27.506071673-05:00","closed_at":"2026-01-18T12:47:27.506071673-05:00","close_reason":"Added 23 new unit tests to config.rs (51 total). Coverage includes: environment variable overrides (CAUT_PROVIDERS, CAUT_FORMAT, CAUT_TIMEOUT, CAUT_NO_COLOR, CAUT_VERBOSE, CAUT_PRETTY, CAUT_CONFIG, NO_COLOR standard), per-provider settings (enabled, api_base), nested config sections, forward compatibility (unknown fields ignored, partial config uses defaults), validation edge cases, and documented default values. All 314 lib tests pass.","dependencies":[{"issue_id":"coding_agent_usage_tracker-ggw","depends_on_id":"coding_agent_usage_tracker-u5h","type":"blocks","created_at":"2026-01-18T02:18:19.415156957-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-gld","title":"API: Add SSE endpoint for real-time updates","description":"## Summary\nImplement Server-Sent Events endpoint for real-time usage updates.\n\n## Background\nSSE provides a simple, HTTP-based way to push updates to clients:\n1. Single long-lived connection\n2. Automatic reconnection\n3. Works through proxies/firewalls\n4. Native browser support\n5. Simpler than WebSockets for one-way data\n\n## Technical Design\n\n### Event Types\n```rust\n#[derive(Debug, Clone, Serialize)]\n#[serde(tag = \"type\", content = \"data\")]\npub enum Event {\n    #[serde(rename = \"usage_updated\")]\n    UsageUpdated {\n        provider: String,\n        usage: UsageSnapshot,\n        status: Option\u003cStatusPayload\u003e,\n        timestamp: DateTime\u003cUtc\u003e,\n    },\n    \n    #[serde(rename = \"status_changed\")]\n    StatusChanged {\n        provider: String,\n        old_indicator: StatusIndicator,\n        new_indicator: StatusIndicator,\n        description: Option\u003cString\u003e,\n    },\n    \n    #[serde(rename = \"budget_alert\")]\n    BudgetAlert {\n        provider: String,\n        alert_type: String,\n        message: String,\n    },\n    \n    #[serde(rename = \"heartbeat\")]\n    Heartbeat {\n        timestamp: DateTime\u003cUtc\u003e,\n    },\n}\n\nimpl Event {\n    pub fn to_sse(\u0026self) -\u003e String {\n        let event_type = match self {\n            Event::UsageUpdated { .. } =\u003e \"usage_updated\",\n            Event::StatusChanged { .. } =\u003e \"status_changed\",\n            Event::BudgetAlert { .. } =\u003e \"budget_alert\",\n            Event::Heartbeat { .. } =\u003e \"heartbeat\",\n        };\n        \n        let data = serde_json::to_string(self).unwrap();\n        \n        format!(\"event: {}\\ndata: {}\\n\\n\", event_type, data)\n    }\n}\n```\n\n### Event Broadcasting\n```rust\nuse tokio::sync::broadcast;\n\npub struct EventBroadcaster {\n    tx: broadcast::Sender\u003cEvent\u003e,\n}\n\nimpl EventBroadcaster {\n    pub fn new(capacity: usize) -\u003e Self {\n        let (tx, _) = broadcast::channel(capacity);\n        Self { tx }\n    }\n    \n    pub fn subscribe(\u0026self) -\u003e broadcast::Receiver\u003cEvent\u003e {\n        self.tx.subscribe()\n    }\n    \n    pub fn send(\u0026self, event: Event) {\n        // Ignore send errors (no subscribers)\n        self.tx.send(event).ok();\n    }\n}\n```\n\n### SSE Handler\n```rust\nuse axum::response::sse::{Event as SseEvent, Sse};\nuse futures::stream::{self, Stream};\nuse std::convert::Infallible;\n\npub async fn sse_events(\n    State(state): State\u003cArc\u003cAppState\u003e\u003e,\n    Query(params): Query\u003cSseQueryParams\u003e,\n) -\u003e Sse\u003cimpl Stream\u003cItem = Result\u003cSseEvent, Infallible\u003e\u003e\u003e {\n    let mut rx = state.broadcaster.subscribe();\n    \n    // Optional: send current state as initial event\n    let initial_events = if params.include_initial.unwrap_or(true) {\n        let cache = state.cache.read().await;\n        cache\n            .iter()\n            .map(|(provider, entry)| Event::UsageUpdated {\n                provider: provider.clone(),\n                usage: entry.payload.usage.clone(),\n                status: entry.payload.status.clone(),\n                timestamp: entry.cached_at,\n            })\n            .collect::\u003cVec\u003c_\u003e\u003e()\n    } else {\n        Vec::new()\n    };\n    \n    // Filter by provider if requested\n    let provider_filter = params.provider.clone();\n    \n    let stream = async_stream::stream! {\n        // Send initial events\n        for event in initial_events {\n            yield Ok(SseEvent::default()\n                .event(event.event_type())\n                .data(serde_json::to_string(\u0026event).unwrap()));\n        }\n        \n        // Stream updates\n        let mut heartbeat_interval = tokio::time::interval(Duration::from_secs(30));\n        \n        loop {\n            tokio::select! {\n                result = rx.recv() =\u003e {\n                    match result {\n                        Ok(event) =\u003e {\n                            // Apply filter\n                            if let Some(ref filter) = provider_filter {\n                                if !event.matches_provider(filter) {\n                                    continue;\n                                }\n                            }\n                            \n                            yield Ok(SseEvent::default()\n                                .event(event.event_type())\n                                .data(serde_json::to_string(\u0026event).unwrap()));\n                        }\n                        Err(broadcast::error::RecvError::Lagged(_)) =\u003e {\n                            // Client too slow, skip events\n                            continue;\n                        }\n                        Err(broadcast::error::RecvError::Closed) =\u003e {\n                            break;\n                        }\n                    }\n                }\n                _ = heartbeat_interval.tick() =\u003e {\n                    let heartbeat = Event::Heartbeat {\n                        timestamp: Utc::now(),\n                    };\n                    yield Ok(SseEvent::default()\n                        .event(\"heartbeat\")\n                        .data(serde_json::to_string(\u0026heartbeat).unwrap()));\n                }\n            }\n        }\n    };\n    \n    Sse::new(stream).keep_alive(\n        axum::response::sse::KeepAlive::new()\n            .interval(Duration::from_secs(15))\n            .text(\"keep-alive\"),\n    )\n}\n\n#[derive(Deserialize)]\npub struct SseQueryParams {\n    provider: Option\u003cString\u003e,       // Filter to specific provider\n    include_initial: Option\u003cbool\u003e,  // Include current state on connect\n}\n```\n\n### Integration with Refresh Scheduler\n```rust\nimpl RefreshScheduler {\n    async fn do_refresh(\u0026self, provider: \u0026str) {\n        if let Some(fetcher) = self.state.fetchers.get(provider) {\n            match fetcher.fetch().await {\n                Ok(payload) =\u003e {\n                    // Update cache\n                    let mut cache = self.state.cache.write().await;\n                    let old_status = cache.get(provider)\n                        .and_then(|e| e.payload.status.clone());\n                    \n                    cache.insert(provider.to_string(), CacheEntry::new(payload.clone()));\n                    drop(cache);\n                    \n                    // Broadcast usage update\n                    self.state.broadcaster.send(Event::UsageUpdated {\n                        provider: provider.to_string(),\n                        usage: payload.usage.clone(),\n                        status: payload.status.clone(),\n                        timestamp: Utc::now(),\n                    });\n                    \n                    // Check for status change\n                    if let (Some(old), Some(new)) = (\u0026old_status, \u0026payload.status) {\n                        if old.indicator != new.indicator {\n                            self.state.broadcaster.send(Event::StatusChanged {\n                                provider: provider.to_string(),\n                                old_indicator: old.indicator.clone(),\n                                new_indicator: new.indicator.clone(),\n                                description: new.description.clone(),\n                            });\n                        }\n                    }\n                }\n                Err(e) =\u003e {\n                    warn!(\"Refresh failed: {}\", e);\n                }\n            }\n        }\n    }\n}\n```\n\n## Client Usage Examples\n\n### JavaScript/Browser\n```javascript\nconst events = new EventSource('http://localhost:8420/api/v1/events');\n\nevents.addEventListener('usage_updated', (e) =\u003e {\n    const data = JSON.parse(e.data);\n    console.log(`${data.provider}: ${data.usage.primary.used_percent}%`);\n});\n\nevents.addEventListener('status_changed', (e) =\u003e {\n    const data = JSON.parse(e.data);\n    console.log(`${data.provider} status: ${data.new_indicator}`);\n});\n\nevents.addEventListener('heartbeat', () =\u003e {\n    console.log('Connection alive');\n});\n\nevents.onerror = () =\u003e {\n    console.log('Connection lost, will reconnect...');\n};\n```\n\n### curl\n```bash\ncurl -N http://localhost:8420/api/v1/events\n\n# Filter to specific provider\ncurl -N 'http://localhost:8420/api/v1/events?provider=claude'\n```\n\n## Acceptance Criteria\n- [ ] SSE endpoint streams events\n- [ ] Initial state sent on connect\n- [ ] Usage updates broadcast\n- [ ] Status changes broadcast\n- [ ] Heartbeat keeps connection alive\n- [ ] Provider filtering works\n- [ ] Reconnection works (client-side)\n- [ ] Slow clients don't block others\n\n## Event Flow\n```\nClient connects to /api/v1/events\n    ‚Üì\nServer sends initial state (all providers)\n    ‚Üì\nEvery 60s: Refresh scheduler fetches data\n    ‚Üì\nOn update: Broadcaster sends event\n    ‚Üì\nClient receives SSE event\n    ‚Üì\nEvery 30s: Heartbeat sent\n```\n\n## Dependencies\n- Requires axum server setup (sibling task)\n- Requires caching with background refresh (sibling task)\n- Uses tokio broadcast channel for pub/sub\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:21:00.042227408-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:21:00.042227408-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-gld","depends_on_id":"coding_agent_usage_tracker-vv4","type":"blocks","created_at":"2026-01-18T14:22:24.280109255-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-h2s","title":"[EPIC] Parallel Fetching with Graceful Degradation","description":"## Overview\n\nTransform the usage fetching system to run provider queries in parallel and gracefully handle partial failures, showing available results even when some providers fail.\n\n## Strategic Rationale\n\nThis is the #2 priority improvement because:\n\n1. **Immediate performance improvement**: Going from sequential to parallel fetching provides 3-5x speedup for multi-provider queries. Every `--provider all` user benefits immediately.\n\n2. **Reliability transformation**: Current behavior - if one provider fails, users might get nothing or confusing errors. New behavior - always show what's available with clear warnings for failures.\n\n3. **Already have infrastructure**: The codebase uses tokio async. Implementation is straightforward with futures::join_all.\n\n4. **User expectation alignment**: Modern CLI tools should be fast and resilient. Sequential fetching with all-or-nothing failure modes feels dated.\n\n## Current vs. Desired Behavior\n\n### Before (Sequential, Fragile)\n```\n$ caut usage --provider all\n# Takes 8+ seconds (sequential fetches)\n# If one provider times out, entire command may fail or hang\n```\n\n### After (Parallel, Resilient)\n```\n$ caut usage --provider all\n# Takes 2-3 seconds (parallel fetches)\n# Shows partial results with warnings\n\n‚ï≠‚îÄ Claude (oauth) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n‚îÇ Session: 45% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 2h reset‚îÇ\n‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n\n‚ï≠‚îÄ Codex (cli) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n‚îÇ Account: user@example.com         ‚îÇ\n‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n\n‚ö† Gemini: Request timed out after 5s\n‚ö† Cursor: Authentication required (run: cursor auth login)\n\nCompleted in 2.3s (2 succeeded, 2 failed)\n```\n\n## Technical Approach\n\n1. **Parallel execution**: Use `futures::future::join_all` to run all provider fetches concurrently\n2. **Timeout per provider**: Each provider gets its own timeout (default 10s)\n3. **Result aggregation**: Collect successes and failures separately\n4. **Partial rendering**: Render successful results, then list failures with suggestions\n5. **Summary footer**: Show timing and success/failure counts\n\n## Success Criteria\n\n- [ ] Multi-provider fetch is at least 3x faster than sequential\n- [ ] Partial failures don't prevent showing successful results\n- [ ] Failed providers show clear error messages with suggestions\n- [ ] Summary shows timing and counts\n- [ ] Works with --json output (failures in separate array)\n\n## Architecture Notes\n\nThe key insight is that provider fetches are independent - there's no reason to wait for Claude before starting Codex. The current sequential approach is a holdover from simpler implementations.","status":"open","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:50:13.289726838-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:50:13.289726838-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-h2s","depends_on_id":"coding_agent_usage_tracker-d30","type":"blocks","created_at":"2026-01-18T02:51:23.173863706-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-h3p","title":"Implement token-accounts CLI commands","description":"The token-accounts list and convert subcommands return placeholders. Need to wire up the storage/token_accounts.rs logic to the CLI.","status":"closed","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T00:47:03.726869357-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T01:34:26.154951084-05:00","closed_at":"2026-01-18T01:34:26.154951084-05:00","close_reason":"Implemented token-accounts list and convert CLI commands. List shows accounts for specific or all providers. Convert handles codexbar\u003c-\u003ecaut format conversion (macOS only for CodexBar paths). All tests pass."}
{"id":"coding_agent_usage_tracker-hlt","title":"API: Implement security controls and validation","description":"Create src/api/security.rs. SecurityConfig: localhost_only (default true), require_auth, api_key, allowed_ips, log_requests. localhost_guard middleware rejects non-loopback IPs with 403. api_key_auth middleware checks Authorization: Bearer header. validate_server_config() returns warnings for non-localhost binding, missing auth when exposed. request_logger middleware logs method, path, status, duration, remote_addr. Proper HTTP status codes: 401 Unauthorized, 403 Forbidden.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:16:09.955830546-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:16:09.955830546-05:00"}
{"id":"coding_agent_usage_tracker-hws","title":"History: Implement history storage layer and queries","description":"## Task Overview\n\nImplement the Rust storage layer for reading/writing usage history. Provides the data access API that other components will use.\n\n## Parent EPIC\n[EPIC] Historical Usage Tracking with Trend Visualization (coding_agent_usage_tracker-smv)\n\n## Technical Requirements\n\n### Storage Module API\n\n```rust\n// src/storage/history.rs\n\npub struct HistoryStore {\n    conn: Connection,\n}\n\nimpl HistoryStore {\n    /// Create or open history database\n    pub fn open(path: \u0026Path) -\u003e Result\u003cSelf\u003e;\n    \n    /// Record a usage snapshot\n    pub fn record_snapshot(\u0026self, snapshot: \u0026UsageSnapshot, provider: \u0026Provider) -\u003e Result\u003ci64\u003e;\n    \n    /// Get snapshots for a provider within time range\n    pub fn get_snapshots(\n        \u0026self,\n        provider: \u0026Provider,\n        from: DateTime\u003cUtc\u003e,\n        to: DateTime\u003cUtc\u003e,\n    ) -\u003e Result\u003cVec\u003cStoredSnapshot\u003e\u003e;\n    \n    /// Get latest snapshot for each provider\n    pub fn get_latest_all(\u0026self) -\u003e Result\u003cHashMap\u003cProvider, StoredSnapshot\u003e\u003e;\n    \n    /// Get usage velocity (% change per hour) over recent window\n    pub fn get_velocity(\n        \u0026self,\n        provider: \u0026Provider,\n        window: Duration,\n    ) -\u003e Result\u003cOption\u003cf64\u003e\u003e;\n    \n    /// Get aggregated stats for time period\n    pub fn get_stats(\n        \u0026self,\n        provider: \u0026Provider,\n        period: StatsPeriod,\n    ) -\u003e Result\u003cUsageStats\u003e;\n    \n    /// Cleanup old snapshots\n    pub fn cleanup(\u0026self, retention_days: i32) -\u003e Result\u003cusize\u003e;\n}\n\n#[derive(Debug)]\npub struct StoredSnapshot {\n    pub id: i64,\n    pub provider: Provider,\n    pub fetched_at: DateTime\u003cUtc\u003e,\n    pub source: String,\n    pub primary_used_pct: Option\u003cf64\u003e,\n    pub secondary_used_pct: Option\u003cf64\u003e,\n    pub tertiary_used_pct: Option\u003cf64\u003e,\n    pub cost_today_usd: Option\u003cf64\u003e,\n    pub cost_mtd_usd: Option\u003cf64\u003e,\n    pub credits_remaining: Option\u003cf64\u003e,\n}\n\npub struct UsageStats {\n    pub average_primary_pct: f64,\n    pub max_primary_pct: f64,\n    pub min_primary_pct: f64,\n    pub total_cost: f64,\n    pub sample_count: usize,\n}\n\npub enum StatsPeriod {\n    Today,\n    Yesterday,\n    Last7Days,\n    Last30Days,\n    ThisMonth,\n    LastMonth,\n    Custom { from: DateTime\u003cUtc\u003e, to: DateTime\u003cUtc\u003e },\n}\n```\n\n### Query Optimization\n\n- Use prepared statements for repeated queries\n- Proper parameterization (no SQL injection)\n- Efficient time range queries using indexes\n- Limit result sets for memory efficiency\n\n```rust\nimpl HistoryStore {\n    fn prepare_statements(\u0026self) -\u003e Result\u003cPreparedStatements\u003e {\n        Ok(PreparedStatements {\n            insert_snapshot: self.conn.prepare(\n                \"INSERT INTO usage_snapshots (...) VALUES (?, ?, ?, ...)\"\n            )?,\n            get_by_time_range: self.conn.prepare(\n                \"SELECT * FROM usage_snapshots \n                 WHERE provider = ? AND fetched_at BETWEEN ? AND ?\n                 ORDER BY fetched_at DESC\n                 LIMIT ?\"\n            )?,\n            // ...\n        })\n    }\n}\n```\n\n### Thread Safety\n\n- Database connection per-thread or use connection pool\n- Consider r2d2 for connection pooling if needed\n- Ensure atomic writes with transactions where needed\n\n## Integration Points\n\n- Called by fetch pipeline to record snapshots\n- Called by history command to retrieve data\n- Called by prediction logic for velocity calculation\n- Called by TUI dashboard for sparklines\n\n## Deliverables\n\n- [ ] `src/storage/history.rs` module\n- [ ] Public API as specified above\n- [ ] Comprehensive unit tests\n- [ ] Integration tests with real database\n- [ ] Error handling with proper error types\n\n## Acceptance Criteria\n\n- [ ] All API methods implemented and tested\n- [ ] Queries return correct results\n- [ ] Performance: \u003c10ms for typical queries\n- [ ] Proper error handling (no panics)\n- [ ] Thread-safe operation","status":"closed","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:59:07.556680955-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T17:05:22.58244104-05:00","closed_at":"2026-01-18T17:05:22.58244104-05:00","close_reason":"Implemented HistoryStore + queries + tests","dependencies":[{"issue_id":"coding_agent_usage_tracker-hws","depends_on_id":"coding_agent_usage_tracker-i3v","type":"blocks","created_at":"2026-01-18T14:21:40.518996467-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-i3v","title":"History: Design usage history schema and migrations","description":"## Task Overview\n\nDesign and implement the SQLite schema for storing usage history snapshots. This is the data foundation for all historical features.\n\n## Parent EPIC\n[EPIC] Historical Usage Tracking with Trend Visualization (coding_agent_usage_tracker-smv)\n\n## Technical Requirements\n\n### Schema Design\n\n```sql\n-- Core snapshots table\nCREATE TABLE usage_snapshots (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    provider TEXT NOT NULL,\n    fetched_at TEXT NOT NULL,  -- ISO8601 timestamp\n    source TEXT NOT NULL,       -- fetch source (oauth, cli, web, etc.)\n    \n    -- Primary rate window\n    primary_used_pct REAL,\n    primary_window_minutes INTEGER,\n    primary_resets_at TEXT,\n    \n    -- Secondary rate window  \n    secondary_used_pct REAL,\n    secondary_window_minutes INTEGER,\n    secondary_resets_at TEXT,\n    \n    -- Tertiary rate window (if applicable)\n    tertiary_used_pct REAL,\n    tertiary_window_minutes INTEGER,\n    tertiary_resets_at TEXT,\n    \n    -- Cost data\n    cost_today_usd REAL,\n    cost_mtd_usd REAL,\n    \n    -- Credits (for providers like Codex)\n    credits_remaining REAL,\n    \n    -- Identity info (denormalized for query simplicity)\n    account_email TEXT,\n    account_org TEXT,\n    \n    -- Metadata\n    fetch_duration_ms INTEGER,\n    created_at TEXT DEFAULT (datetime('now'))\n);\n\n-- Indexes for common queries\nCREATE INDEX idx_snapshots_provider_time ON usage_snapshots(provider, fetched_at DESC);\nCREATE INDEX idx_snapshots_fetched_at ON usage_snapshots(fetched_at DESC);\n\n-- Schema version tracking\nCREATE TABLE IF NOT EXISTS schema_migrations (\n    version INTEGER PRIMARY KEY,\n    applied_at TEXT DEFAULT (datetime('now'))\n);\n```\n\n### Migration Strategy\n\n1. Check current schema version\n2. Apply migrations sequentially\n3. Handle existing databases gracefully\n4. Rollback capability for safety\n\n```rust\nconst MIGRATIONS: \u0026[\u0026str] = \u0026[\n    // v1: Initial schema\n    include_str!(\"../migrations/001_usage_snapshots.sql\"),\n    // v2: Add cost fields\n    include_str!(\"../migrations/002_add_cost_fields.sql\"),\n    // ...\n];\n\nfn run_migrations(conn: \u0026Connection) -\u003e Result\u003c()\u003e {\n    let current_version = get_schema_version(conn)?;\n    for (idx, migration) in MIGRATIONS.iter().enumerate() {\n        let version = idx + 1;\n        if version \u003e current_version {\n            conn.execute_batch(migration)?;\n            set_schema_version(conn, version)?;\n        }\n    }\n    Ok(())\n}\n```\n\n## Data Retention\n\n- Default: 90 days of history\n- Configurable via config file\n- Auto-cleanup on startup and periodically\n- Vacuum after cleanup for space reclamation\n\n```rust\nfn cleanup_old_snapshots(conn: \u0026Connection, retention_days: i32) -\u003e Result\u003cusize\u003e {\n    let cutoff = Utc::now() - Duration::days(retention_days as i64);\n    let deleted = conn.execute(\n        \"DELETE FROM usage_snapshots WHERE fetched_at \u003c ?\",\n        [cutoff.to_rfc3339()],\n    )?;\n    if deleted \u003e 0 {\n        conn.execute_batch(\"VACUUM\")?;\n    }\n    Ok(deleted)\n}\n```\n\n## Deliverables\n\n- [ ] Schema SQL file(s) in migrations/ directory\n- [ ] Migration runner in storage module\n- [ ] Schema version tracking\n- [ ] Data retention/cleanup logic\n- [ ] Unit tests for migrations\n- [ ] Documentation of schema\n\n## Acceptance Criteria\n\n- [ ] Fresh database creates schema correctly\n- [ ] Existing databases migrate without data loss\n- [ ] Indexes created for performance\n- [ ] Cleanup removes old data correctly\n- [ ] Schema documented in code comments","status":"closed","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:59:04.924498473-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T16:59:30.840690983-05:00","closed_at":"2026-01-18T16:59:30.840690983-05:00","close_reason":"Completed schema/migrations + retention + tests"}
{"id":"coding_agent_usage_tracker-i9x","title":"TUI: Design and implement core dashboard layout with ratatui","description":"## Summary\nDesign and implement the core TUI layout using ratatui with responsive panels.\n\n## Background\nThe current watch mode is text-based. A proper TUI dashboard provides:\n1. At-a-glance status for all providers\n2. Real-time updating without screen flicker\n3. Keyboard navigation\n4. Responsive layout that adapts to terminal size\n\n## Technical Design\n\n### TUI Framework Selection\nUsing `ratatui` (formerly tui-rs) because:\n- Actively maintained\n- Good cross-platform support\n- Flexible widget system\n- Works with crossterm backend\n\n### Dashboard Layout\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  caut dashboard                                        [?] Help  [q] Quit‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ  Claude                            ‚îÇ  Codex                              ‚îÇ\n‚îÇ  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 42%         ‚îÇ  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 71%          ‚îÇ\n‚îÇ  Primary: 42% (resets 2h 15m)     ‚îÇ  Primary: 71% (resets 45m)         ‚îÇ\n‚îÇ  Secondary: 28% (resets 6d)       ‚îÇ                                     ‚îÇ\n‚îÇ  ‚úì All systems operational        ‚îÇ  ‚ö† Minor service disruption        ‚îÇ\n‚îÇ  Auth: Valid (expires 6h)         ‚îÇ  Credits: $47.50 remaining          ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ  OpenRouter                        ‚îÇ  Cursor                             ‚îÇ\n‚îÇ  ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 18%         ‚îÇ  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 89%          ‚îÇ\n‚îÇ  Fast: 18%  Slow: 5%              ‚îÇ  Primary: 89% (resets 3h)           ‚îÇ\n‚îÇ  ‚úì All systems operational        ‚îÇ  ‚ö† Approaching limit                ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ  History (last 24h)                          ‚îÇ Budget Status             ‚îÇ\n‚îÇ  ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ         ‚îÇ Daily: $4.50/$10 ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë   ‚îÇ\n‚îÇ  Claude ‚îÄ‚îÄ‚îÄ‚îÄ  Codex ¬∑¬∑¬∑¬∑           ‚îÇ Weekly: $28/$50  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n‚îÇ Last updated: 2 seconds ago                    Press 'r' to refresh now  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n### Core Layout Implementation\n```rust\nuse ratatui::{\n    layout::{Constraint, Direction, Layout, Rect},\n    widgets::{Block, Borders, Paragraph},\n    Frame,\n};\n\npub struct Dashboard {\n    providers: Vec\u003cProviderPanel\u003e,\n    history_panel: HistoryPanel,\n    budget_panel: BudgetPanel,\n    selected_panel: usize,\n}\n\nimpl Dashboard {\n    pub fn render(\u0026self, frame: \u0026mut Frame) {\n        let chunks = Layout::default()\n            .direction(Direction::Vertical)\n            .constraints([\n                Constraint::Length(1),      // Header\n                Constraint::Min(10),        // Main content\n                Constraint::Length(3),      // History/Budget\n                Constraint::Length(1),      // Footer\n            ])\n            .split(frame.size());\n        \n        self.render_header(frame, chunks[0]);\n        self.render_providers(frame, chunks[1]);\n        self.render_bottom_panels(frame, chunks[2]);\n        self.render_footer(frame, chunks[3]);\n    }\n    \n    fn render_providers(\u0026self, frame: \u0026mut Frame, area: Rect) {\n        // Responsive grid layout based on terminal width\n        let cols = if area.width \u003e= 120 { 4 }\n                  else if area.width \u003e= 80 { 2 }\n                  else { 1 };\n        \n        let provider_chunks = self.create_grid(area, cols, self.providers.len());\n        \n        for (i, (panel, chunk)) in self.providers.iter()\n            .zip(provider_chunks.iter())\n            .enumerate() \n        {\n            let selected = i == self.selected_panel;\n            panel.render(frame, *chunk, selected);\n        }\n    }\n}\n```\n\n### Responsive Behavior\n```rust\nimpl Dashboard {\n    fn layout_for_width(\u0026self, width: u16) -\u003e LayoutMode {\n        match width {\n            0..=60 =\u003e LayoutMode::SingleColumn,\n            61..=100 =\u003e LayoutMode::TwoColumn,\n            101..=140 =\u003e LayoutMode::ThreeColumn,\n            _ =\u003e LayoutMode::FourColumn,\n        }\n    }\n    \n    fn handle_resize(\u0026mut self, width: u16, height: u16) {\n        self.layout_mode = self.layout_for_width(width);\n        // Recalculate panel sizes\n        // Hide optional panels if height too small\n    }\n}\n```\n\n## Dependencies\n```toml\n# Cargo.toml\n[dependencies]\nratatui = \"0.26\"\ncrossterm = \"0.27\"\n```\n\n## Acceptance Criteria\n- [ ] Dashboard renders correctly\n- [ ] Layout adapts to terminal size\n- [ ] No flicker on updates\n- [ ] Header and footer display correctly\n- [ ] Provider panels arranged in grid\n- [ ] Bottom panels (history/budget) render\n- [ ] Smooth resize handling\n\n## Implementation Notes\n- Use double-buffering to prevent flicker\n- Render at 1 FPS to reduce CPU usage (increase on updates)\n- Consider terminal color scheme detection\n- Handle very small terminals gracefully (minimum size warning)\n\n## Dependencies\n- None (foundational for TUI)\n- Used by all other TUI tasks\n\n## Testing\n- Unit tests for layout calculations\n- Manual testing on various terminal sizes\n- Test with tmux, screen, native terminals\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:15:28.638318133-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:15:28.638318133-05:00"}
{"id":"coding_agent_usage_tracker-isd","title":"[EPIC] API Server Mode for Local Integrations","description":"## Overview\n\nRun caut as a local HTTP server that other tools can query for usage data. This enables an ecosystem of integrations - custom dashboards, Raycast extensions, automation scripts, and other development tools can all consume caut data.\n\n## Strategic Importance (Why P2)\n\n- **Enables ecosystem**: Power users build custom integrations\n- **Clean architecture**: caut becomes a \"usage data service\"\n- **Future-proof**: Opens doors for community-built tools\n- **Power user feature**: Narrower audience but high value for them\n\n## User Value Proposition\n\n```bash\n$ caut serve --port 8420\ncaut API server running on http://localhost:8420\n\nEndpoints:\n  GET /usage           - All providers\n  GET /usage/:provider - Single provider  \n  GET /history         - Historical data\n  GET /health          - Server health check\n\nPress Ctrl+C to stop.\n```\n\n```bash\n# Query from any tool\n$ curl localhost:8420/usage | jq .claude.primary.used_percent\n65.5\n\n$ curl localhost:8420/usage/claude\n{\n  \"provider\": \"claude\",\n  \"primary\": {\n    \"used_percent\": 65.5,\n    \"resets_in_minutes\": 145\n  },\n  \"secondary\": {\n    \"used_percent\": 42.0,\n    \"resets_in_minutes\": 8640\n  },\n  \"cost_today\": 12.34,\n  \"status\": \"operational\",\n  \"updated_at\": \"2026-01-18T12:34:56Z\"\n}\n```\n\n### Use Cases\n\n1. **Custom menubar apps**: macOS/Windows status bar showing usage\n2. **Raycast/Alfred extensions**: Quick usage lookup\n3. **Grafana dashboards**: Long-term usage visualization\n4. **CI/CD pipelines**: Fail builds if usage too high\n5. **Slack bots**: Team usage notifications\n6. **Integration with other dev tools**: IDE extensions, etc.\n\n## Technical Approach\n\n### HTTP Server with Axum\n\n```rust\nuse axum::{Router, routing::get, Json};\n\nasync fn serve(port: u16) -\u003e Result\u003c()\u003e {\n    let app = Router::new()\n        .route(\"/health\", get(handle_health))\n        .route(\"/usage\", get(handle_all_usage))\n        .route(\"/usage/:provider\", get(handle_provider_usage))\n        .route(\"/history\", get(handle_history))\n        .route(\"/history/:provider\", get(handle_provider_history))\n        .route(\"/budgets\", get(handle_budgets))\n        .layer(CorsLayer::permissive());  // Local only, permissive OK\n    \n    let addr = SocketAddr::from(([127, 0, 0, 1], port));\n    println!(\"caut API server running on http://{}\", addr);\n    \n    axum::Server::bind(\u0026addr)\n        .serve(app.into_make_service())\n        .await\n}\n```\n\n### Endpoint Handlers\n\n```rust\nasync fn handle_all_usage(State(state): State\u003cAppState\u003e) -\u003e Json\u003cAllUsageResponse\u003e {\n    // Reuse existing fetch logic, same as `caut usage --json`\n    let snapshots = fetch_all_providers(\u0026state.config).await;\n    Json(AllUsageResponse::from(snapshots))\n}\n\nasync fn handle_provider_usage(\n    State(state): State\u003cAppState\u003e,\n    Path(provider): Path\u003cString\u003e,\n) -\u003e Result\u003cJson\u003cProviderUsageResponse\u003e, StatusCode\u003e {\n    let provider = Provider::from_str(\u0026provider)\n        .map_err(|_| StatusCode::NOT_FOUND)?;\n    \n    let snapshot = fetch_provider(\u0026state.config, \u0026provider).await\n        .map_err(|_| StatusCode::SERVICE_UNAVAILABLE)?;\n    \n    Ok(Json(ProviderUsageResponse::from(snapshot)))\n}\n```\n\n### Caching Layer\n\nAvoid hammering providers on every HTTP request:\n\n```rust\nasync fn handle_all_usage(State(state): State\u003cAppState\u003e) -\u003e Json\u003cAllUsageResponse\u003e {\n    // Check cache first\n    if let Some(cached) = state.cache.get(\"all_usage\").await {\n        if cached.age() \u003c Duration::from_secs(30) {\n            return Json(cached.data);\n        }\n    }\n    \n    // Fetch fresh data\n    let fresh = fetch_all_providers(\u0026state.config).await;\n    state.cache.set(\"all_usage\", fresh.clone()).await;\n    \n    Json(fresh)\n}\n```\n\n### Server-Sent Events for Real-Time\n\nOptional: streaming updates for dashboards\n\n```rust\nasync fn handle_stream() -\u003e Sse\u003cimpl Stream\u003cItem = Result\u003cEvent, Infallible\u003e\u003e\u003e {\n    let stream = IntervalStream::new(interval(Duration::from_secs(30)))\n        .then(|_| async {\n            let data = fetch_all_providers().await;\n            Ok(Event::default().json_data(data).unwrap())\n        });\n    \n    Sse::new(stream).keep_alive(KeepAlive::default())\n}\n```\n\n## API Endpoints\n\n| Endpoint | Method | Description |\n|----------|--------|-------------|\n| `/health` | GET | Server health check |\n| `/usage` | GET | All providers usage |\n| `/usage/:provider` | GET | Single provider usage |\n| `/history` | GET | Historical data (query params for filtering) |\n| `/history/:provider` | GET | Provider-specific history |\n| `/budgets` | GET | Budget status |\n| `/stream` | GET | SSE real-time updates |\n\n## Configuration\n\n```bash\n$ caut serve --help\nRun caut as an HTTP API server\n\nOptions:\n  -p, --port \u003cPORT\u003e      Port to listen on [default: 8420]\n  -b, --bind \u003cADDR\u003e      Address to bind [default: 127.0.0.1]\n  --cache-ttl \u003cSECS\u003e     Cache TTL in seconds [default: 30]\n  --cors                 Enable CORS (default: enabled for localhost)\n```\n\n## Security Considerations\n\n- **Localhost only by default**: Bind to 127.0.0.1, not 0.0.0.0\n- **No auth needed**: Local access only, trust the user\n- **CORS permissive**: Needed for browser-based tools\n- **Warning on non-local bind**: Clearly warn if exposing to network\n\n## Success Criteria\n\n- [ ] Server starts and responds to health checks\n- [ ] All usage endpoints return correct data\n- [ ] History endpoint with time range filtering\n- [ ] Caching prevents excessive provider calls\n- [ ] SSE streaming works for real-time updates\n- [ ] Clean shutdown on Ctrl+C\n- [ ] Clear documentation of all endpoints\n\n## Dependencies\n\n- **Benefits from**: All core features (history, budgets, etc.)\n- **New dependency**: axum (lightweight, async-first HTTP)\n- **Optional**: tower-http for middleware\n\n## Considerations\n\n- Port conflicts: What if 8420 is in use?\n- Daemonization: Should there be a `--daemon` mode?\n- Systemd integration: Service file for always-on operation\n- Log output: Structured logging for debugging","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:58:07.308109376-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:58:07.308109376-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-isd","depends_on_id":"coding_agent_usage_tracker-v3f","type":"blocks","created_at":"2026-01-18T14:21:34.434014002-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-isd","depends_on_id":"coding_agent_usage_tracker-s46","type":"blocks","created_at":"2026-01-18T15:16:43.383207391-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-isd","depends_on_id":"coding_agent_usage_tracker-7ng","type":"blocks","created_at":"2026-01-18T15:16:43.431839109-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-isd","depends_on_id":"coding_agent_usage_tracker-teh","type":"blocks","created_at":"2026-01-18T15:16:43.478643236-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-isd","depends_on_id":"coding_agent_usage_tracker-7zk","type":"blocks","created_at":"2026-01-18T15:16:43.525639905-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-isd","depends_on_id":"coding_agent_usage_tracker-hlt","type":"blocks","created_at":"2026-01-18T15:16:43.573339237-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-j5d","title":"TUI: Add keyboard navigation and controls","description":"## Summary\nImplement keyboard navigation and interaction for the TUI dashboard.\n\n## Background\nA good TUI needs keyboard controls for:\n1. Navigation between panels\n2. Triggering actions (refresh, quit)\n3. Expanding/collapsing details\n4. Help overlay\n5. Accessibility\n\n## Technical Design\n\n### Event Loop\n```rust\nuse crossterm::event::{self, Event, KeyCode, KeyEvent, KeyModifiers};\n\npub struct DashboardApp {\n    dashboard: Dashboard,\n    running: bool,\n    show_help: bool,\n    selected_panel: usize,\n}\n\nimpl DashboardApp {\n    pub async fn run(\u0026mut self) -\u003e Result\u003c()\u003e {\n        let mut terminal = self.setup_terminal()?;\n        \n        let tick_rate = Duration::from_millis(100);\n        let mut last_tick = Instant::now();\n        \n        while self.running {\n            terminal.draw(|f| self.render(f))?;\n            \n            // Handle events with timeout\n            let timeout = tick_rate\n                .checked_sub(last_tick.elapsed())\n                .unwrap_or(Duration::ZERO);\n            \n            if event::poll(timeout)? {\n                if let Event::Key(key) = event::read()? {\n                    self.handle_key(key).await?;\n                }\n            }\n            \n            if last_tick.elapsed() \u003e= tick_rate {\n                self.tick().await?;\n                last_tick = Instant::now();\n            }\n        }\n        \n        self.restore_terminal(\u0026mut terminal)?;\n        Ok(())\n    }\n}\n```\n\n### Key Handling\n```rust\nimpl DashboardApp {\n    async fn handle_key(\u0026mut self, key: KeyEvent) -\u003e Result\u003c()\u003e {\n        // Help overlay takes precedence\n        if self.show_help {\n            if matches!(key.code, KeyCode::Esc | KeyCode::Char('?')) {\n                self.show_help = false;\n            }\n            return Ok(());\n        }\n        \n        match key.code {\n            // Navigation\n            KeyCode::Left | KeyCode::Char('h') =\u003e self.select_prev_panel(),\n            KeyCode::Right | KeyCode::Char('l') =\u003e self.select_next_panel(),\n            KeyCode::Up | KeyCode::Char('k') =\u003e self.select_up_panel(),\n            KeyCode::Down | KeyCode::Char('j') =\u003e self.select_down_panel(),\n            KeyCode::Tab =\u003e self.select_next_panel(),\n            KeyCode::BackTab =\u003e self.select_prev_panel(),\n            \n            // Actions\n            KeyCode::Char('r') =\u003e self.refresh_now().await?,\n            KeyCode::Char('R') =\u003e self.refresh_all().await?,\n            KeyCode::Enter =\u003e self.toggle_panel_detail(),\n            KeyCode::Char(' ') =\u003e self.toggle_panel_detail(),\n            \n            // Time range\n            KeyCode::Char('1') =\u003e self.set_history_range(Duration::hours(1)),\n            KeyCode::Char('2') =\u003e self.set_history_range(Duration::hours(24)),\n            KeyCode::Char('3') =\u003e self.set_history_range(Duration::days(7)),\n            \n            // Help and quit\n            KeyCode::Char('?') =\u003e self.show_help = true,\n            KeyCode::Char('q') =\u003e self.running = false,\n            KeyCode::Esc =\u003e {\n                if self.detail_expanded {\n                    self.detail_expanded = false;\n                } else {\n                    self.running = false;\n                }\n            }\n            \n            // Ctrl+C to quit\n            KeyCode::Char('c') if key.modifiers.contains(KeyModifiers::CONTROL) =\u003e {\n                self.running = false;\n            }\n            \n            _ =\u003e {}\n        }\n        \n        Ok(())\n    }\n}\n```\n\n### Panel Selection\n```rust\nimpl DashboardApp {\n    fn select_next_panel(\u0026mut self) {\n        let count = self.dashboard.providers.len();\n        self.selected_panel = (self.selected_panel + 1) % count;\n    }\n    \n    fn select_prev_panel(\u0026mut self) {\n        let count = self.dashboard.providers.len();\n        self.selected_panel = self.selected_panel.checked_sub(1).unwrap_or(count - 1);\n    }\n    \n    fn select_up_panel(\u0026mut self) {\n        let cols = self.dashboard.columns();\n        if self.selected_panel \u003e= cols {\n            self.selected_panel -= cols;\n        }\n    }\n    \n    fn select_down_panel(\u0026mut self) {\n        let cols = self.dashboard.columns();\n        let count = self.dashboard.providers.len();\n        let new_idx = self.selected_panel + cols;\n        if new_idx \u003c count {\n            self.selected_panel = new_idx;\n        }\n    }\n}\n```\n\n### Help Overlay\n```rust\nimpl DashboardApp {\n    fn render_help(\u0026self, frame: \u0026mut Frame) {\n        let help_text = vec![\n            \"\",\n            \"  Navigation\",\n            \"  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\",\n            \"  h/‚Üê      Previous panel\",\n            \"  l/‚Üí      Next panel\",\n            \"  k/‚Üë      Panel above\",\n            \"  j/‚Üì      Panel below\",\n            \"  Tab      Next panel\",\n            \"\",\n            \"  Actions\",\n            \"  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\",\n            \"  r        Refresh selected\",\n            \"  R        Refresh all\",\n            \"  Enter    Toggle details\",\n            \"\",\n            \"  History Range\",\n            \"  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\",\n            \"  1        Last hour\",\n            \"  2        Last 24 hours\",\n            \"  3        Last 7 days\",\n            \"\",\n            \"  General\",\n            \"  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\",\n            \"  ?        Show/hide help\",\n            \"  q/Esc    Quit\",\n            \"\",\n        ];\n        \n        let block = Block::default()\n            .title(\" Help \")\n            .borders(Borders::ALL)\n            .border_style(Style::default().fg(Color::Cyan));\n        \n        let paragraph = Paragraph::new(help_text.join(\"\\n\"))\n            .block(block)\n            .alignment(Alignment::Left);\n        \n        // Center the help overlay\n        let area = self.centered_rect(50, 80, frame.size());\n        \n        // Clear the background\n        frame.render_widget(Clear, area);\n        frame.render_widget(paragraph, area);\n    }\n    \n    fn centered_rect(\u0026self, percent_x: u16, percent_y: u16, r: Rect) -\u003e Rect {\n        let popup_layout = Layout::default()\n            .direction(Direction::Vertical)\n            .constraints([\n                Constraint::Percentage((100 - percent_y) / 2),\n                Constraint::Percentage(percent_y),\n                Constraint::Percentage((100 - percent_y) / 2),\n            ])\n            .split(r);\n        \n        Layout::default()\n            .direction(Direction::Horizontal)\n            .constraints([\n                Constraint::Percentage((100 - percent_x) / 2),\n                Constraint::Percentage(percent_x),\n                Constraint::Percentage((100 - percent_x) / 2),\n            ])\n            .split(popup_layout[1])[1]\n    }\n}\n```\n\n## Key Bindings Summary\n| Key | Action |\n|-----|--------|\n| h/‚Üê | Previous panel |\n| l/‚Üí | Next panel |\n| k/‚Üë | Panel above |\n| j/‚Üì | Panel below |\n| Tab | Next panel |\n| r | Refresh selected |\n| R | Refresh all |\n| Enter | Toggle details |\n| 1/2/3 | History range |\n| ? | Show help |\n| q/Esc | Quit |\n\n## Acceptance Criteria\n- [ ] Arrow key navigation works\n- [ ] Vi-style hjkl navigation works\n- [ ] Tab cycles through panels\n- [ ] Selected panel visually highlighted\n- [ ] r refreshes selected provider\n- [ ] R refreshes all providers\n- [ ] Help overlay displays and dismisses\n- [ ] q and Esc quit properly\n- [ ] Ctrl+C quits properly\n- [ ] History range keys work\n\n## Accessibility\n- All actions have keyboard shortcuts\n- Selected item clearly visible\n- Help always accessible\n- No mouse required\n\n## Dependencies\n- Requires core TUI layout (sibling task)\n- Requires provider panels (sibling task)\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:16:52.841210631-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:16:52.841210631-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-j5d","depends_on_id":"coding_agent_usage_tracker-i9x","type":"blocks","created_at":"2026-01-18T14:22:09.296156439-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-j5d","depends_on_id":"coding_agent_usage_tracker-ymb","type":"blocks","created_at":"2026-01-18T14:22:09.34213319-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-jkf","title":"[EPIC] Usage Budgets with Smart Alerts","description":"## Overview\n\nUsage Budgets allow users to set spending and usage limits with configurable alerts. \"Warn me at $50/month\" or \"Alert when Claude hits 80%.\" This shifts caut from descriptive to prescriptive - from telling you what happened to helping you stay within bounds.\n\n## Strategic Importance (Why P1)\n\n- **Natural evolution**: History tells you what happened; budgets tell you what SHOULD happen\n- **Proactive cost management**: Users set guardrails matching their constraints\n- **High user value**: Directly addresses \"I don't want to overspend\" concern\n- **Depends on history**: Must come after EPIC 1 (Historical Tracking)\n\n## User Value Proposition\n\n```\n$ caut budget set claude --monthly-cost 75 --warn-at 80%\nBudget set: Claude ‚â§ $75/month, alert at $60 (80%)\n\n$ caut budget set --global --daily-usage 85%\nGlobal budget set: Alert when any provider exceeds 85% daily\n\n$ caut usage\nClaude: 72% used ($58.40 of $75 budget)\n        ‚îú‚îÄ ‚ö†Ô∏è Approaching budget limit (78% of monthly)\n        ‚îî‚îÄ At current pace: will exceed budget in 3 days\n\nCodex: 45% used ($12.30, no budget set)\n```\n\n## Technical Approach\n\n### Budget Configuration\n\n```toml\n# ~/.config/caut/budgets.toml\n[claude]\nmonthly_cost_limit = 75.00\nwarn_at_percent = 80\nalert_method = \"inline\"  # or \"notification\"\n\n[codex]\nmonthly_cost_limit = 50.00\nwarn_at_percent = 90\n\n[global]\ndaily_usage_alert = 85\nany_provider_monthly = 100.00\n```\n\n### Budget Checking Logic\n\n```rust\nfn check_budgets(provider: \u0026Provider, history: \u0026History) -\u003e Vec\u003cBudgetAlert\u003e {\n    let mut alerts = vec![];\n    \n    if let Some(budget) = get_budget(provider) {\n        let monthly_spend = history.cost_this_month(provider);\n        let percent_of_budget = monthly_spend / budget.limit * 100.0;\n        \n        if percent_of_budget \u003e= budget.warn_at_percent {\n            alerts.push(BudgetAlert::ApproachingLimit {\n                provider: provider.clone(),\n                current: monthly_spend,\n                limit: budget.limit,\n                percent: percent_of_budget,\n            });\n        }\n    }\n    \n    // Check global budgets\n    if let Some(global) = get_global_budget() {\n        // ... similar logic\n    }\n    \n    alerts\n}\n```\n\n### Budget Types\n\n1. **Cost budgets**: Monthly/weekly dollar limits\n2. **Usage budgets**: Percentage thresholds\n3. **Global budgets**: Across all providers\n4. **Provider-specific**: Per-provider limits\n\n## Commands\n\n- `caut budget set \u003cprovider\u003e [options]` - Set budget\n- `caut budget list` - Show all budgets\n- `caut budget clear \u003cprovider\u003e` - Remove budget\n- `caut budget status` - Current budget consumption\n\n### Options for `budget set`:\n- `--monthly-cost \u003camount\u003e` - Monthly dollar limit\n- `--weekly-cost \u003camount\u003e` - Weekly dollar limit\n- `--daily-cost \u003camount\u003e` - Daily dollar limit\n- `--warn-at \u003cpercent\u003e` - Alert threshold (default: 80%)\n- `--hard-limit` - Future: actually block usage (requires integration)\n\n## Alert Delivery\n\nInitially: Inline in CLI output\nLater: Integration with notification system (EPIC not in top 10)\n\n## Success Criteria\n\n- [ ] Budget configuration persisted to file\n- [ ] Budgets checked on every usage fetch\n- [ ] Clear alert display in usage output\n- [ ] Multiple budget types (cost, usage, global)\n- [ ] Budget status command shows consumption\n- [ ] JSON output includes budget data\n\n## Dependencies\n\n- **REQUIRES**: Historical Usage Tracking (EPIC 1) - needs history to calculate spend-to-date\n- **Benefits from**: Time-to-Limit Prediction (EPIC 2) - \"will exceed budget in X days\"\n\n## Considerations\n\n- Currency handling: assume USD, document clearly\n- Timezone handling: when does \"monthly\" reset?\n- Budget inheritance: global vs provider-specific precedence\n- Future: webhook/notification integration","status":"open","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:12:29.680620584-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:12:29.680620584-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-jkf","depends_on_id":"coding_agent_usage_tracker-smv","type":"blocks","created_at":"2026-01-18T14:21:34.338865452-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-jkf","depends_on_id":"coding_agent_usage_tracker-cr9","type":"blocks","created_at":"2026-01-18T15:16:45.333726578-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-jlp","title":"Unit tests for storage/token_accounts.rs (token storage)","description":"## Overview\nTest the token account storage module for multi-account support.\n\n## Target: src/storage/token_accounts.rs (4.6KB)\nCritical for: Multi-account management, credential safety\n\n## Test Cases\n\n### 1. TokenAccount Struct\n- All fields serialize/deserialize correctly\n- token field is NOT serialized (skip_serializing)\n- DateTime handling for added_at, last_used\n\n### 2. ProviderTokenAccountData\n- Version field handling\n- Empty accounts list\n- active_index validation\n\n### 3. TokenAccountsFile\n- Multi-provider storage\n- Version migration (if applicable)\n- Empty state handling\n\n### 4. TokenAccountStore Operations\n- load() - existing file\n- load() - missing file (creates default)\n- empty() - in-memory only\n- save() - creates parent directories\n- save() - writes pretty JSON\n\n### 5. Account Queries\n- get_provider() - existing/missing provider\n- get_by_label() - case insensitive matching\n- get_by_index() - bounds checking\n- get_active() - returns correct account\n- get_all() - returns all accounts\n\n### 6. CodexBar Conversion\n- from_codexbar() parsing\n- to_codexbar() serialization\n- Round-trip conversion\n\n### 7. Security Tests\n- Token NOT leaked in JSON output\n- Token NOT in error messages\n- Token NOT in debug output\n\n## Test Data\n- Multi-account test fixtures\n- Edge cases: empty accounts, invalid indices\n- Large account lists\n\n## Acceptance Criteria\n- [ ] All CRUD operations tested\n- [ ] Query methods tested\n- [ ] Serialization verified (no token leak!)\n- [ ] CodexBar compatibility verified\n- [ ] Security: token never serialized","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:52:11.802320551-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:52:11.802320551-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-jlp","depends_on_id":"coding_agent_usage_tracker-u5h","type":"blocks","created_at":"2026-01-18T02:53:19.099370537-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-jqn","title":"Unit tests for core/http.rs (HTTP client)","description":"## Overview\nTest the HTTP client wrapper and its configuration.\n\n## Target: src/core/http.rs (1.6KB)\nCritical for: Reliable network operations\n\n## Test Cases\n\n### 1. Client Configuration\n- Default timeout settings\n- User-Agent header\n- Connection pooling (if applicable)\n- TLS configuration\n\n### 2. Request Building\n- Header injection\n- Query parameter encoding\n- Body serialization\n\n### 3. Response Handling\n- Success response parsing\n- Error status code handling\n- Response body deserialization\n- Timeout handling\n\n### 4. Error Types\n- Network errors\n- Timeout errors\n- TLS errors\n- DNS resolution errors\n\n## Implementation Notes\n- Unit tests should NOT make real HTTP calls\n- Test request/response construction logic\n- Test error type mappings\n- Integration tests (64u) will cover actual HTTP\n\n## Acceptance Criteria\n- [ ] Client configuration verified\n- [ ] Request building tested\n- [ ] Response handling tested\n- [ ] Error type coverage complete","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:50:45.104520837-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:50:45.104520837-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-jqn","depends_on_id":"coding_agent_usage_tracker-u5h","type":"blocks","created_at":"2026-01-18T02:53:18.879279192-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-jt0","title":"Parallel: Graceful degradation with partial results","description":"## Overview\nImplement graceful degradation so that when some providers fail, we still show results from successful ones.\n\n## Background \u0026 Rationale\nCurrently if one provider fails, the entire command fails. This is poor UX - users want to see what data IS available, not get a total failure. Real-world scenarios: network issues to one API, expired auth for one provider, rate limiting on one service. The tool should show partial data with clear indication of what failed.\n\n## Technical Approach\n\n### 1. Result Aggregation Pattern\n```rust\n// In core/pipeline.rs\npub struct FetchResults {\n    pub successes: Vec\u003cProviderPayload\u003e,\n    pub failures: Vec\u003cProviderError\u003e,\n    pub partial: bool,  // true if any failures occurred\n}\n\npub struct ProviderError {\n    pub provider: Provider,\n    pub error: CautError,\n    pub attempted_sources: Vec\u003cString\u003e,\n}\n```\n\n### 2. Pipeline Changes\n- Modify `fetch_all_providers()` to collect Results, not propagate errors\n- Use `futures::future::join_all` to run all fetches\n- Partition results into successes and failures\n- Return both together instead of failing fast\n\n### 3. Rendering Changes\n- Render successful results normally\n- Add footer section showing failed providers:\n  ```\n  ‚ö† Some providers unavailable:\n    ‚Ä¢ codex: Network timeout (tried: cli, api)\n    ‚Ä¢ gemini: Authentication expired\n  ```\n\n## Files to Modify\n- `src/core/pipeline.rs`: New result aggregation types and logic\n- `src/render/human.rs`: Add failure section rendering\n- `src/render/json.rs`: Add errors array to output\n- `src/cli/usage.rs`: Update to handle partial results\n\n## Dependencies\n- Requires parallel fetch refactor (d30) to be complete first\n- Should be done before timeout handling\n\n## Acceptance Criteria\n- [ ] When 1 of 3 providers fails, other 2 results are shown\n- [ ] Failed providers are clearly indicated in output\n- [ ] JSON output includes both `results` and `errors` arrays\n- [ ] Exit code reflects partial failure (e.g., exit 2)\n- [ ] Human output shows friendly failure reasons\n\n## Testing Strategy\n- Mock one provider to always fail, verify others succeed\n- Test with various failure modes: network, auth, parse errors\n- Verify JSON schema includes error structure","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:53:30.894054126-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T10:40:18.24973727-05:00","closed_at":"2026-01-18T10:40:18.24973727-05:00","close_reason":"Completed","dependencies":[{"issue_id":"coding_agent_usage_tracker-jt0","depends_on_id":"coding_agent_usage_tracker-d30","type":"blocks","created_at":"2026-01-18T02:54:45.761327099-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-kod","title":"[EPIC] Provider Health Status Integration","description":"## Overview\n\nIntegrate with provider status pages to show when external issues are affecting service. When Claude's API is degraded, users should know it's not their fault - and not waste time debugging on their end.\n\n## Strategic Importance (Why P2)\n\n- **Reduces user frustration**: During outages, users often blame themselves\n- **Builds trust**: Tool that understands context feels intelligent\n- **Low complexity**: Most providers use standard Statuspage API\n- **Partially implemented**: Status module already exists in codebase\n\n## User Value Proposition\n\n**Current state**: Fetch fails with timeout, user wonders \"is it me or them?\"\n\n**Target state**:\n```\n$ caut usage\n‚ö†Ô∏è Anthropic Status: Degraded Performance (API latency issues)\n   See: https://status.anthropic.com\n\nClaude: Unable to fetch (API timeout)\n        ‚îî‚îÄ Likely related to ongoing incident\n\nCodex: 45% used ‚úì\n       ‚îî‚îÄ OpenAI Status: All Systems Operational\n```\n\nIn watch mode:\n```\nCLAUDE [‚ö†Ô∏è DEGRADED]              CODEX [‚úì OPERATIONAL]\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ             ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nLast fetch failed                Primary: 45%\nRetrying in 30s...               ...\n```\n\n## Technical Approach\n\n### Status Page Endpoints\n\nMost providers use Atlassian Statuspage with standard API:\n\n```rust\nconst STATUS_ENDPOINTS: \u0026[(\u0026str, \u0026str)] = \u0026[\n    (\"claude\", \"https://status.anthropic.com/api/v2/status.json\"),\n    (\"openai\", \"https://status.openai.com/api/v2/status.json\"),\n    (\"google\", \"https://status.cloud.google.com/incidents.json\"),\n    // Google uses different format - needs adapter\n];\n```\n\n### Statuspage API Response\n\n```rust\n#[derive(Deserialize)]\nstruct StatuspageResponse {\n    status: StatusSummary,\n    incidents: Vec\u003cIncident\u003e,\n}\n\n#[derive(Deserialize)]\nstruct StatusSummary {\n    indicator: String,  // \"none\", \"minor\", \"major\", \"critical\"\n    description: String,\n}\n\n#[derive(Deserialize)]\nstruct Incident {\n    name: String,\n    status: String,\n    impact: String,\n    updated_at: String,\n}\n```\n\n### Parallel Fetching\n\nFetch status alongside usage to avoid adding latency:\n\n```rust\nasync fn fetch_with_status(provider: \u0026Provider) -\u003e FetchResult {\n    let (usage, status) = tokio::join!(\n        fetch_usage(provider),\n        fetch_provider_status(provider),\n    );\n    \n    FetchResult {\n        usage: usage.ok(),\n        status: status.ok(),\n        fetch_error: usage.err(),\n    }\n}\n```\n\n### Contextual Error Messages\n\n```rust\nfn format_error_with_context(error: \u0026FetchError, status: Option\u003c\u0026Status\u003e) -\u003e String {\n    match (error, status) {\n        (FetchError::Timeout, Some(s)) if s.is_degraded() =\u003e {\n            format!(\"Timeout (likely due to: {})\", s.active_incident_summary())\n        }\n        (FetchError::Timeout, Some(s)) if s.is_operational() =\u003e {\n            \"Timeout (provider reports operational - may be local issue)\".into()\n        }\n        (FetchError::Timeout, None) =\u003e {\n            \"Timeout (status unknown)\".into()\n        }\n        // ... more cases\n    }\n}\n```\n\n## Display Integration\n\n1. **Status badge**: Show in provider header `[‚úì OK]` or `[‚ö†Ô∏è DEGRADED]`\n2. **Incident summary**: When degraded, show brief description\n3. **Error context**: When fetch fails, explain if likely related to incident\n4. **Status URL**: Provide link for more details\n\n## Caching\n\nStatus pages are rate-limited. Cache appropriately:\n- Cache duration: 60 seconds\n- Stale-while-revalidate: Use cached if fresh enough\n- Background refresh: Update cache periodically in watch mode\n\n## Success Criteria\n\n- [ ] Status fetched for major providers (Claude, OpenAI, Google)\n- [ ] Status displayed alongside usage data\n- [ ] Error messages contextualized with status info\n- [ ] Caching prevents excessive API calls\n- [ ] Graceful handling when status unavailable\n\n## Dependencies\n\n- **Extends**: Existing status module in codebase\n- **Independent of**: Other EPICs\n- **Parallel with**: Usage fetching (no blocking)\n\n## Considerations\n\n- Different providers have different status page formats\n- Some providers may not have public status APIs\n- Status can change rapidly during incidents\n- Don't let status fetch failure block usage fetch","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:58:01.116923481-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:58:01.116923481-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-kod","depends_on_id":"coding_agent_usage_tracker-bzy","type":"blocks","created_at":"2026-01-18T15:16:40.498727114-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-kod","depends_on_id":"coding_agent_usage_tracker-smm","type":"blocks","created_at":"2026-01-18T15:16:40.544572205-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-kod","depends_on_id":"coding_agent_usage_tracker-lgh","type":"blocks","created_at":"2026-01-18T15:16:40.592981404-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-kod","depends_on_id":"coding_agent_usage_tracker-67u","type":"blocks","created_at":"2026-01-18T15:16:40.639282374-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-kqm","title":"Creds: Implement token refresh flow for OAuth providers","description":"## Summary\nImplement the actual token refresh flow for OAuth-based providers.\n\n## Refresh Flow\n```rust\npub async fn refresh_token(provider: \u0026str) -\u003e Result\u003c()\u003e {\n    let creds = load_credentials(provider)?;\n    \n    match creds.auth_type {\n        AuthType::OAuth { refresh_token, .. } =\u003e {\n            let new_tokens = oauth_refresh(\u0026refresh_token).await?;\n            save_credentials(provider, new_tokens)?;\n            info!(provider, \"Token refreshed successfully\");\n            Ok(())\n        }\n        AuthType::ApiKey =\u003e {\n            Err(anyhow!(\"API keys cannot be refreshed\"))\n        }\n    }\n}\n```\n\n## CLI Commands\n- `caut auth refresh claude` - Refresh Claude OAuth token\n- `caut auth refresh codex` - Refresh Codex OAuth token\n- `caut auth refresh --all` - Refresh all refreshable tokens\n\n## Provider-Specific Logic\n- **Claude**: Uses Anthropic OAuth flow\n- **Codex**: Uses OpenAI OAuth flow\n\n## Error Handling\n- Token revoked ‚Üí Clear error message, suggest re-auth\n- Network error ‚Üí Retry with backoff\n- Invalid refresh token ‚Üí Suggest re-auth\n\n## Acceptance Criteria\n- [ ] Refresh works for Claude OAuth\n- [ ] Refresh works for Codex OAuth\n- [ ] API keys handled gracefully (not refreshable)\n- [ ] Success/failure clearly reported\n- [ ] New tokens properly saved","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:01:22.838338099-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:01:22.838338099-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-kqm","depends_on_id":"coding_agent_usage_tracker-2tn","type":"blocks","created_at":"2026-01-18T15:03:55.379474855-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-kva","title":"Session: Add cost correlation with pricing models","description":"## Summary\nCorrelate parsed session data with provider pricing to calculate accurate per-session costs.\n\n## Background\nOnce we have token counts from session logs, we need to convert them to dollar amounts using current provider pricing. This involves:\n1. Model-specific pricing (different rates for different models)\n2. Token type pricing (input vs output vs cache read)\n3. Handling pricing changes over time\n4. Batch vs interactive pricing differences\n\n## Technical Design\n\n### Pricing Configuration\n```rust\npub struct PricingTable {\n    pub models: HashMap\u003cString, ModelPricing\u003e,\n    pub effective_date: DateTime\u003cUtc\u003e,\n}\n\npub struct ModelPricing {\n    pub input_per_million: f64,\n    pub output_per_million: f64,\n    pub cache_read_per_million: f64,\n    pub cache_creation_per_million: f64,\n}\n\nimpl Default for PricingTable {\n    fn default() -\u003e Self {\n        // Current pricing as of implementation date\n        // Claude 3.5 Sonnet: $3/$15 per million\n        // Claude 3.5 Haiku: $0.25/$1.25 per million\n        // GPT-4o: $2.50/$10 per million\n        // etc.\n    }\n}\n```\n\n### Cost Calculator\n```rust\npub struct SessionCostCalculator {\n    pricing: PricingTable,\n}\n\nimpl SessionCostCalculator {\n    pub fn calculate(\u0026self, usage: \u0026SessionUsage) -\u003e SessionCost {\n        let mut total = 0.0;\n        let mut breakdown = Vec::new();\n        \n        // Get primary model pricing (use most expensive if multiple)\n        let model = usage.primary_model().unwrap_or(\"unknown\");\n        let pricing = self.pricing.get(model).unwrap_or_default();\n        \n        // Calculate costs\n        let input_cost = (usage.input_tokens as f64 / 1_000_000.0) * pricing.input_per_million;\n        let output_cost = (usage.output_tokens as f64 / 1_000_000.0) * pricing.output_per_million;\n        let cache_cost = (usage.cache_read_tokens as f64 / 1_000_000.0) * pricing.cache_read_per_million;\n        \n        SessionCost {\n            total_usd: input_cost + output_cost + cache_cost,\n            input_cost_usd: input_cost,\n            output_cost_usd: output_cost,\n            cache_cost_usd: cache_cost,\n            model: model.to_string(),\n            confidence: self.calculate_confidence(usage),\n        }\n    }\n    \n    fn calculate_confidence(\u0026self, usage: \u0026SessionUsage) -\u003e CostConfidence {\n        // High: known model, complete session\n        // Medium: known model, partial session\n        // Low: unknown model or missing data\n    }\n}\n```\n\n### Confidence Levels\n```rust\npub enum CostConfidence {\n    High,    // Known model, complete data\n    Medium,  // Some uncertainty in pricing\n    Low,     // Significant estimation involved\n    Unknown, // Cannot calculate reliably\n}\n```\n\n## Pricing Data Sources\n1. **Hardcoded defaults**: Current pricing embedded in code\n2. **Config file override**: `~/.config/caut/pricing.toml`\n3. **Future**: Auto-fetch from provider APIs (if available)\n\n## Acceptance Criteria\n- [ ] Calculate costs for Claude models accurately\n- [ ] Calculate costs for OpenAI/Codex models accurately\n- [ ] Handle multiple models in single session\n- [ ] Confidence scoring works correctly\n- [ ] Config file override works\n- [ ] Unit tests with known token/cost pairs\n\n## Edge Cases\n- Unknown model: use conservative estimate, mark low confidence\n- Mixed models: calculate per-model, sum totals\n- Cache tokens: handle correctly for Claude\n- Zero tokens: return zero cost, not error\n\n## Dependencies\n- Requires session log parsing (sibling task)\n- Used by session CLI command\n\n## Future Enhancements\n- Fetch pricing from provider APIs\n- Historical pricing for accurate past session costs\n- Batch pricing vs interactive pricing differentiation\n","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:12:27.756016441-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:12:27.756016441-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-kva","depends_on_id":"coding_agent_usage_tracker-b9i","type":"blocks","created_at":"2026-01-18T14:21:53.932502608-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-lgh","title":"Status: Implement status-aware error context","description":"Create src/error/context.rs with ContextualError struct that correlates fetch errors with provider status. Include ErrorCause enum (ProviderOutage, ProviderDegraded, NetworkIssue, AuthExpired, RateLimit, Unknown). Analyze error type + status to provide actionable suggestions. Link to status page when relevant. Include in JSON output.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:15:04.473968535-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:15:04.473968535-05:00"}
{"id":"coding_agent_usage_tracker-lw2","title":"Prompt: Add shell snippet generator and documentation","description":"## Summary\nProvide ready-to-use shell snippets and a generator command for easy shell prompt integration.\n\n## Background\nUsers should not have to figure out shell integration themselves. We provide:\n1. A `caut prompt init \u003cSHELL\u003e` command that outputs ready-to-use snippets\n2. Documentation for manual configuration\n3. Support for bash, zsh, fish, and powershell\n\n## Command Interface\n```\ncaut prompt init \u003cSHELL\u003e\n\nSHELLS:\n    bash        Bash shell configuration\n    zsh         Zsh shell configuration  \n    fish        Fish shell configuration\n    powershell  PowerShell configuration\n    \nOPTIONS:\n    --right-prompt    Configure for right-side prompt (zsh/fish)\n    --async           Use async prompt update (zsh)\n    --minimal         Minimal configuration\n```\n\n## Generated Snippets\n\n### Bash\n```bash\n# caut shell integration - add to ~/.bashrc\n_caut_prompt() {\n    local usage=$(caut prompt --cache-only 2\u003e/dev/null)\n    [ -n \"$usage\" ] \u0026\u0026 echo \"[$usage] \"\n}\nPS1='$(_caut_prompt)\\u@\\h:\\w\\$ '\n\n# Optional: refresh cache after each command\nPROMPT_COMMAND=\"${PROMPT_COMMAND:+$PROMPT_COMMAND ;} caut prompt --refresh \u0026\u003e/dev/null \u0026\"\n```\n\n### Zsh\n```zsh\n# caut shell integration - add to ~/.zshrc\nautoload -Uz add-zsh-hook\n\n_caut_prompt() {\n    CAUT_PROMPT=$(caut prompt --cache-only 2\u003e/dev/null)\n}\nadd-zsh-hook precmd _caut_prompt\n\nPROMPT='${CAUT_PROMPT:+[$CAUT_PROMPT] }%n@%m:%~%# '\n```\n\n### Fish\n```fish\n# caut shell integration - add to ~/.config/fish/config.fish\nfunction _caut_prompt\n    set -l usage (caut prompt --cache-only 2\u003e/dev/null)\n    test -n \"$usage\"; and echo \"[$usage] \"\nend\n\nfunction fish_prompt\n    _caut_prompt\n    echo (prompt_pwd) \"\u003e \"\nend\n```\n\n### PowerShell\n```powershell\n# caut shell integration - add to $PROFILE\nfunction prompt {\n    $usage = caut prompt --cache-only 2\u003e$null\n    if ($usage) { \"[$usage] \" }\n    \"PS $($executionContext.SessionState.Path.CurrentLocation)$('\u003e' * ($nestedPromptLevel + 1)) \"\n}\n```\n\n## Implementation\n```rust\n#[derive(Parser)]\npub struct PromptInitCommand {\n    shell: Shell,\n    \n    #[arg(long)]\n    right_prompt: bool,\n    \n    #[arg(long)]\n    r#async: bool,\n}\n\nimpl PromptInitCommand {\n    pub fn run(\u0026self) -\u003e Result\u003c()\u003e {\n        let snippet = match self.shell {\n            Shell::Bash =\u003e self.bash_snippet(),\n            Shell::Zsh =\u003e self.zsh_snippet(),\n            Shell::Fish =\u003e self.fish_snippet(),\n            Shell::PowerShell =\u003e self.powershell_snippet(),\n        };\n        \n        println!(\"{}\", snippet);\n        println!(\"\\n# Add the above to your shell configuration file\");\n        Ok(())\n    }\n}\n```\n\n## Acceptance Criteria\n- [ ] `caut prompt init bash` outputs working bash snippet\n- [ ] `caut prompt init zsh` outputs working zsh snippet\n- [ ] `caut prompt init fish` outputs working fish snippet\n- [ ] `caut prompt init powershell` outputs working powershell snippet\n- [ ] --right-prompt works for zsh and fish\n- [ ] Generated snippets are tested in actual shells\n- [ ] README updated with shell integration section\n\n## Testing Strategy\n- Automated: snippet generation tests\n- Manual: test each snippet in actual shell environments\n- Consider Docker-based integration tests for each shell\n\n## Dependencies\n- Requires prompt command (sibling task)\n- Requires cache layer (sibling task)\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:11:48.278839516-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:11:48.278839516-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-lw2","depends_on_id":"coding_agent_usage_tracker-yfg","type":"blocks","created_at":"2026-01-18T14:21:49.409956132-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-m5a","title":"Implement configuration file loading","description":"Config file paths are defined in storage/paths.rs but config loading is not implemented. Should load ~/.config/caut/config.toml (Linux/macOS) or %APPDATA%/caut/config.toml (Windows).","status":"closed","priority":3,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T00:47:04.681116179-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T01:44:15.096742924-05:00","closed_at":"2026-01-18T01:44:15.096742924-05:00","close_reason":"Implemented config.rs with Config struct, TOML loading/saving, tests. 28 tests pass."}
{"id":"coding_agent_usage_tracker-m5r","title":"Status: Add contextual error messages with status correlation","description":"## Summary\nEnhance error messages with context from provider status to help users understand failures.\n\n## Background\nWhen fetches fail, users want to know:\n1. Is this a provider-side issue or local?\n2. Is the provider having an outage?\n3. What should I do?\n\nBy correlating errors with status data, we provide actionable information.\n\n## Technical Design\n\n### Error Contextualization\n```rust\npub struct ContextualError {\n    pub original: FetchError,\n    pub status: Option\u003cStatusPayload\u003e,\n    pub context: ErrorContext,\n    pub suggestion: String,\n}\n\npub enum ErrorContext {\n    ProviderOutage,       // Status page confirms issue\n    PossibleOutage,       // Error suggests provider issue\n    AuthenticationError,  // Credentials issue\n    NetworkError,         // Local network problem\n    RateLimited,          // Rate limit hit\n    Unknown,              // Cannot determine\n}\n\nimpl ContextualError {\n    pub fn from_fetch_error(\n        error: FetchError,\n        status: Option\u003c\u0026StatusPayload\u003e,\n    ) -\u003e Self {\n        let (context, suggestion) = Self::analyze(\u0026error, status);\n        \n        Self {\n            original: error,\n            status: status.cloned(),\n            context,\n            suggestion,\n        }\n    }\n    \n    fn analyze(\n        error: \u0026FetchError,\n        status: Option\u003c\u0026StatusPayload\u003e,\n    ) -\u003e (ErrorContext, String) {\n        // Check if provider has active incident\n        if let Some(s) = status {\n            if matches!(s.indicator, StatusIndicator::Major | StatusIndicator::Critical) {\n                return (\n                    ErrorContext::ProviderOutage,\n                    format!(\n                        \"Provider is experiencing issues: {}. Check {} for updates.\",\n                        s.description.as_deref().unwrap_or(\"service disruption\"),\n                        s.url\n                    ),\n                );\n            }\n        }\n        \n        // Analyze error type\n        match error {\n            FetchError::AuthFailed(_) =\u003e (\n                ErrorContext::AuthenticationError,\n                \"Authentication failed. Try re-authenticating with your provider.\".to_string(),\n            ),\n            FetchError::RateLimited(_) =\u003e (\n                ErrorContext::RateLimited,\n                \"Rate limit exceeded. Wait before retrying.\".to_string(),\n            ),\n            FetchError::NetworkError(e) =\u003e {\n                if e.is_timeout() {\n                    (\n                        ErrorContext::PossibleOutage,\n                        \"Request timed out. Provider may be experiencing issues.\".to_string(),\n                    )\n                } else if e.is_connect() {\n                    (\n                        ErrorContext::NetworkError,\n                        \"Connection failed. Check your network.\".to_string(),\n                    )\n                } else {\n                    (ErrorContext::Unknown, \"Network error occurred.\".to_string())\n                }\n            }\n            FetchError::ServerError(code) if *code \u003e= 500 =\u003e (\n                ErrorContext::PossibleOutage,\n                format!(\"Server returned {}. Provider may be having issues.\", code),\n            ),\n            _ =\u003e (\n                ErrorContext::Unknown,\n                \"An error occurred. Try again later.\".to_string(),\n            ),\n        }\n    }\n}\n```\n\n### Display Integration\n```rust\nimpl fmt::Display for ContextualError {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter\u003c'_\u003e) -\u003e fmt::Result {\n        // Show original error\n        writeln!(f, \"Error: {}\", self.original)?;\n        \n        // Show context\n        match self.context {\n            ErrorContext::ProviderOutage =\u003e {\n                writeln!(f, \"‚ö†Ô∏è  Provider is experiencing an outage\")?;\n            }\n            ErrorContext::PossibleOutage =\u003e {\n                writeln!(f, \"‚ö†Ô∏è  Provider may be experiencing issues\")?;\n            }\n            ErrorContext::AuthenticationError =\u003e {\n                writeln!(f, \"üîë Authentication problem detected\")?;\n            }\n            ErrorContext::RateLimited =\u003e {\n                writeln!(f, \"‚è≥ Rate limit exceeded\")?;\n            }\n            _ =\u003e {}\n        }\n        \n        // Show suggestion\n        writeln!(f, \"üí° {}\", self.suggestion)?;\n        \n        // Show status if relevant\n        if let Some(status) = \u0026self.status {\n            if !matches!(status.indicator, StatusIndicator::None | StatusIndicator::Unknown) {\n                writeln!(f, \"üìä Current status: {} - {}\",\n                    status.indicator,\n                    status.description.as_deref().unwrap_or(\"unknown\")\n                )?;\n            }\n        }\n        \n        Ok(())\n    }\n}\n```\n\n### CLI Output Examples\n```\nError: Failed to fetch Claude usage\n\nError: Request timed out\n‚ö†Ô∏è  Provider may be experiencing issues\nüí° Request timed out. Provider may be experiencing issues.\nüìä Current status: Major - Degraded API performance\n   See: https://status.anthropic.com\n\nError: Authentication failed\nüîë Authentication problem detected\nüí° Authentication failed. Try re-authenticating with your provider.\n   Run: claude auth login\n```\n\n### Watch Mode Integration\n```rust\nimpl WatchMode {\n    fn display_error(\u0026self, error: \u0026ContextualError) {\n        match error.context {\n            ErrorContext::ProviderOutage =\u003e {\n                self.show_banner(\n                    BannerType::Warning,\n                    \u0026format!(\"{} is experiencing an outage\", self.provider),\n                );\n            }\n            ErrorContext::AuthenticationError =\u003e {\n                self.show_banner(\n                    BannerType::Error,\n                    \"Re-authentication required\",\n                );\n            }\n            _ =\u003e {\n                self.show_banner(\n                    BannerType::Info,\n                    \u0026error.suggestion,\n                );\n            }\n        }\n    }\n}\n```\n\n## Acceptance Criteria\n- [ ] Errors enriched with status context\n- [ ] Provider outages detected from status\n- [ ] Authentication errors identified\n- [ ] Rate limiting detected\n- [ ] Network errors distinguished from server errors\n- [ ] Suggestions provided for all error types\n- [ ] Watch mode shows contextual banners\n- [ ] Unit tests for error analysis\n\n## Error Message Quality\nEvery error message should answer:\n1. What happened? (the error)\n2. Why might it have happened? (the context)\n3. What can I do? (the suggestion)\n4. Where can I learn more? (status URL)\n\n## Dependencies\n- Requires status page clients (sibling task)\n- Requires parallel status fetching (sibling task)\n- Integrates with existing error handling\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:18:08.949026498-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:18:08.949026498-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-m5r","depends_on_id":"coding_agent_usage_tracker-7qd","type":"blocks","created_at":"2026-01-18T14:22:13.965167441-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-mf1","title":"Prompt: Implement fast cache layer with sub-50ms reads","description":"## Summary\nImplement a high-performance cache layer optimized for shell prompt integration where latency is critical.\n\n## Background\nShell prompts execute on every command. Users will abandon the feature if it adds perceptible lag (\u003e50ms). We need a cache that:\n1. Reads in \u003c10ms (ideally \u003c5ms)\n2. Writes asynchronously (non-blocking)\n3. Handles stale data gracefully\n4. Works across all providers\n\n## Technical Design\n\n### Cache Storage\n```rust\n// ~/.config/caut/cache/prompt_cache.json\npub struct PromptCache {\n    pub entries: HashMap\u003cString, CachedEntry\u003e,\n    pub updated_at: DateTime\u003cUtc\u003e,\n}\n\npub struct CachedEntry {\n    pub provider: String,\n    pub primary_pct: f64,\n    pub secondary_pct: Option\u003cf64\u003e,\n    pub status_indicator: StatusIndicator,\n    pub cached_at: DateTime\u003cUtc\u003e,\n    pub ttl_seconds: u64,\n}\n```\n\n### Fast Read Path\n```rust\nimpl PromptCache {\n    /// Read cache with memory-mapped file for speed\n    pub fn read_fast() -\u003e Option\u003cSelf\u003e {\n        // Use mmap for zero-copy reads\n        // Fall back to regular read if mmap fails\n        // Return None if cache missing/corrupt (never block)\n    }\n    \n    pub fn get(\u0026self, provider: \u0026str) -\u003e Option\u003c\u0026CachedEntry\u003e {\n        self.entries.get(provider).filter(|e| !e.is_stale())\n    }\n}\n```\n\n### Async Write Path\n```rust\nimpl PromptCache {\n    /// Write cache asynchronously - never blocks caller\n    pub fn write_async(data: ProviderPayload) {\n        // Spawn detached thread/process\n        // Use atomic rename for corruption safety\n        // temp file -\u003e atomic rename to cache file\n    }\n}\n```\n\n### Staleness Handling\n- Fresh: \u003c5 minutes old, display normally\n- Stale: 5-30 minutes old, display with \"~\" prefix\n- Very stale: \u003e30 minutes old, display with \"?\" prefix\n- Missing: Display \"-\" or nothing\n\n## Acceptance Criteria\n- [ ] Cache reads complete in \u003c10ms (benchmark required)\n- [ ] Cache writes are non-blocking\n- [ ] Atomic writes prevent corruption\n- [ ] Graceful handling of missing/corrupt cache\n- [ ] Configurable TTL per provider\n- [ ] Unit tests with mock filesystem\n\n## Performance Benchmarks\nMust include benchmarks proving:\n- Cold read: \u003c20ms\n- Warm read (hot file cache): \u003c5ms\n- Write: \u003c1ms (async spawn time only)\n\n## Dependencies\n- Requires history storage (EPIC 1) for initial population\n- Used by prompt command (sibling task)\n\n## Implementation Notes\n- Consider using `memmap2` crate for memory-mapped reads\n- Use `tempfile` crate for atomic writes\n- Cache file should be small (\u003c10KB) for fast reads\n- JSON format for debuggability, consider msgpack if too slow","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:10:56.502647039-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:10:56.502647039-05:00"}
{"id":"coding_agent_usage_tracker-moy","title":"Config: Provider-specific settings","description":"## Overview\nImplement per-provider configuration for timeouts, enabling/disabling, priority ordering, and custom settings.\n\n## Background \u0026 Rationale\nDifferent providers have different characteristics:\n- Claude CLI might be slow (needs longer timeout)\n- User might want to disable Codex entirely\n- Priority affects which provider is tried first in fallback scenarios\n- Some providers might need custom settings (API endpoints, etc.)\n\n## Technical Approach\n\n### 1. Provider Config Structure\n```rust\n// In core/config.rs\n#[derive(Debug, Deserialize, Default)]\n#[serde(default)]\npub struct ProviderConfig {\n    /// Whether this provider is enabled.\n    pub enabled: bool,\n    \n    /// Priority for ordering (lower = higher priority).\n    pub priority: Option\u003ci32\u003e,\n    \n    /// Override timeout for this provider specifically.\n    pub timeout_seconds: Option\u003cu64\u003e,\n    \n    /// Override default strategies to try.\n    pub strategies: Option\u003cVec\u003cString\u003e\u003e,\n    \n    /// Custom API endpoint (for enterprise/proxy setups).\n    pub api_base: Option\u003cString\u003e,\n}\n```\n\n### 2. Example Config\n```toml\n[providers.claude]\nenabled = true\npriority = 1\ntimeout_seconds = 15\nstrategies = [\"oauth\", \"cli-pty\"]  # Skip web scraping\n\n[providers.codex]\nenabled = true\npriority = 2\n# Uses default timeout and strategies\n\n[providers.gemini]\nenabled = false  # Disabled entirely\n\n[providers.cursor]\nenabled = true\npriority = 3\napi_base = \"https://internal-proxy.company.com/cursor\"\n```\n\n### 3. Merging with Defaults\n```rust\nimpl Config {\n    /// Get effective config for a provider.\n    pub fn provider_config(\u0026self, provider: Provider) -\u003e ProviderConfig {\n        let name = provider.cli_name();\n        \n        self.providers\n            .get(name)\n            .cloned()\n            .unwrap_or_else(|| ProviderConfig {\n                enabled: true,  // Default: all providers enabled\n                priority: Some(provider.default_priority()),\n                timeout_seconds: None,\n                strategies: None,\n                api_base: None,\n            })\n    }\n}\n\nimpl Provider {\n    pub fn default_priority(\u0026self) -\u003e i32 {\n        match self {\n            Provider::Claude =\u003e 1,\n            Provider::Codex =\u003e 2,\n            Provider::Gemini =\u003e 3,\n            Provider::Cursor =\u003e 4,\n            Provider::Windsurf =\u003e 5,\n        }\n    }\n}\n```\n\n### 4. Integration with Fetch Plan\n```rust\n// In core/fetch_plan.rs\nimpl FetchPlan {\n    pub fn from_config(provider: Provider, config: \u0026ProviderConfig) -\u003e Self {\n        let base_plan = match provider {\n            Provider::Claude =\u003e claude::fetch_plan(),\n            // ... etc\n        };\n        \n        // Apply config overrides\n        let mut plan = base_plan;\n        \n        if let Some(timeout) = config.timeout_seconds {\n            plan.timeout = Duration::from_secs(timeout);\n        }\n        \n        if let Some(strategies) = \u0026config.strategies {\n            plan.strategies.retain(|s| strategies.contains(\u0026s.id.to_string()));\n        }\n        \n        plan\n    }\n}\n```\n\n### 5. Filtering Enabled Providers\n```rust\nimpl ResolvedConfig {\n    /// Get list of enabled providers, sorted by priority.\n    pub fn enabled_providers(\u0026self) -\u003e Vec\u003cProvider\u003e {\n        let config = Config::load().unwrap_or_default();\n        \n        self.providers\n            .iter()\n            .filter(|p| config.provider_config(**p).enabled)\n            .cloned()\n            .sorted_by_key(|p| config.provider_config(*p).priority)\n            .collect()\n    }\n}\n```\n\n## Files to Modify\n- `src/core/config.rs`: Add ProviderConfig and methods\n- `src/core/fetch_plan.rs`: Use provider config for timeouts/strategies\n- `src/core/pipeline.rs`: Filter disabled providers\n- `src/core/provider.rs`: Add default_priority()\n\n## Dependencies\n- Requires core config loading (1n2) to be complete\n\n## Acceptance Criteria\n- [ ] Per-provider enabled flag works\n- [ ] Per-provider timeout override works\n- [ ] Per-provider priority affects ordering\n- [ ] Disabled providers are skipped entirely\n- [ ] Default values used when not specified\n- [ ] Strategy filtering works\n\n## Testing Strategy\n- Test enabling/disabling providers\n- Test timeout override per provider\n- Test priority ordering\n- Test strategy filtering\n- Test defaults when no provider config","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:56:56.553931483-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:56:56.553931483-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-moy","depends_on_id":"coding_agent_usage_tracker-1n2","type":"blocks","created_at":"2026-01-18T02:57:28.162915779-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-nlu","title":"Unit tests for core/models.rs (data structures)","description":"## Overview\nComprehensive tests for all core data models.\n\n## Target: src/core/models.rs\nFoundation for: All provider data handling\n\n## Test Cases\n1. **RateWindow**\n   - remaining_percent() calculation\n   - Boundary values (0%, 100%, \u003e100%)\n   - Serialization round-trip\n\n2. **UsageSnapshot**\n   - Construction with various window combinations\n   - Updated_at timestamp handling\n   - Identity field handling\n\n3. **StatusIndicator**\n   - from_statuspage() parsing for all variants\n   - label() output verification\n   - Unknown fallback behavior\n\n4. **CostPayload**\n   - Token aggregation\n   - USD calculation precision\n   - Daily breakdown handling\n\n5. **RobotOutput**\n   - Envelope construction\n   - Error attachment\n   - Schema version correctness\n\n## Acceptance Criteria\n- [ ] All model constructors tested\n- [ ] All computed properties tested\n- [ ] Serde round-trips verified\n- [ ] Edge cases (empty, null, overflow)","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:13:35.975330162-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:13:35.975330162-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-nlu","depends_on_id":"coding_agent_usage_tracker-32d","type":"blocks","created_at":"2026-01-18T02:18:19.320647344-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-okl","title":"API: Implement daemon mode with process management","description":"## Summary\nRun caut server as a background daemon with proper process management.\n\n## CLI Flags\n- `caut serve --daemon` - Fork to background\n- `caut serve --pidfile /var/run/caut.pid` - Write PID file\n- `caut serve stop` - Stop running daemon\n\n## Implementation\n```rust\npub fn daemonize(config: \u0026ServerConfig) -\u003e Result\u003c()\u003e {\n    // Fork process\n    match fork()? {\n        ForkResult::Parent { child } =\u003e {\n            // Write PID file\n            if let Some(pidfile) = \u0026config.pidfile {\n                fs::write(pidfile, child.to_string())?;\n            }\n            println!(\"caut server started (PID: {})\", child);\n            std::process::exit(0);\n        }\n        ForkResult::Child =\u003e {\n            // Become session leader\n            setsid()?;\n            \n            // Redirect stdio to /dev/null\n            redirect_stdio_to_null()?;\n            \n            // Run server\n            run_server(config)\n        }\n    }\n}\n```\n\n## Signal Handling\n- SIGTERM ‚Üí Graceful shutdown (finish pending requests)\n- SIGHUP ‚Üí Reload configuration\n- SIGINT ‚Üí Immediate shutdown\n\n## Systemd Service File\n```ini\n[Unit]\nDescription=caut API Server\nAfter=network.target\n\n[Service]\nType=simple\nExecStart=/usr/local/bin/caut serve --port 8420\nRestart=on-failure\nUser=caut\n\n[Install]\nWantedBy=multi-user.target\n```\n\n## Acceptance Criteria\n- [ ] --daemon forks correctly\n- [ ] PID file written and cleaned up\n- [ ] Signal handlers work\n- [ ] stop command works\n- [ ] Systemd service file provided\n- [ ] Logs to file when daemonized","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:02:01.903656527-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:02:01.903656527-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-okl","depends_on_id":"coding_agent_usage_tracker-isd","type":"blocks","created_at":"2026-01-18T15:03:58.936617141-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-oq1","title":"TUI: Add sparkline visualization from history","description":"Implement UsageSparkline component showing trend charts from historical data. Calculate trend direction and integrate with provider cards. See /tmp/bead_tui_impl_tasks.md Task 3 for implementation details.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:13:09.460772043-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:13:09.460772043-05:00"}
{"id":"coding_agent_usage_tracker-oyf","title":"E2E test script: caut cost command scenarios","description":"## Overview\nEnd-to-end test suite for the cost command with comprehensive logging.\n\n## Dual Implementation Strategy\nCreate BOTH shell scripts and Rust integration tests:\n1. **Shell scripts** (`tests/e2e/test_cost.sh`) - CI-friendly, quick iteration\n2. **Rust tests** (`tests/e2e_cost.rs`) - Programmatic, precise assertions\n\n## Shell Script: tests/e2e/test_cost.sh\n\n### Test Scenarios\n```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\nLOG_DIR=\"${TEST_LOG_DIR:-./test-logs}\"\nLOG_FILE=\"$LOG_DIR/test_cost_$(date +%Y%m%d_%H%M%S).log\"\nmkdir -p \"$LOG_DIR\"\n\nlog() { echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $*\" | tee -a \"$LOG_FILE\"; }\n\n# Test 1: Basic Cost Query\nlog \"TEST: Basic cost command\"\nOUTPUT=$(caut cost 2\u003e\u00261) || EXIT_CODE=$?\nlog \"Exit code: ${EXIT_CODE:-0}\"\nlog \"OUTPUT:\\n$OUTPUT\"\n\n# Verify output structure\nif echo \"$OUTPUT\" | grep -qE 'Today|Last 30 days|Cost'; then\n    log \"PASS: Cost output has expected structure\"\nelse\n    log \"WARN: Cost output may be empty or different format\"\nfi\n\n# Test 2: JSON Cost Output\nlog \"TEST: JSON cost output\"\nOUTPUT=$(caut cost --json 2\u003e\u00261)\nif echo \"$OUTPUT\" | jq . \u003e/dev/null 2\u003e\u00261; then\n    log \"PASS: Valid JSON\"\n    \n    # Extract and validate cost values\n    SESSION_COST=$(echo \"$OUTPUT\" | jq -r '.data[0].sessionCostUsd // \"null\"')\n    MONTHLY_COST=$(echo \"$OUTPUT\" | jq -r '.data[0].last30DaysCostUsd // \"null\"')\n    log \"Session cost: $SESSION_COST\"\n    log \"Monthly cost: $MONTHLY_COST\"\n    \n    # Verify costs are non-negative (if present)\n    if [ \"$SESSION_COST\" != \"null\" ]; then\n        if (( $(echo \"$SESSION_COST \u003e= 0\" | bc -l) )); then\n            log \"PASS: Session cost is non-negative\"\n        else\n            log \"FAIL: Session cost is negative: $SESSION_COST\"\n        fi\n    fi\nelse\n    log \"FAIL: Invalid JSON\"\nfi\n\n# Test 3: Provider-Specific Cost\nlog \"TEST: Provider-specific cost\"\nOUTPUT=$(caut cost --provider=codex 2\u003e\u00261) || true\nlog \"Codex cost output: $OUTPUT\"\n\n# Test 4: Empty History Handling\nlog \"TEST: Empty history (if applicable)\"\n# This would need a clean test environment\nlog \"SKIP: Requires isolated environment\"\n\n# Test 5: Token Count Formatting\nlog \"TEST: Token count formatting\"\nOUTPUT=$(caut cost --json 2\u003e\u00261)\nTOKENS=$(echo \"$OUTPUT\" | jq -r '.data[0].sessionTokens // \"null\"')\nif [ \"$TOKENS\" != \"null\" ]; then\n    log \"Token count: $TOKENS\"\n    # Verify it's a reasonable integer\n    if [[ \"$TOKENS\" =~ ^[0-9]+$ ]]; then\n        log \"PASS: Token count is valid integer\"\n    else\n        log \"WARN: Token count format unexpected: $TOKENS\"\n    fi\nfi\n\nlog \"Test complete. Log: $LOG_FILE\"\n```\n\n## Rust Tests: tests/e2e_cost.rs\n\n```rust\nuse assert_cmd::Command;\nuse predicates::prelude::*;\n\n#[test]\nfn test_cost_basic() {\n    let mut cmd = Command::cargo_bin(\"caut\").unwrap();\n    cmd.arg(\"cost\")\n        .assert()\n        .success();\n}\n\n#[test]\nfn test_cost_json_schema() {\n    let mut cmd = Command::cargo_bin(\"caut\").unwrap();\n    let output = cmd.arg(\"cost\").arg(\"--json\").output().unwrap();\n    \n    let json: serde_json::Value = serde_json::from_slice(\u0026output.stdout)\n        .expect(\"Output should be valid JSON\");\n    \n    // Verify schema\n    assert_eq!(json.get(\"schemaVersion\").and_then(|v| v.as_str()), Some(\"caut.v1\"));\n    assert_eq!(json.get(\"command\").and_then(|v| v.as_str()), Some(\"cost\"));\n}\n\n#[test]\nfn test_cost_values_non_negative() {\n    let mut cmd = Command::cargo_bin(\"caut\").unwrap();\n    let output = cmd.arg(\"cost\").arg(\"--json\").output().unwrap();\n    \n    let json: serde_json::Value = serde_json::from_slice(\u0026output.stdout).unwrap();\n    \n    if let Some(data) = json.get(\"data\").and_then(|d| d.as_array()) {\n        for provider in data {\n            if let Some(cost) = provider.get(\"sessionCostUsd\").and_then(|c| c.as_f64()) {\n                assert!(cost \u003e= 0.0, \"Cost should be non-negative\");\n            }\n        }\n    }\n}\n\n#[test]\nfn test_cost_provider_filter() {\n    let mut cmd = Command::cargo_bin(\"caut\").unwrap();\n    let output = cmd.arg(\"cost\")\n        .arg(\"--provider=claude\")\n        .arg(\"--json\")\n        .output()\n        .unwrap();\n    \n    let json: serde_json::Value = serde_json::from_slice(\u0026output.stdout).unwrap();\n    \n    if let Some(data) = json.get(\"data\").and_then(|d| d.as_array()) {\n        for provider in data {\n            let name = provider.get(\"provider\").and_then(|p| p.as_str()).unwrap_or(\"\");\n            assert!(name.to_lowercase().contains(\"claude\"), \n                \"Only Claude should be present when filtered\");\n        }\n    }\n}\n```\n\n## Cost-Specific Verification\n\n### Numerical Accuracy Tests\n- Token counts: integers, non-negative\n- USD costs: 2 decimal precision, non-negative\n- Daily breakdowns: dates in YYYY-MM-DD format\n- Totals: sum of daily values matches\n\n### Time-Based Tests\n- \"Today\" reflects current date\n- \"Last 30 days\" window is accurate\n- Reset timestamps are valid ISO8601\n\n## Logging Specification\nSame as test_usage.sh - see that bead for full logging spec.\n\n## Acceptance Criteria\n- [ ] Shell script with cost-specific scenarios\n- [ ] Rust tests with assert_cmd\n- [ ] Cost value validation (non-negative)\n- [ ] Token count validation (integer)\n- [ ] JSON schema compliance\n- [ ] Provider filtering works correctly\n- [ ] Comprehensive logging","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:16:28.080879087-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T12:44:35.546773224-05:00","closed_at":"2026-01-18T12:44:35.546773224-05:00","close_reason":"E2E cost command tests complete: Shell script (16 tests) and Rust tests (43 tests) both pass. Tests cover basic invocation, JSON/markdown output, flag handling, provider filtering, cost value validation (non-negative), token count validation (integer), schema compliance, and comprehensive logging. All acceptance criteria met.","dependencies":[{"issue_id":"coding_agent_usage_tracker-oyf","depends_on_id":"coding_agent_usage_tracker-p8x","type":"blocks","created_at":"2026-01-18T02:18:32.792410832-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-p7p","title":"History: Add automatic snapshot capture in fetch pipeline","description":"## Task Overview\n\nHook into the existing fetch pipeline to automatically record a snapshot every time usage is successfully fetched. Users shouldn't have to do anything - every `caut usage` call generates a data point.\n\n## Parent EPIC\n[EPIC] Historical Usage Tracking with Trend Visualization (coding_agent_usage_tracker-smv)\n\n## Technical Requirements\n\n### Integration Point\n\nThe fetch pipeline (likely in `core/pipeline.rs` or similar) needs to call the history storage after successful fetch:\n\n```rust\n// In the fetch orchestration code\npub async fn fetch_provider_usage(provider: \u0026Provider) -\u003e Result\u003cUsageSnapshot\u003e {\n    let snapshot = execute_fetch_strategies(provider).await?;\n    \n    // NEW: Record to history (fire-and-forget, don't block on failure)\n    if let Err(e) = record_to_history(\u0026snapshot, provider) {\n        tracing::warn!(?e, ?provider, \"Failed to record history snapshot\");\n        // Don't fail the fetch - history is secondary\n    }\n    \n    Ok(snapshot)\n}\n\nfn record_to_history(snapshot: \u0026UsageSnapshot, provider: \u0026Provider) -\u003e Result\u003c()\u003e {\n    let store = HistoryStore::open(\u0026get_history_path())?;\n    store.record_snapshot(snapshot, provider)?;\n    Ok(())\n}\n```\n\n### Key Principles\n\n1. **Non-blocking**: History recording should not slow down fetch\n2. **Fault-tolerant**: History failures don't fail the fetch\n3. **Automatic**: Zero user configuration needed\n4. **Efficient**: Minimal overhead per fetch\n\n### Data Capture\n\nFor each successful fetch, capture:\n- All rate window percentages\n- Reset times\n- Cost data (if available)\n- Credits (if applicable)\n- Source (which fetch strategy succeeded)\n- Fetch duration (for performance tracking)\n\n### Deduplication\n\nAvoid recording duplicate snapshots for rapid sequential calls:\n\n```rust\nfn should_record(provider: \u0026Provider, last_recorded: Option\u003cDateTime\u003cUtc\u003e\u003e) -\u003e bool {\n    match last_recorded {\n        Some(last) =\u003e {\n            // Don't record if last snapshot was within 30 seconds\n            Utc::now() - last \u003e Duration::seconds(30)\n        }\n        None =\u003e true,\n    }\n}\n```\n\n### Error Handling\n\n```rust\n#[derive(Debug, thiserror::Error)]\npub enum HistoryError {\n    #[error(\"Database error: {0}\")]\n    Database(#[from] rusqlite::Error),\n    \n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n    \n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n}\n\n// In pipeline code - log but don't propagate\nmatch record_to_history(\u0026snapshot, provider) {\n    Ok(_) =\u003e tracing::debug!(?provider, \"Recorded history snapshot\"),\n    Err(e) =\u003e tracing::warn!(?e, ?provider, \"History recording failed\"),\n}\n```\n\n## Deliverables\n\n- [ ] Modify fetch pipeline to call history storage\n- [ ] Implement deduplication logic\n- [ ] Add tracing/logging for observability\n- [ ] Ensure non-blocking behavior\n- [ ] Unit tests for integration point\n\n## Acceptance Criteria\n\n- [ ] Every successful fetch creates a history record\n- [ ] Fetch latency not noticeably affected (\u003c5ms overhead)\n- [ ] History failures don't break fetch command\n- [ ] Deduplication prevents spam from rapid calls\n- [ ] Logs show history recording activity","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:59:09.950424476-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:59:09.950424476-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-p7p","depends_on_id":"coding_agent_usage_tracker-hws","type":"blocks","created_at":"2026-01-18T14:21:40.564799531-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-p8x","title":"Integration tests: Provider to Render pipeline","description":"## Overview\nTest the full data flow from provider extraction to rendered output.\n\n## Scope\nProvider ‚Üí Models ‚Üí Render ‚Üí Output\n\n## Test Scenarios\n1. **Full Usage Pipeline**\n   - Provider extracts usage data\n   - Data transforms to ProviderPayload\n   - Render produces human output\n   - Verify output content matches input\n\n2. **Full Cost Pipeline**\n   - Provider extracts cost data\n   - Data transforms to CostPayload\n   - Render produces formatted output\n   - Verify calculations are correct\n\n3. **Multi-Provider Aggregation**\n   - Multiple providers produce data\n   - All results aggregated\n   - Output contains all providers\n\n## Test Infrastructure\n- Use real data fixtures\n- No HTTP mocking (test internal flow)\n- Detailed logging at each stage\n\n## Acceptance Criteria\n- [ ] Usage pipeline end-to-end\n- [ ] Cost pipeline end-to-end\n- [ ] Multi-provider handling\n- [ ] Error propagation verified","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:15:21.432331707-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T11:23:42.654100729-05:00","closed_at":"2026-01-18T11:23:42.654100729-05:00","close_reason":"Completed: 21 pipeline tests covering usage‚Üíhuman/robot/md, cost‚Üíhuman/robot/md, error propagation, round-trip serialization, cross-format consistency. Added test-utils feature flag to expose macros for integration tests.","dependencies":[{"issue_id":"coding_agent_usage_tracker-p8x","depends_on_id":"coding_agent_usage_tracker-8gp","type":"blocks","created_at":"2026-01-18T02:18:28.804265392-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-p8x","depends_on_id":"coding_agent_usage_tracker-2k1","type":"blocks","created_at":"2026-01-18T02:18:28.861686728-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-p8x","depends_on_id":"coding_agent_usage_tracker-2yz","type":"blocks","created_at":"2026-01-18T02:18:28.917464458-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-p8x","depends_on_id":"coding_agent_usage_tracker-1i9","type":"blocks","created_at":"2026-01-18T02:18:28.968104672-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-p8x","depends_on_id":"coding_agent_usage_tracker-uuv","type":"blocks","created_at":"2026-01-18T02:57:32.037562311-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-pj0","title":"Prompt: Performance benchmarks and shell compatibility tests","description":"## Summary\nImplement comprehensive test suite for Shell Prompt Integration with performance benchmarks, shell compatibility tests, and cache verification.\n\n## Parent EPIC\n[EPIC] Shell Prompt Integration (coding_agent_usage_tracker-5rv)\n\n## Test Categories\n\n### 1. Performance Benchmarks (CRITICAL)\nThe 50ms target is the most important requirement for this feature.\n\n```rust\n#[cfg(test)]\nmod performance_tests {\n    use std::time::{Duration, Instant};\n    \n    #[test]\n    fn bench_cache_read_cold() {\n        let cache = setup_populated_cache();\n        \n        // Simulate cold read (file not in OS cache)\n        drop_os_caches();  // Platform-specific\n        \n        let start = Instant::now();\n        let _ = cache.read_fast();\n        let elapsed = start.elapsed();\n        \n        assert!(elapsed \u003c Duration::from_millis(20), \n            \"Cold cache read took {:?}, target \u003c20ms\", elapsed);\n        \n        println!(\"Cold cache read: {:?}\", elapsed);\n    }\n    \n    #[test]\n    fn bench_cache_read_warm() {\n        let cache = setup_populated_cache();\n        \n        // Warm up OS cache\n        let _ = cache.read_fast();\n        \n        let start = Instant::now();\n        for _ in 0..100 {\n            let _ = cache.read_fast();\n        }\n        let elapsed = start.elapsed();\n        let per_read = elapsed / 100;\n        \n        assert!(per_read \u003c Duration::from_millis(5),\n            \"Warm cache read took {:?}, target \u003c5ms\", per_read);\n        \n        println!(\"Warm cache read (avg of 100): {:?}\", per_read);\n    }\n    \n    #[test]\n    fn bench_prompt_command_total() {\n        // Full prompt command including formatting\n        let start = Instant::now();\n        \n        let output = std::process::Command::new(\"caut\")\n            .args([\"prompt\", \"--cache-only\"])\n            .output()\n            .unwrap();\n        \n        let elapsed = start.elapsed();\n        \n        assert!(output.status.success());\n        assert!(elapsed \u003c Duration::from_millis(50),\n            \"Prompt command took {:?}, target \u003c50ms\", elapsed);\n        \n        println!(\"Full prompt command: {:?}\", elapsed);\n    }\n    \n    #[test]\n    fn bench_prompt_under_load() {\n        // Test performance under repeated rapid calls (like shell prompt)\n        let mut times = Vec::new();\n        \n        for _ in 0..20 {\n            let start = Instant::now();\n            let _ = std::process::Command::new(\"caut\")\n                .args([\"prompt\", \"--cache-only\"])\n                .output();\n            times.push(start.elapsed());\n        }\n        \n        let max = times.iter().max().unwrap();\n        let avg = times.iter().sum::\u003cDuration\u003e() / times.len() as u32;\n        \n        assert!(*max \u003c Duration::from_millis(100),\n            \"Max time {:?} exceeds 100ms\", max);\n        assert!(avg \u003c Duration::from_millis(50),\n            \"Avg time {:?} exceeds 50ms\", avg);\n        \n        println!(\"20 calls: avg {:?}, max {:?}\", avg, max);\n    }\n}\n```\n\n### 2. Unit Tests: Cache Layer\n```rust\n#[cfg(test)]\nmod cache_tests {\n    #[test]\n    fn test_cache_write_and_read() {\n        let tmp = TempDir::new().unwrap();\n        let cache = PromptCache::new(tmp.path());\n        \n        let data = provider_payload_default(\"claude\", \"oauth\");\n        cache.write(\u0026data).unwrap();\n        \n        let read = cache.read().unwrap().unwrap();\n        assert!((read.primary_pct - 30.0).abs() \u003c f64::EPSILON);\n    }\n    \n    #[test]\n    fn test_cache_atomic_write() {\n        let tmp = TempDir::new().unwrap();\n        let cache = PromptCache::new(tmp.path());\n        \n        // Write should not corrupt on partial failure\n        // Simulate by checking temp file behavior\n        let data = provider_payload_default(\"claude\", \"oauth\");\n        \n        // Start write\n        let tmp_path = cache.cache_path().with_extension(\"tmp\");\n        cache.write(\u0026data).unwrap();\n        \n        // Temp file should not exist after successful write\n        assert!(!tmp_path.exists());\n    }\n    \n    #[test]\n    fn test_cache_staleness_levels() {\n        let tmp = TempDir::new().unwrap();\n        let cache = PromptCache::new(tmp.path());\n        \n        // Write with backdated timestamp\n        let mut entry = CachedEntry::from(\u0026provider_payload_default(\"claude\", \"oauth\"));\n        \n        // Fresh (\u003c 5 min)\n        entry.cached_at = Utc::now() - Duration::minutes(3);\n        assert!(entry.is_fresh());\n        \n        // Stale (5-30 min)\n        entry.cached_at = Utc::now() - Duration::minutes(15);\n        assert!(entry.is_stale());\n        \n        // Very stale (\u003e 30 min)\n        entry.cached_at = Utc::now() - Duration::minutes(45);\n        assert!(entry.is_very_stale());\n    }\n    \n    #[test]\n    fn test_cache_missing_handled() {\n        let tmp = TempDir::new().unwrap();\n        let cache = PromptCache::new(tmp.path());\n        \n        // No cache file\n        assert!(cache.read().unwrap().is_none());\n        assert!(cache.read_fast().is_none());\n    }\n    \n    #[test]\n    fn test_cache_corrupt_handled() {\n        let tmp = TempDir::new().unwrap();\n        let cache_path = tmp.path().join(\"prompt_cache.json\");\n        \n        // Write garbage\n        std::fs::write(\u0026cache_path, \"not json at all {{{\").unwrap();\n        \n        let cache = PromptCache::new(tmp.path());\n        // Should return None, not error\n        assert!(cache.read().unwrap().is_none());\n    }\n}\n```\n\n### 3. Unit Tests: Prompt Command\n```rust\n#[cfg(test)]\nmod prompt_command_tests {\n    #[test]\n    fn test_minimal_format() {\n        let output = format_minimal(\u0026[\n            (\"claude\", 30.0),\n            (\"codex\", 45.0),\n        ]);\n        assert_eq!(output, \"C:30%|X:45%\");\n    }\n    \n    #[test]\n    fn test_compact_format() {\n        let output = format_compact(\u0026[(\"claude\", 30.0)]);\n        assert_eq!(output, \"claude:30%\");\n    }\n    \n    #[test]\n    fn test_stale_indicator() {\n        let output = format_with_staleness(30.0, Staleness::Stale { age: Duration::minutes(10) });\n        assert!(output.starts_with(\"~\"));\n    }\n    \n    #[test]\n    fn test_never_errors_to_stdout() {\n        // Even with corrupt cache, broken state, etc.\n        // Command should output empty string or fallback, not error\n        let result = run_prompt_command_with_broken_state();\n        assert!(result.status.success());\n        // May be empty, but not error message\n        assert!(!String::from_utf8_lossy(\u0026result.stderr).contains(\"error\"));\n    }\n}\n```\n\n### 4. Shell Compatibility Tests\n```bash\n#!/bin/bash\n# tests/e2e/shell_integration.sh\n\nset -euo pipefail\nsource \"$(dirname \"$0\")/helpers.sh\"\n\nlog_section \"Shell Integration Tests\"\n\nTEMP_DIR=$(mktemp -d)\nexport CAUT_DATA_DIR=\"$TEMP_DIR\"\ntrap \"rm -rf $TEMP_DIR\" EXIT\n\n# Setup: create cache\ncaut fetch --mock --provider claude\n\n# Test 1: Bash integration\nlog_test \"Bash prompt integration\"\nbash -c '\n    eval \"$(caut prompt init bash)\"\n    # Verify PS1 contains caut\n    [[ \"$PS1\" == *\"caut\"* ]] || exit 1\n    # Test the function works\n    OUTPUT=$(_caut_prompt)\n    echo \"Bash output: $OUTPUT\"\n'\nlog_pass\n\n# Test 2: Zsh integration  \nlog_test \"Zsh prompt integration\"\nif command -v zsh \u0026\u003e/dev/null; then\n    zsh -c '\n        eval \"$(caut prompt init zsh)\"\n        # Test prompt function\n        _caut_prompt\n        echo \"Zsh: $CAUT_PROMPT\"\n    '\n    log_pass\nelse\n    log_skip \"zsh not installed\"\nfi\n\n# Test 3: Fish integration\nlog_test \"Fish prompt integration\"\nif command -v fish \u0026\u003e/dev/null; then\n    fish -c '\n        source (caut prompt init fish | psub)\n        set output (_caut_prompt)\n        echo \"Fish: $output\"\n    '\n    log_pass\nelse\n    log_skip \"fish not installed\"\nfi\n\n# Test 4: Performance in shell context\nlog_test \"Prompt performance in shell\"\nSTART=$(date +%s%N)\nfor i in {1..10}; do\n    caut prompt --cache-only \u003e/dev/null 2\u003e\u00261\ndone\nEND=$(date +%s%N)\nELAPSED_MS=$(( (END - START) / 1000000 ))\nAVG_MS=$(( ELAPSED_MS / 10 ))\necho \"Average: ${AVG_MS}ms\"\n[[ $AVG_MS -lt 50 ]] || fail \"Too slow: ${AVG_MS}ms avg\"\nlog_pass\n\n# Test 5: Graceful degradation\nlog_test \"No cache graceful handling\"\nrm -rf \"$TEMP_DIR\"/*\nOUTPUT=$(caut prompt --cache-only 2\u003e\u00261)\n# Should be empty or minimal, not error\n[[ -z \"$OUTPUT\" || \"$OUTPUT\" == \"-\" ]] \u0026\u0026 log_pass || log_pass \"Got: $OUTPUT\"\n\nlog_summary\n```\n\n### 5. Integration Tests\n```rust\n#[test]\nfn test_prompt_populated_by_fetch() {\n    let tmp = TempDir::new().unwrap();\n    let cache = PromptCache::new(tmp.path());\n    \n    // Initially empty\n    assert!(cache.read().unwrap().is_none());\n    \n    // Run fetch (mocked)\n    run_fetch_with_cache_update(\u0026tmp);\n    \n    // Cache should now be populated\n    let entry = cache.read().unwrap().unwrap();\n    assert!(entry.primary_pct \u003e 0.0);\n}\n```\n\n## Acceptance Criteria\n- [ ] Cache read \u003c10ms (warm), \u003c20ms (cold)\n- [ ] Full prompt command \u003c50ms\n- [ ] All shell snippets work (bash, zsh, fish)\n- [ ] Staleness indicators correct\n- [ ] Never errors or hangs\n- [ ] Performance consistent under load\n- [ ] Logging verified\n\n## Dependencies\n- Requires logging infrastructure\n- Requires prompt implementation tasks\n","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:49:18.061097858-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:49:18.061097858-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-pj0","depends_on_id":"coding_agent_usage_tracker-zev","type":"blocks","created_at":"2026-01-18T14:56:59.212582432-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-pj0","depends_on_id":"coding_agent_usage_tracker-5rv","type":"blocks","created_at":"2026-01-18T14:56:59.26221172-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-ptc","title":"Parallel: Error aggregation and structured reporting","description":"## Overview\nImplement comprehensive error aggregation that collects and reports failures from multiple providers in a structured, actionable way.\n\n## Background \u0026 Rationale\nWhen running parallel fetches with graceful degradation, we need to collect errors from multiple providers and present them coherently. Users need to understand: what failed, why it failed, which fallback strategies were attempted, and what they can do about it.\n\n## Technical Approach\n\n### 1. Error Aggregation Structure\n```rust\n// In error.rs or new core/error_aggregate.rs\npub struct AggregatedErrors {\n    pub errors: Vec\u003cProviderError\u003e,\n    pub partial_success: bool,\n    pub total_attempted: usize,\n    pub total_succeeded: usize,\n}\n\npub struct ProviderError {\n    pub provider: Provider,\n    pub strategies_attempted: Vec\u003cStrategyAttempt\u003e,\n    pub final_error: CautError,\n    pub recoverable: bool,\n    pub suggested_action: Option\u003cString\u003e,\n}\n\npub struct StrategyAttempt {\n    pub strategy_id: String,  // e.g., \"claude-oauth\", \"claude-cli-pty\"\n    pub kind: FetchKind,\n    pub error: Option\u003cCautError\u003e,\n    pub duration: Duration,\n}\n```\n\n### 2. Error Collection During Fetch\n- Each strategy attempt records its outcome\n- Track which strategies were tried and in what order\n- Measure timing for each attempt (helps diagnose timeouts)\n- Flag whether error is recoverable (e.g., auth expired vs network down)\n\n### 3. Error Categorization\n```rust\nimpl CautError {\n    pub fn is_recoverable(\u0026self) -\u003e bool {\n        matches!(self,\n            CautError::Network(_) |\n            CautError::Timeout(_) |\n            CautError::RateLimited { .. }\n        )\n    }\n\n    pub fn suggested_action(\u0026self) -\u003e Option\u003c\u0026str\u003e {\n        match self {\n            CautError::AuthExpired { .. } =\u003e Some(\"Run `caut auth refresh`\"),\n            CautError::NotConfigured { .. } =\u003e Some(\"Run `caut setup \u003cprovider\u003e`\"),\n            _ =\u003e None,\n        }\n    }\n}\n```\n\n### 4. Rendering Aggregated Errors\nHuman output:\n```\n‚ö† Some providers failed:\n\n  Claude (1 strategy attempted):\n    ‚Ä¢ oauth: Authentication expired\n      üí° Run `caut auth refresh claude`\n\n  Codex (2 strategies attempted):\n    ‚Ä¢ cli: Command timed out (10s)\n    ‚Ä¢ api: Network error\n      (Will retry on next run)\n```\n\nJSON output includes full `errors` array with strategy attempts.\n\n## Files to Modify\n- `src/error.rs`: Add aggregation types\n- `src/core/pipeline.rs`: Collect errors during fetch\n- `src/render/human.rs`: Error section rendering\n- `src/render/json.rs`: Structured error output\n\n## Dependencies\n- Requires graceful degradation (jt0) to be complete\n- Works alongside timeout handling (b14)\n\n## Acceptance Criteria\n- [ ] Each provider failure records all attempted strategies\n- [ ] Errors include timing information\n- [ ] Recoverable vs non-recoverable errors are distinguished\n- [ ] Actionable suggestions provided where applicable\n- [ ] JSON output includes full error structure\n- [ ] Human output is clear and actionable\n\n## Testing Strategy\n- Mock multiple failure modes for same provider\n- Verify all strategies are recorded in order\n- Test timing capture accuracy\n- Verify suggestions appear for appropriate errors","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:54:18.304572072-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:54:18.304572072-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-ptc","depends_on_id":"coding_agent_usage_tracker-jt0","type":"blocks","created_at":"2026-01-18T02:54:45.95059242-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-q0r","title":"Budget: Add alert notifications (CLI, desktop, watch)","description":"## Summary\nImplement alert notifications for budget violations and threshold warnings.\n\n## Background\nWhen budgets are exceeded or thresholds reached, users need to be notified through:\n1. CLI output (always)\n2. Desktop notifications (optional)\n3. Watch mode alerts (visual + optional sound)\n\n## Technical Design\n\n### Alert Renderer\n```rust\npub struct AlertRenderer {\n    config: AlertConfig,\n}\n\nimpl AlertRenderer {\n    /// Render budget status as CLI output\n    pub fn render_cli(\u0026self, status: \u0026BudgetStatus) -\u003e String {\n        let mut output = String::new();\n        \n        for violation in \u0026status.violations {\n            output.push_str(\u0026format!(\n                \"üö® BUDGET EXCEEDED: {}\\n\",\n                self.format_violation(violation)\n            ));\n        }\n        \n        for warning in \u0026status.warnings {\n            output.push_str(\u0026format!(\n                \"‚ö†Ô∏è  {}\\n\",\n                self.format_warning(warning)\n            ));\n        }\n        \n        output\n    }\n    \n    fn format_violation(\u0026self, v: \u0026BudgetViolation) -\u003e String {\n        match v {\n            BudgetViolation::DailyCostExceeded { limit, current } =\u003e {\n                format!(\"Daily cost ${:.2} exceeds limit ${:.2}\", current, limit)\n            }\n            BudgetViolation::DailyUsageExceeded { limit, current } =\u003e {\n                format!(\"Daily usage {:.0}% exceeds limit {:.0}%\", current, limit)\n            }\n            // etc.\n        }\n    }\n}\n```\n\n### Desktop Notifications\n```rust\n#[cfg(feature = \"notifications\")]\npub struct DesktopNotifier {\n    enabled: bool,\n}\n\nimpl DesktopNotifier {\n    /// Send desktop notification for budget alert\n    pub fn notify(\u0026self, status: \u0026BudgetStatus) -\u003e Result\u003c()\u003e {\n        if !self.enabled || status.overall == BudgetHealth::Ok {\n            return Ok(());\n        }\n        \n        let (title, body, urgency) = match status.overall {\n            BudgetHealth::Exceeded =\u003e (\n                \"Budget Exceeded!\",\n                self.summarize_violations(\u0026status.violations),\n                Urgency::Critical,\n            ),\n            BudgetHealth::Warning =\u003e (\n                \"Budget Warning\",\n                self.summarize_warnings(\u0026status.warnings),\n                Urgency::Normal,\n            ),\n            BudgetHealth::Ok =\u003e return Ok(()),\n        };\n        \n        Notification::new()\n            .summary(title)\n            .body(\u0026body)\n            .urgency(urgency)\n            .show()?;\n        \n        Ok(())\n    }\n}\n```\n\n### Watch Mode Integration\n```rust\nimpl WatchMode {\n    fn handle_budget_alert(\u0026mut self, status: \u0026BudgetStatus) {\n        // Visual indicator in watch display\n        match status.overall {\n            BudgetHealth::Exceeded =\u003e {\n                self.set_status_bar_color(Color::Red);\n                self.flash_alert();\n                if self.config.sound_enabled {\n                    self.play_alert_sound();\n                }\n            }\n            BudgetHealth::Warning =\u003e {\n                self.set_status_bar_color(Color::Yellow);\n            }\n            BudgetHealth::Ok =\u003e {\n                self.set_status_bar_color(Color::Green);\n            }\n        }\n        \n        // Desktop notification\n        if self.config.desktop_notifications {\n            self.notifier.notify(status)?;\n        }\n    }\n}\n```\n\n### Alert Configuration\n```toml\n# ~/.config/caut/config.toml\n[alerts]\ndesktop_notifications = true\nsound_enabled = false\nsound_file = \"~/.config/caut/alert.wav\"  # optional custom sound\n\n# Notification settings\nnotification_timeout_seconds = 10\nonly_first_violation = false  # if true, only notify once per budget period\n```\n\n## CLI Output Examples\n\n### Budget Warning\n```\nClaude Code (oauth)                                          ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 75%\n  Primary: 75% used (resets in 1h 30m)\n  ‚ö†Ô∏è  Usage threshold reached: 75%\n```\n\n### Budget Exceeded\n```\nClaude Code (oauth)                                          ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 92%\n  Primary: 92% used (resets in 45m)\n  üö® BUDGET EXCEEDED: Daily usage 92% exceeds limit 80%\n```\n\n### Watch Mode with Alert\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  caut watch                                    ‚ö†Ô∏è BUDGET WARNING    ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ  Claude: 75% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë   Codex: $4.50 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë              ‚îÇ\n‚îÇ                                                                     ‚îÇ\n‚îÇ  ‚ö†Ô∏è Claude: Usage threshold reached (75%)                          ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n## Acceptance Criteria\n- [ ] CLI output shows violations and warnings\n- [ ] Desktop notifications work (Linux/macOS/Windows)\n- [ ] Watch mode visual alerts work\n- [ ] Sound alerts configurable\n- [ ] Notifications respect user config\n- [ ] Alert deduplication works\n- [ ] Unit tests for alert rendering\n\n## Platform Support\n- Linux: notify-rust crate (libnotify)\n- macOS: notify-rust (osascript)\n- Windows: notify-rust (winrt)\n\n## Dependencies\n- Requires budget checking (sibling task)\n- notify-rust crate for desktop notifications\n\n## Feature Flags\n```toml\n# Cargo.toml\n[features]\nnotifications = [\"notify-rust\"]\n```\n\nNotifications are optional - core CLI alerts always work.\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:14:53.387814008-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:14:53.387814008-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-q0r","depends_on_id":"coding_agent_usage_tracker-d9u","type":"blocks","created_at":"2026-01-18T14:22:03.515242352-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-qdt","title":"Session: Log parsing validation and cost accuracy tests","description":"## Summary\nImplement comprehensive test suite for Session-Aware Cost Attribution including log parsing validation, cost calculation accuracy, and E2E verification.\n\n## Parent EPIC\n[EPIC] Session-Aware Cost Attribution (coding_agent_usage_tracker-7zh)\n\n## Test Categories\n\n### 1. Unit Tests: Session Log Discovery\n```rust\n#[cfg(test)]\nmod discovery_tests {\n    #[test]\n    fn test_find_claude_session_logs() {\n        let tmp = TempDir::new().unwrap();\n        \n        // Create mock Claude Code structure\n        let project = tmp.path().join(\".claude/projects/test-project/conversations\");\n        fs::create_dir_all(\u0026project).unwrap();\n        fs::write(project.join(\"abc123.jsonl\"), \"{}\").unwrap();\n        \n        let finder = SessionLogFinder::new(tmp.path());\n        let logs = finder.find_claude_sessions();\n        \n        assert_eq!(logs.len(), 1);\n        assert!(logs[0].path.ends_with(\"abc123.jsonl\"));\n    }\n    \n    #[test]\n    fn test_find_codex_session_logs() {\n        let tmp = TempDir::new().unwrap();\n        \n        // Create mock Codex structure\n        let sessions = tmp.path().join(\".codex/sessions\");\n        fs::create_dir_all(\u0026sessions).unwrap();\n        fs::write(sessions.join(\"session_001.jsonl\"), \"{}\").unwrap();\n        \n        let finder = SessionLogFinder::new(tmp.path());\n        let logs = finder.find_codex_sessions();\n        \n        assert_eq!(logs.len(), 1);\n    }\n    \n    #[test]\n    fn test_filter_by_date_range() {\n        // Create logs with different modification times\n        // Verify filtering works\n    }\n    \n    #[test]\n    fn test_handle_missing_directories() {\n        let tmp = TempDir::new().unwrap();\n        let finder = SessionLogFinder::new(tmp.path());\n        \n        // Should return empty, not error\n        assert!(finder.find_claude_sessions().is_empty());\n    }\n}\n```\n\n### 2. Unit Tests: Log Parsing\n```rust\n#[cfg(test)]\nmod parsing_tests {\n    use crate::test_fixtures::*;\n    \n    #[test]\n    fn test_parse_claude_session_basic() {\n        let log_content = load_fixture_text(\"claude/session_basic.jsonl\");\n        let parser = ClaudeSessionParser::new();\n        \n        let usage = parser.parse_str(\u0026log_content).unwrap();\n        \n        assert!(usage.input_tokens \u003e 0);\n        assert!(usage.output_tokens \u003e 0);\n        assert!(usage.models_used.contains(\"claude-3-opus\"));\n    }\n    \n    #[test]\n    fn test_parse_claude_session_with_cache_tokens() {\n        let log_content = load_fixture_text(\"claude/session_with_cache.jsonl\");\n        let parser = ClaudeSessionParser::new();\n        \n        let usage = parser.parse_str(\u0026log_content).unwrap();\n        \n        assert!(usage.cache_read_tokens \u003e 0);\n    }\n    \n    #[test]\n    fn test_parse_multi_model_session() {\n        // Session that used both Sonnet and Opus\n        let log_content = load_fixture_text(\"claude/session_multi_model.jsonl\");\n        let parser = ClaudeSessionParser::new();\n        \n        let usage = parser.parse_str(\u0026log_content).unwrap();\n        \n        assert!(usage.models_used.len() \u003e= 2);\n    }\n    \n    #[test]\n    fn test_parse_malformed_log_graceful() {\n        let log_content = \"not json\\n{\\\"partial\\\": true\\nmore garbage\";\n        let parser = ClaudeSessionParser::new();\n        \n        // Should parse what it can, skip bad lines\n        let usage = parser.parse_str(log_content).unwrap();\n        // May have zero tokens, but shouldn't error\n        assert!(usage.message_count \u003e= 0);\n    }\n    \n    #[test]\n    fn test_parse_empty_session() {\n        let parser = ClaudeSessionParser::new();\n        let usage = parser.parse_str(\"\").unwrap();\n        \n        assert_eq!(usage.input_tokens, 0);\n        assert_eq!(usage.output_tokens, 0);\n    }\n}\n```\n\n### 3. Unit Tests: Cost Calculation\n```rust\n#[cfg(test)]\nmod cost_tests {\n    #[test]\n    fn test_cost_calculation_opus() {\n        let calculator = SessionCostCalculator::default();\n        let usage = SessionUsage {\n            input_tokens: 1_000_000,\n            output_tokens: 100_000,\n            models_used: hashset![\"claude-3-opus\"],\n            ..Default::default()\n        };\n        \n        let cost = calculator.calculate(\u0026usage);\n        \n        // Opus: $15/M input, $75/M output (example rates)\n        // Actual: $15 + $7.50 = $22.50\n        assert!((cost.total_usd - 22.5).abs() \u003c 0.01);\n        assert_eq!(cost.confidence, CostConfidence::High);\n    }\n    \n    #[test]\n    fn test_cost_calculation_with_cache() {\n        let calculator = SessionCostCalculator::default();\n        let usage = SessionUsage {\n            input_tokens: 500_000,\n            output_tokens: 100_000,\n            cache_read_tokens: 1_000_000,  // Cached prompts\n            models_used: hashset![\"claude-3-sonnet\"],\n            ..Default::default()\n        };\n        \n        let cost = calculator.calculate(\u0026usage);\n        \n        // Cache read tokens should be cheaper\n        assert!(cost.cache_cost_usd \u003c cost.input_cost_usd);\n    }\n    \n    #[test]\n    fn test_unknown_model_low_confidence() {\n        let calculator = SessionCostCalculator::default();\n        let usage = SessionUsage {\n            input_tokens: 100_000,\n            output_tokens: 50_000,\n            models_used: hashset![\"claude-4-ultra\"],  // Unknown future model\n            ..Default::default()\n        };\n        \n        let cost = calculator.calculate(\u0026usage);\n        \n        assert_eq!(cost.confidence, CostConfidence::Low);\n    }\n    \n    #[test]\n    fn test_multi_model_cost() {\n        // Session using both cheap and expensive models\n        let calculator = SessionCostCalculator::default();\n        let usage = SessionUsage {\n            input_tokens: 500_000,\n            output_tokens: 100_000,\n            models_used: hashset![\"claude-3-opus\", \"claude-3-haiku\"],\n            ..Default::default()\n        };\n        \n        let cost = calculator.calculate(\u0026usage);\n        \n        // Should use most expensive model for conservative estimate\n        assert_eq!(cost.confidence, CostConfidence::Medium);\n    }\n}\n```\n\n### 4. Integration Tests\n```rust\n#[test]\nfn test_full_session_cost_workflow() {\n    let tmp = TempDir::new().unwrap();\n    \n    // Create realistic session log\n    let session_dir = tmp.path().join(\".claude/projects/test/conversations\");\n    fs::create_dir_all(\u0026session_dir).unwrap();\n    fs::write(\n        session_dir.join(\"session.jsonl\"),\n        load_fixture_text(\"claude/session_realistic.jsonl\")\n    ).unwrap();\n    \n    // Run session command\n    let output = Command::new(\"caut\")\n        .args([\"session\", \"today\", \"--format\", \"json\"])\n        .env(\"HOME\", tmp.path())\n        .output()\n        .unwrap();\n    \n    let result: SessionOutput = serde_json::from_slice(\u0026output.stdout).unwrap();\n    \n    assert!(!result.sessions.is_empty());\n    assert!(result.total_cost \u003e 0.0);\n}\n```\n\n### 5. E2E Tests\n```bash\n#!/bin/bash\n# tests/e2e/session_e2e.sh\n\nset -euo pipefail\nsource \"$(dirname \"$0\")/helpers.sh\"\n\nlog_section \"Session Cost E2E Tests\"\n\nTEMP_DIR=$(mktemp -d)\nexport HOME=\"$TEMP_DIR\"\ntrap \"rm -rf $TEMP_DIR\" EXIT\n\n# Setup: Create mock session logs\nsetup_mock_sessions() {\n    mkdir -p \"$TEMP_DIR/.claude/projects/test-project/conversations\"\n    cp \"$(fixture_path claude/session_basic.jsonl)\" \\\n       \"$TEMP_DIR/.claude/projects/test-project/conversations/session1.jsonl\"\n}\n\nsetup_mock_sessions\n\n# Test 1: Session discovery\nlog_test \"Session discovery finds logs\"\nOUTPUT=$(caut session list --format json 2\u003e\u00261)\necho \"$OUTPUT\" | jq -e '.sessions | length \u003e 0' || fail \"No sessions found\"\nlog_pass\n\n# Test 2: Cost calculation\nlog_test \"Cost calculation produces values\"\nOUTPUT=$(caut session today --format json 2\u003e\u00261)\nCOST=$(echo \"$OUTPUT\" | jq '.total_cost')\n[[ \"$COST\" != \"null\" \u0026\u0026 \"$COST\" != \"0\" ]] || fail \"Cost is zero or null\"\nlog_pass\n\n# Test 3: Project aggregation\nlog_test \"Project aggregation works\"\nOUTPUT=$(caut session project --format json 2\u003e\u00261)\necho \"$OUTPUT\" | jq -e '.projects | length \u003e 0' || fail \"No projects\"\nlog_pass\n\n# Test 4: Empty state handling\nlog_test \"Empty session list handled\"\nrm -rf \"$TEMP_DIR/.claude\"\nOUTPUT=$(caut session today 2\u003e\u00261)\n# Should not error\necho \"$OUTPUT\" | grep -qi \"no sessions\\|empty\" \u0026\u0026 log_pass || log_pass \"Empty handled gracefully\"\n\nlog_summary\n```\n\n### 6. Test Fixtures Needed\nCreate these fixture files:\n- `tests/fixtures/claude/session_basic.jsonl` - Simple session with token counts\n- `tests/fixtures/claude/session_with_cache.jsonl` - Session using prompt caching\n- `tests/fixtures/claude/session_multi_model.jsonl` - Session switching models\n- `tests/fixtures/claude/session_realistic.jsonl` - Full realistic session\n- `tests/fixtures/codex/session_basic.jsonl` - Codex session format\n\n## Acceptance Criteria\n- [ ] Session log discovery works for all providers\n- [ ] Parsing handles malformed logs gracefully\n- [ ] Cost calculations accurate to within 1%\n- [ ] Multi-model sessions handled correctly\n- [ ] E2E tests pass\n- [ ] Logging verified\n\n## Dependencies\n- Requires logging infrastructure\n- Requires session implementation tasks\n","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:49:55.15694402-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:49:55.15694402-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-qdt","depends_on_id":"coding_agent_usage_tracker-zev","type":"blocks","created_at":"2026-01-18T14:57:00.013633549-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-qdt","depends_on_id":"coding_agent_usage_tracker-7zh","type":"blocks","created_at":"2026-01-18T14:57:00.063155114-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-r8q","title":"Offline: Implement enhanced cache layer with TTL and staleness","description":"Extend src/storage/cache.rs with CacheEntry\u003cT\u003e struct storing data, cached_at, expires_at, stale_at, source (Network/Cache/Fallback). Add FreshnessStatus enum (Fresh/Stale/Expired). Create CacheLayer class with set(), set_with_staleness(), get(), get_with_metadata(). Use MD5 hash for cache keys. Handle corrupted cache gracefully. Default TTL 1hr, stale threshold 5min.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:15:20.986135227-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:15:20.986135227-05:00"}
{"id":"coding_agent_usage_tracker-rl8","title":"Errors: Enhanced error rendering with suggestions","description":"## Overview\nImplement rich error rendering that displays fix suggestions in a clear, actionable format for both terminal and JSON output.\n\n## Background \u0026 Rationale\nHaving suggestions is only useful if users can easily see and use them. The rendering needs to be:\n- Clear and scannable for humans\n- Copy-paste friendly for commands\n- Machine-parseable for AI agents\n\n## Technical Approach\n\n### 1. Terminal Error Display\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Error: Authentication expired for Claude                 [CAUT-A001]\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ                                                                 ‚îÇ\n‚îÇ üí° How to fix:                                                  ‚îÇ\n‚îÇ    1. Run: caut auth refresh claude                            ‚îÇ\n‚îÇ    2. If that fails: caut auth login claude                    ‚îÇ\n‚îÇ                                                                 ‚îÇ\n‚îÇ ‚ÑπÔ∏è Why this happened:                                          ‚îÇ\n‚îÇ    Your OAuth token for Claude has expired. Tokens are         ‚îÇ\n‚îÇ    typically valid for 24 hours. The token may have been       ‚îÇ\n‚îÇ    revoked if you logged out elsewhere.                        ‚îÇ\n‚îÇ                                                                 ‚îÇ\n‚îÇ üìñ Prevention:                                                  ‚îÇ\n‚îÇ    Use `caut usage --watch` to monitor session health and      ‚îÇ\n‚îÇ    get alerts before tokens expire.                            ‚îÇ\n‚îÇ                                                                 ‚îÇ\n‚îÇ üîó Docs: https://github.com/.../docs/auth.md                   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n### 2. Error Rendering Code\n```rust\n// In render/error.rs\nuse crate::error::{CautError, FixSuggestion};\nuse rich_rust::prelude::*;\n\npub fn render_error(error: \u0026CautError, no_color: bool) -\u003e String {\n    let suggestions = error.fix_suggestions();\n    \n    let mut content_lines: Vec\u003cVec\u003cSegment\u003e\u003e = Vec::new();\n    \n    // Error message with code\n    let header = format\\!(\"Error: {} [{}]\", error, error.error_code());\n    content_lines.push(vec\\![Segment::styled(\n        header,\n        Style::new().bold().color(Color::parse(\"red\").unwrap()),\n    )]);\n    \n    // Fix suggestions\n    if \\!suggestions.is_empty() {\n        content_lines.push(vec\\![Segment::plain(\"\")]);\n        content_lines.push(vec\\![Segment::styled(\n            \"üí° How to fix:\",\n            Style::new().bold(),\n        )]);\n        \n        for (i, suggestion) in suggestions.iter().enumerate() {\n            for (j, cmd) in suggestion.commands.iter().enumerate() {\n                let prefix = if j == 0 {\n                    format\\!(\"   {}. Run: \", i + 1)\n                } else {\n                    \"      Or: \".to_string()\n                };\n                content_lines.push(vec\\![\n                    Segment::plain(prefix),\n                    Segment::styled(\n                        cmd.clone(),\n                        Style::new().color(Color::parse(\"cyan\").unwrap()),\n                    ),\n                ]);\n            }\n        }\n    }\n    \n    // Context\n    if let Some(suggestion) = suggestions.first() {\n        content_lines.push(vec\\![Segment::plain(\"\")]);\n        content_lines.push(vec\\![Segment::styled(\n            \"‚ÑπÔ∏è Why this happened:\",\n            Style::new().bold(),\n        )]);\n        for line in textwrap::wrap(\u0026suggestion.context, 60) {\n            content_lines.push(vec\\![Segment::plain(format\\!(\"   {}\", line))]);\n        }\n    }\n    \n    // Prevention\n    if let Some(prevention) = suggestions.first().and_then(|s| s.prevention.as_ref()) {\n        content_lines.push(vec\\![Segment::plain(\"\")]);\n        content_lines.push(vec\\![Segment::styled(\n            \"üìñ Prevention:\",\n            Style::new().bold(),\n        )]);\n        for line in textwrap::wrap(prevention, 60) {\n            content_lines.push(vec\\![Segment::plain(format\\!(\"   {}\", line))]);\n        }\n    }\n    \n    // Doc link\n    if let Some(url) = suggestions.first().and_then(|s| s.doc_url.as_ref()) {\n        content_lines.push(vec\\![Segment::plain(\"\")]);\n        content_lines.push(vec\\![\n            Segment::styled(\"üîó Docs: \", Style::new().bold()),\n            Segment::styled(url.clone(), Style::new().underline()),\n        ]);\n    }\n    \n    // Build panel\n    let panel = Panel::new(content_lines)\n        .border_style(Style::new().color(Color::parse(\"red\").unwrap()))\n        .padding((1, 2));\n    \n    let segments = panel.render(70);\n    segments_to_string(\u0026segments, no_color)\n}\n```\n\n### 3. Simple Mode (--quiet or non-TTY)\n```rust\npub fn render_error_simple(error: \u0026CautError) -\u003e String {\n    let suggestions = error.fix_suggestions();\n    let mut output = format\\!(\"Error [{}]: {}\\n\", error.error_code(), error);\n    \n    if let Some(suggestion) = suggestions.first() {\n        if let Some(cmd) = suggestion.commands.first() {\n            output.push_str(\u0026format\\!(\"Fix: {}\\n\", cmd));\n        }\n    }\n    \n    output\n}\n```\n\n### 4. Integration with Main Error Handler\n```rust\n// In main.rs\nmatch result {\n    Ok(()) =\u003e ExitCode::SUCCESS,\n    Err(e) =\u003e {\n        // Use rich rendering if TTY, simple otherwise\n        let output = if atty::is(atty::Stream::Stderr) \u0026\u0026 \\!cli.no_color {\n            render::error::render_error(\u0026e, cli.no_color)\n        } else {\n            render::error::render_error_simple(\u0026e)\n        };\n        \n        eprintln\\!(\"{}\", output);\n        ExitCode::from(e.exit_code() as u8)\n    }\n}\n```\n\n## Files to Create/Modify\n- `src/render/error.rs`: New file for error rendering\n- `src/render/mod.rs`: Export error module\n- `src/main.rs`: Use rich error rendering\n- `Cargo.toml`: Add textwrap dependency if needed\n\n## Dependencies\n- Requires error taxonomy (v53) to be complete\n- Requires fix suggestions (1mj) to be complete\n\n## Acceptance Criteria\n- [ ] Errors render with full suggestions in TTY\n- [ ] Errors render simply in non-TTY/quiet mode\n- [ ] Commands are easy to copy\n- [ ] No color mode works correctly\n- [ ] Error code displayed for reference\n\n## Testing Strategy\n- Test rendering for each error category\n- Test TTY vs non-TTY output\n- Test no-color mode\n- Visual review of output formatting","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T03:02:29.942006564-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T03:02:29.942006564-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-rl8","depends_on_id":"coding_agent_usage_tracker-v53","type":"blocks","created_at":"2026-01-18T03:03:20.260292153-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-rl8","depends_on_id":"coding_agent_usage_tracker-1mj","type":"blocks","created_at":"2026-01-18T03:03:20.322548499-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-s46","title":"API: Implement Axum HTTP server setup","description":"Create src/api/mod.rs with Axum router setup. ServerConfig with port (default 8420), bind_addr (default 127.0.0.1), cache_ttl_secs, enable_cors, warn_non_localhost. AppState with config, cache, last_fetch. Register routes: /health, /usage, /usage/:provider, /history, /history/:provider, /budgets, /stream. Graceful shutdown on Ctrl+C and SIGTERM. Startup message shows endpoints.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:15:44.63898061-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:15:44.63898061-05:00"}
{"id":"coding_agent_usage_tracker-slz","title":"Config: CLI and environment variable precedence","description":"## Overview\nImplement the precedence system where CLI flags override environment variables override config file settings.\n\n## Background \u0026 Rationale\nUsers need predictable ways to override settings:\n- CI/CD systems often use environment variables\n- One-off commands use CLI flags\n- Persistent preferences live in config file\n\nThe precedence must be clear and consistent.\n\n## Technical Approach\n\n### 1. Layered Config Resolution\n```rust\n// In core/config.rs\npub struct ResolvedConfig {\n    pub providers: Vec\u003cProvider\u003e,\n    pub format: OutputFormat,\n    pub timeout: Duration,\n    pub no_color: bool,\n    pub verbose: bool,\n    pub pretty: bool,\n}\n\nimpl ResolvedConfig {\n    /// Resolve final config from CLI args, env vars, and config file.\n    pub fn resolve(cli: \u0026Cli) -\u003e Result\u003cSelf\u003e {\n        let config = Config::load()?;\n        config.validate()?;\n        \n        Ok(Self {\n            providers: Self::resolve_providers(cli, \u0026config)?,\n            format: Self::resolve_format(cli, \u0026config)?,\n            timeout: Self::resolve_timeout(cli, \u0026config),\n            no_color: Self::resolve_no_color(cli, \u0026config),\n            verbose: Self::resolve_verbose(cli, \u0026config),\n            pretty: Self::resolve_pretty(cli, \u0026config),\n        })\n    }\n}\n```\n\n### 2. Per-Setting Resolution Pattern\n```rust\nfn resolve_format(cli: \u0026Cli, config: \u0026Config) -\u003e Result\u003cOutputFormat\u003e {\n    // 1. CLI flag (highest priority)\n    if let Some(format) = \u0026cli.format {\n        return OutputFormat::from_str(format);\n    }\n    \n    // 2. Environment variable\n    if let Ok(format) = env::var(\"CAUT_FORMAT\") {\n        return OutputFormat::from_str(\u0026format);\n    }\n    \n    // 3. Config file\n    if let Some(format) = \u0026config.defaults.format {\n        return OutputFormat::from_str(format);\n    }\n    \n    // 4. Built-in default\n    Ok(OutputFormat::Human)\n}\n\nfn resolve_providers(cli: \u0026Cli, config: \u0026Config) -\u003e Result\u003cVec\u003cProvider\u003e\u003e {\n    // CLI --provider flag\n    if \\!cli.providers.is_empty() {\n        return cli.providers.iter()\n            .map(|s| Provider::from_cli_name(s))\n            .collect();\n    }\n    \n    // CAUT_PROVIDERS env var (comma-separated)\n    if let Ok(providers) = env::var(\"CAUT_PROVIDERS\") {\n        return providers.split(,)\n            .map(|s| Provider::from_cli_name(s.trim()))\n            .collect();\n    }\n    \n    // Config file\n    if let Some(providers) = \u0026config.defaults.providers {\n        return providers.iter()\n            .map(|s| Provider::from_cli_name(s))\n            .collect();\n    }\n    \n    // Default: primary providers\n    Ok(Provider::primary_providers().to_vec())\n}\n```\n\n### 3. Environment Variables\nDocument and support these env vars:\n- `CAUT_PROVIDERS`: Comma-separated provider list\n- `CAUT_FORMAT`: Output format (human, json, md)\n- `CAUT_TIMEOUT`: Default timeout in seconds\n- `CAUT_NO_COLOR`: Disable colors (1, true, yes)\n- `CAUT_VERBOSE`: Enable verbose output\n- `CAUT_CONFIG`: Override config file path\n\n### 4. Integration with CLI\n```rust\n// In cli/args.rs - add this to Cli struct\nimpl Cli {\n    /// Get resolved configuration merging CLI, env, and config file.\n    pub fn resolved_config(\u0026self) -\u003e Result\u003cResolvedConfig\u003e {\n        ResolvedConfig::resolve(self)\n    }\n}\n\n// In main.rs or cli commands\nasync fn run(cli: Cli) -\u003e Result\u003c()\u003e {\n    let config = cli.resolved_config()?;\n    // Use config.format, config.providers, etc.\n}\n```\n\n## Files to Modify\n- `src/core/config.rs`: Add ResolvedConfig and resolution logic\n- `src/cli/args.rs`: Add resolved_config() method\n- `src/cli/usage.rs`: Use resolved config\n- `src/cli/cost.rs`: Use resolved config\n- `src/main.rs`: Wire up config resolution\n\n## Dependencies\n- Requires core config loading (1n2) to be complete\n\n## Acceptance Criteria\n- [ ] CLI flags override all other sources\n- [ ] Env vars override config file\n- [ ] Config file overrides built-in defaults\n- [ ] All documented env vars work\n- [ ] Precedence is testable and verified\n- [ ] Error messages indicate source of bad value\n\n## Testing Strategy\n- Test each setting with all 4 sources\n- Test mixed sources (CLI for one, env for another)\n- Test CAUT_CONFIG override\n- Verify error messages include source context","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:56:22.843887768-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T12:39:14.046947516-05:00","closed_at":"2026-01-18T12:39:14.046947516-05:00","close_reason":"Implemented config precedence system (CLI \u003e Env \u003e Config \u003e Default). Added ResolvedConfig struct with ConfigSources tracking, per-setting resolution functions for providers/format/timeout/no_color/verbose/pretty/include_status, and 28 comprehensive tests including env var tests with safe helpers for Rust 2024. Changed unsafe_code lint from forbid to deny to allow test helpers.","dependencies":[{"issue_id":"coding_agent_usage_tracker-slz","depends_on_id":"coding_agent_usage_tracker-1n2","type":"blocks","created_at":"2026-01-18T02:57:28.094849429-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-smm","title":"Status: Integrate status display into usage output","description":"Modify src/render/human.rs to show provider status alongside usage. Add format_provider_header() with status badge, format_status_badge() with color-coded symbols (‚úì=OK, ‚ö†=DEGRADED, ‚úï=OUTAGE, üîß=MAINTENANCE). Show status details and link when degraded. Support --no-color. Include status field in JSON output.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:15:03.478108334-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:15:03.478108334-05:00"}
{"id":"coding_agent_usage_tracker-smt","title":"Prediction: Implement usage velocity calculation from history","description":"## Task Overview\n\nImplement the core velocity calculation that measures how quickly usage is increasing or decreasing over a recent time window. This is the foundation for time-to-limit prediction.\n\n## Parent EPIC\n[EPIC] Time-to-Limit Prediction (coding_agent_usage_tracker-swp)\n\n## Technical Requirements\n\n### Velocity Definition\n\nVelocity = rate of change in usage percentage per unit time\n\n```\nvelocity = Œî usage_percent / Œî time\n         = (current_pct - earlier_pct) / hours_elapsed\n         \nExample: 65% now, 45% two hours ago\nvelocity = (65 - 45) / 2 = 10% per hour\n```\n\n### Implementation\n\n```rust\n// src/core/prediction.rs\n\n/// Calculate usage velocity over a time window\n/// Returns percentage points per hour (can be negative for decreasing usage)\npub fn calculate_velocity(\n    history: \u0026[StoredSnapshot],\n    window: Duration,\n) -\u003e Option\u003cf64\u003e {\n    if history.len() \u003c 2 {\n        return None;  // Need at least 2 points\n    }\n    \n    let now = Utc::now();\n    let window_start = now - window;\n    \n    // Filter to snapshots within window\n    let recent: Vec\u003c_\u003e = history.iter()\n        .filter(|s| s.fetched_at \u003e= window_start)\n        .collect();\n    \n    if recent.len() \u003c 2 {\n        return None;\n    }\n    \n    // Use linear regression for more stable velocity\n    let velocity = linear_regression_slope(\u0026recent)?;\n    \n    // Convert to per-hour rate\n    Some(velocity * 3600.0)  // seconds to hours\n}\n\n/// Simple linear regression to get slope\nfn linear_regression_slope(points: \u0026[\u0026StoredSnapshot]) -\u003e Option\u003cf64\u003e {\n    let n = points.len() as f64;\n    if n \u003c 2.0 {\n        return None;\n    }\n    \n    let base_time = points[0].fetched_at.timestamp() as f64;\n    \n    let mut sum_x = 0.0;   // time offset in seconds\n    let mut sum_y = 0.0;   // usage percent\n    let mut sum_xy = 0.0;\n    let mut sum_xx = 0.0;\n    \n    for p in points {\n        let x = (p.fetched_at.timestamp() as f64) - base_time;\n        let y = p.primary_used_pct?;\n        \n        sum_x += x;\n        sum_y += y;\n        sum_xy += x * y;\n        sum_xx += x * x;\n    }\n    \n    let denominator = n * sum_xx - sum_x * sum_x;\n    if denominator.abs() \u003c f64::EPSILON {\n        return None;  // Vertical line or insufficient variation\n    }\n    \n    let slope = (n * sum_xy - sum_x * sum_y) / denominator;\n    Some(slope)\n}\n```\n\n### Smoothing and Noise Handling\n\nUsage data can be noisy. Apply smoothing:\n\n```rust\n/// Exponential moving average for smoothed velocity\npub fn smoothed_velocity(\n    history: \u0026[StoredSnapshot],\n    window: Duration,\n    alpha: f64,  // smoothing factor 0-1, higher = more recent weight\n) -\u003e Option\u003cf64\u003e {\n    let raw_velocities = calculate_interval_velocities(history, window)?;\n    \n    if raw_velocities.is_empty() {\n        return None;\n    }\n    \n    let mut ema = raw_velocities[0];\n    for v in \u0026raw_velocities[1..] {\n        ema = alpha * v + (1.0 - alpha) * ema;\n    }\n    \n    Some(ema)\n}\n```\n\n### Edge Cases\n\n1. **Insufficient data**: Return None, display \"insufficient data\"\n2. **Zero/negative velocity**: Usage stable or decreasing - \"sustainable\"\n3. **Very high velocity**: May indicate unusual activity - flag it\n4. **Reset events**: Detect when usage resets to 0, exclude from calculation\n\n```rust\npub fn detect_reset(prev: \u0026StoredSnapshot, curr: \u0026StoredSnapshot) -\u003e bool {\n    // Usage dropped significantly and curr has small value\n    let prev_pct = prev.primary_used_pct.unwrap_or(0.0);\n    let curr_pct = curr.primary_used_pct.unwrap_or(0.0);\n    \n    prev_pct \u003e 50.0 \u0026\u0026 curr_pct \u003c 10.0 \u0026\u0026 prev_pct - curr_pct \u003e 40.0\n}\n```\n\n## Deliverables\n\n- [ ] `calculate_velocity()` function\n- [ ] Linear regression implementation\n- [ ] Smoothing/EMA for noise reduction\n- [ ] Reset detection logic\n- [ ] Edge case handling\n- [ ] Comprehensive unit tests\n\n## Acceptance Criteria\n\n- [ ] Velocity accurate for known test data\n- [ ] Handles insufficient data gracefully\n- [ ] Resets don't corrupt velocity calculation\n- [ ] Smoothing reduces noise without excessive lag\n- [ ] Performance: \u003c1ms for typical history size","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:09:30.601390808-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:09:30.601390808-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-smt","depends_on_id":"coding_agent_usage_tracker-hws","type":"blocks","created_at":"2026-01-18T14:21:45.19836325-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-smv","title":"[EPIC] Historical Usage Tracking with Trend Visualization","description":"## Overview\n\nHistorical Usage Tracking is the **FOUNDATIONAL** feature that transforms caut from a \"point-in-time meter\" into a comprehensive \"usage analytics platform.\" This is the single most important feature to build next.\n\n## Strategic Importance (Why P0)\n\nThis epic is Priority 0 because it **unlocks multiple downstream features**:\n- **Time-to-Limit Prediction** requires velocity data calculated from history\n- **Usage Budgets** need historical spend to calculate budget consumption  \n- **TUI Dashboard** needs history for sparkline trend visualizations\n- **Session Attribution** benefits from historical correlation data\n\nWithout history, caut is permanently limited to answering \"what is my usage RIGHT NOW?\" With history, it can answer:\n- \"How has my usage changed over time?\"\n- \"What's my average daily/weekly/monthly consumption?\"\n- \"When do I typically hit rate limits?\"\n- \"Am I trending up or down?\"\n- \"What patterns exist in my usage?\"\n\n## User Value Proposition\n\n**Current state**: User runs `caut usage`, sees \"65% used\", has zero context about whether that's normal, trending up, or concerning.\n\n**Target state**: User runs `caut history --days 7` and sees:\n```\nClaude Usage (Last 7 Days)\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nMon: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 78%\nTue: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 62%  \nWed: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 91% ‚Üê Hit limit\nThu: ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 41%\nFri: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 65%\nSat: ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 23%\nSun: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 52%\n\nAverage: 59%  Trend: ‚Üò -8% vs previous week\nPeak day: Wednesday (consider spreading heavy work)\n```\n\n## Technical Approach\n\n1. **Storage**: Extend existing SQLite infrastructure (storage/ module) with `usage_snapshots` table\n2. **Capture**: Hook into fetch pipeline to automatically save snapshot on every successful fetch\n3. **Query**: Time-range queries with proper indexes for performance\n4. **Display**: ASCII visualization using existing rich_rust dependency\n5. **Export**: JSON/CSV output for external analysis tools\n\n## Architecture Decisions\n\n- **Why SQLite?** Already using it for state/cache. No new dependencies. Handles time-series well.\n- **Why automatic capture?** Users shouldn't have to remember to log. Every fetch = data point.\n- **Why ASCII viz?** Stays in terminal, no external deps, works over SSH, matches CLI philosophy.\n\n## Success Criteria\n\n- [ ] Every `caut usage` call automatically records a snapshot (zero user effort)\n- [ ] `caut history` command shows usage over configurable time periods\n- [ ] Trend calculation shows direction and magnitude of change\n- [ ] ASCII visualization clearly shows patterns at a glance\n- [ ] Export to JSON/CSV works for external analysis\n- [ ] Performance: history queries \u003c 100ms for 30 days of data (thousands of rows)\n- [ ] Storage: efficient schema with proper indexes, auto-cleanup of old data\n\n## Risks and Mitigations\n\n- **Risk**: Database growth over time ‚Üí **Mitigation**: Configurable retention, auto-pruning\n- **Risk**: Slow queries on large datasets ‚Üí **Mitigation**: Proper indexes, query optimization\n- **Risk**: Schema changes break existing data ‚Üí **Mitigation**: Versioned migrations\n\n## Dependencies\n\nThis EPIC has no dependencies - it is foundational. Many other EPICs depend on this one.","status":"open","priority":0,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:10:04.631391225-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:10:04.631391225-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-smv","depends_on_id":"coding_agent_usage_tracker-525","type":"blocks","created_at":"2026-01-18T15:16:45.289048835-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-swp","title":"[EPIC] Time-to-Limit Prediction","description":"## Overview\n\nTime-to-Limit Prediction transforms raw usage percentages into **actionable intelligence**. Instead of showing \"65% used,\" show \"65% used ‚Ä¢ ~1h 45m until limit at current pace.\"\n\n## Strategic Importance (Why P1)\n\nThis is the simplest high-value feature possible with excellent ROI:\n- **Low complexity**: Simple math once history exists\n- **High immediate value**: Users can plan their work around concrete timeframes  \n- **Differentiating**: Few tools translate percentages into time\n\n## User Value Proposition\n\n**Current state**: \"Claude: 65% used (resets in 2h 30m)\" - User has to do mental math.\n\n**Target state**:\n```\nClaude: 65% used\n        ‚îú‚îÄ Resets in: 2h 30m\n        ‚îî‚îÄ At current pace: ~1h 45m until limit ‚ö†Ô∏è\n```\n\nUser immediately knows: \"I'm going to hit my limit before it resets. I should slow down or switch providers.\"\n\n## Technical Approach\n\n1. **Velocity Calculation**: Track `Œî usage / Œî time` over recent window (e.g., last hour)\n2. **Prediction Math**: `remaining_capacity / velocity = time_to_limit`\n3. **Comparison**: If `time_to_limit \u003c reset_time`, show warning\n4. **Edge Cases**: Handle low/zero velocity (sustainable), insufficient history (show nothing)\n\n```rust\nfn predict_time_to_limit(current: f64, velocity: f64, reset_minutes: i32) -\u003e Prediction {\n    if velocity \u003c= 0.0 {\n        return Prediction::Sustainable; // Usage going down or stable\n    }\n    let remaining = 100.0 - current;\n    let minutes_to_limit = (remaining / velocity) as i32;\n    \n    if minutes_to_limit \u003e reset_minutes {\n        Prediction::Sustainable // Will reset before hitting limit\n    } else {\n        Prediction::WillHitLimit { minutes: minutes_to_limit }\n    }\n}\n```\n\n## Display Integration\n\n- Integrate directly into `caut usage` output\n- Warning indicators when limit will be hit before reset\n- Color coding: green (sustainable), yellow (close), red (will hit)\n- Works in both human and robot output modes\n\n## Success Criteria\n\n- [ ] Velocity calculated from recent history (configurable window)\n- [ ] Time-to-limit shown alongside usage percentage\n- [ ] Clear warning when limit will be hit before reset\n- [ ] Graceful handling of edge cases (no history, zero velocity, etc.)\n- [ ] JSON output includes prediction data for automation\n\n## Dependencies\n\n- **REQUIRES**: Historical Usage Tracking (EPIC 1) - needs history for velocity calculation\n- Minimum viable: needs at least 2 data points to calculate velocity\n- Better accuracy: 10+ data points over an hour\n\n## Considerations\n\n- Velocity is inherently noisy - consider smoothing (moving average)\n- Different providers may have different usage patterns\n- Weekend vs weekday patterns may differ significantly\n- Consider showing confidence level based on data quantity","status":"open","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:11:08.989548041-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:11:08.989548041-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-swp","depends_on_id":"coding_agent_usage_tracker-smv","type":"blocks","created_at":"2026-01-18T14:21:34.289222086-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-sww","title":"Unit tests for core/fetch_plan.rs (plan generation)","description":"## Overview\nTest the fetch plan generation logic that determines what to fetch.\n\n## Target: src/core/fetch_plan.rs (5.8KB)\nCritical for: Efficient data fetching\n\n## Test Cases\n\n### 1. Plan Generation\n- Single provider plan\n- Multi-provider plan\n- Provider filtering applied correctly\n- Empty provider list handling\n\n### 2. Fetch Strategy\n- Parallel vs sequential fetching\n- Priority ordering\n- Dependency resolution (if any)\n\n### 3. Configuration Integration\n- Respects config settings\n- Timeout settings applied\n- Cache policy applied\n\n### 4. Plan Optimization\n- Deduplication of sources\n- Rate limit awareness\n- Cache hit optimization\n\n## Test Data\n- Various provider configurations\n- Different CLI flag combinations\n- Edge cases (no providers enabled, all providers)\n\n## Acceptance Criteria\n- [ ] get_fetch_plan() tested for all providers\n- [ ] Provider filtering verified\n- [ ] Plan optimization verified\n- [ ] Edge cases handled","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:51:30.532830359-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:51:30.532830359-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-sww","depends_on_id":"coding_agent_usage_tracker-u5h","type":"blocks","created_at":"2026-01-18T02:53:18.99083564-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-t1u","title":"TUI: Test suite for rendering, navigation, and accessibility","description":"## Summary\nImplement comprehensive test suite for TUI Dashboard including component rendering, keyboard navigation, live updates, and accessibility.\n\n## Parent EPIC\n[EPIC] TUI Dashboard (coding_agent_usage_tracker-36t)\n\n## Test Categories\n\n### 1. Unit Tests: Component Rendering\n```rust\n#[cfg(test)]\nmod rendering_tests {\n    use crate::tui::components::*;\n    use ratatui::backend::TestBackend;\n    use ratatui::Terminal;\n\n    #[test]\n    fn test_usage_gauge_rendering() {\n        let backend = TestBackend::new(80, 24);\n        let mut terminal = Terminal::new(backend).unwrap();\n\n        let gauge = UsageGauge::new(\"Claude\", 75.0, GaugeStyle::default());\n\n        terminal.draw(|f| {\n            gauge.render(f, f.size());\n        }).unwrap();\n\n        let buffer = terminal.backend().buffer();\n        assert!(buffer_contains_text(buffer, \"Claude\"));\n        assert!(buffer_contains_text(buffer, \"75%\"));\n    }\n\n    #[test]\n    fn test_sparkline_rendering() {\n        let backend = TestBackend::new(80, 24);\n        let mut terminal = Terminal::new(backend).unwrap();\n\n        let data = vec![10.0, 25.0, 50.0, 75.0, 60.0, 80.0];\n        let sparkline = UsageSparkline::new(\u0026data);\n\n        terminal.draw(|f| {\n            sparkline.render(f, f.size());\n        }).unwrap();\n\n        // Sparkline should render without panic\n        assert!(terminal.backend().buffer().area.height \u003e 0);\n    }\n\n    #[test]\n    fn test_provider_card_rendering() {\n        let backend = TestBackend::new(80, 24);\n        let mut terminal = Terminal::new(backend).unwrap();\n\n        let payload = mock_provider_payload(\"claude\", 45.0);\n        let card = ProviderCard::new(\u0026payload);\n\n        terminal.draw(|f| {\n            card.render(f, f.size());\n        }).unwrap();\n\n        let buffer = terminal.backend().buffer();\n        assert!(buffer_contains_text(buffer, \"claude\"));\n        assert!(buffer_contains_text(buffer, \"45\"));\n    }\n\n    #[test]\n    fn test_status_indicator_colors() {\n        let backend = TestBackend::new(80, 24);\n        let mut terminal = Terminal::new(backend).unwrap();\n\n        // Test each status indicator renders with correct styling\n        for indicator in [StatusIndicator::None, StatusIndicator::Minor,\n                          StatusIndicator::Major, StatusIndicator::Critical] {\n            let status = StatusWidget::new(indicator);\n            terminal.draw(|f| {\n                status.render(f, f.size());\n            }).unwrap();\n            // Should not panic\n        }\n    }\n\n    #[test]\n    fn test_empty_state_rendering() {\n        let backend = TestBackend::new(80, 24);\n        let mut terminal = Terminal::new(backend).unwrap();\n\n        let dashboard = Dashboard::new(vec![]); // No providers\n\n        terminal.draw(|f| {\n            dashboard.render(f, f.size());\n        }).unwrap();\n\n        let buffer = terminal.backend().buffer();\n        assert!(buffer_contains_text(buffer, \"No providers\") ||\n                buffer_contains_text(buffer, \"Configure\"));\n    }\n}\n```\n\n### 2. Unit Tests: Layout System\n```rust\n#[cfg(test)]\nmod layout_tests {\n    #[test]\n    fn test_responsive_layout_wide() {\n        let layout = DashboardLayout::calculate(Rect::new(0, 0, 120, 40));\n\n        // Wide terminal: side-by-side providers\n        assert!(layout.columns \u003e= 2);\n    }\n\n    #[test]\n    fn test_responsive_layout_narrow() {\n        let layout = DashboardLayout::calculate(Rect::new(0, 0, 60, 40));\n\n        // Narrow terminal: stacked providers\n        assert_eq!(layout.columns, 1);\n    }\n\n    #[test]\n    fn test_minimum_size_handling() {\n        let layout = DashboardLayout::calculate(Rect::new(0, 0, 20, 10));\n\n        // Should not panic, should show condensed view\n        assert!(layout.condensed);\n    }\n\n    #[test]\n    fn test_provider_area_allocation() {\n        let layout = DashboardLayout::calculate(Rect::new(0, 0, 100, 40));\n        let providers = vec![\"claude\", \"codex\", \"openai\"];\n\n        let areas = layout.allocate_provider_areas(\u0026providers);\n\n        assert_eq!(areas.len(), 3);\n        // Areas should not overlap\n        for (i, a) in areas.iter().enumerate() {\n            for (j, b) in areas.iter().enumerate() {\n                if i != j {\n                    assert!(!a.intersects(*b));\n                }\n            }\n        }\n    }\n}\n```\n\n### 3. Unit Tests: Keyboard Navigation\n```rust\n#[cfg(test)]\nmod navigation_tests {\n    use crossterm::event::{KeyCode, KeyModifiers};\n\n    #[test]\n    fn test_tab_navigation() {\n        let mut app = DashboardApp::new(mock_providers());\n\n        assert_eq!(app.focused_panel(), Panel::Providers);\n\n        app.handle_key(KeyCode::Tab, KeyModifiers::empty());\n        assert_eq!(app.focused_panel(), Panel::History);\n\n        app.handle_key(KeyCode::Tab, KeyModifiers::empty());\n        assert_eq!(app.focused_panel(), Panel::Status);\n\n        app.handle_key(KeyCode::Tab, KeyModifiers::empty());\n        assert_eq!(app.focused_panel(), Panel::Providers); // Wrap around\n    }\n\n    #[test]\n    fn test_arrow_key_selection() {\n        let mut app = DashboardApp::new(mock_providers());\n\n        assert_eq!(app.selected_provider_index(), 0);\n\n        app.handle_key(KeyCode::Down, KeyModifiers::empty());\n        assert_eq!(app.selected_provider_index(), 1);\n\n        app.handle_key(KeyCode::Up, KeyModifiers::empty());\n        assert_eq!(app.selected_provider_index(), 0);\n    }\n\n    #[test]\n    fn test_vim_style_navigation() {\n        let mut app = DashboardApp::new(mock_providers());\n\n        app.handle_key(KeyCode::Char('j'), KeyModifiers::empty());\n        assert_eq!(app.selected_provider_index(), 1);\n\n        app.handle_key(KeyCode::Char('k'), KeyModifiers::empty());\n        assert_eq!(app.selected_provider_index(), 0);\n    }\n\n    #[test]\n    fn test_quit_keys() {\n        let mut app = DashboardApp::new(mock_providers());\n\n        app.handle_key(KeyCode::Char('q'), KeyModifiers::empty());\n        assert!(app.should_quit());\n\n        let mut app = DashboardApp::new(mock_providers());\n        app.handle_key(KeyCode::Char('c'), KeyModifiers::CONTROL);\n        assert!(app.should_quit());\n    }\n\n    #[test]\n    fn test_refresh_key() {\n        let mut app = DashboardApp::new(mock_providers());\n\n        app.handle_key(KeyCode::Char('r'), KeyModifiers::empty());\n        assert!(app.refresh_requested());\n    }\n\n    #[test]\n    fn test_help_toggle() {\n        let mut app = DashboardApp::new(mock_providers());\n\n        assert!(!app.showing_help());\n\n        app.handle_key(KeyCode::Char('?'), KeyModifiers::empty());\n        assert!(app.showing_help());\n\n        app.handle_key(KeyCode::Esc, KeyModifiers::empty());\n        assert!(!app.showing_help());\n    }\n}\n```\n\n### 4. Unit Tests: Live Updates\n```rust\n#[cfg(test)]\nmod update_tests {\n    #[test]\n    fn test_data_update_triggers_redraw() {\n        let mut app = DashboardApp::new(mock_providers());\n\n        let initial_frame = app.frame_count();\n\n        app.update_provider_data(\"claude\", mock_provider_payload(\"claude\", 80.0));\n\n        // Should mark as needing redraw\n        assert!(app.needs_redraw());\n    }\n\n    #[test]\n    fn test_ticker_interval() {\n        let app = DashboardApp::new(mock_providers())\n            .with_refresh_interval(Duration::from_secs(5));\n\n        assert_eq!(app.refresh_interval(), Duration::from_secs(5));\n    }\n\n    #[test]\n    fn test_status_change_animation() {\n        let mut app = DashboardApp::new(mock_providers());\n\n        // Simulate status change\n        let old_status = StatusIndicator::None;\n        let new_status = StatusIndicator::Minor;\n\n        app.update_status(\"claude\", new_status);\n\n        // Should trigger highlight animation\n        assert!(app.has_pending_animations());\n    }\n\n    #[test]\n    fn test_history_sparkline_update() {\n        let mut app = DashboardApp::new(mock_providers());\n\n        let history = vec![\n            usage_snapshot(30.0, None),\n            usage_snapshot(40.0, None),\n            usage_snapshot(50.0, None),\n        ];\n\n        app.update_history(\"claude\", history);\n\n        let sparkline_data = app.get_sparkline_data(\"claude\");\n        assert_eq!(sparkline_data.len(), 3);\n    }\n}\n```\n\n### 5. Integration Tests\n```rust\n#[test]\nfn test_tui_app_lifecycle() {\n    // Test full app initialization and teardown\n    let backend = TestBackend::new(80, 24);\n    let terminal = Terminal::new(backend).unwrap();\n\n    let mut app = DashboardApp::new(mock_providers());\n\n    // Simulate a few frames\n    for _ in 0..10 {\n        terminal.draw(|f| app.render(f)).unwrap();\n        app.tick();\n    }\n\n    // Send quit\n    app.handle_key(KeyCode::Char('q'), KeyModifiers::empty());\n\n    assert!(app.should_quit());\n}\n\n#[test]\nfn test_tui_with_real_data_sources() {\n    let tmp = TempDir::new().unwrap();\n    setup_mock_provider_data(\u0026tmp);\n\n    let backend = TestBackend::new(80, 24);\n    let terminal = Terminal::new(backend).unwrap();\n\n    let data_source = FileDataSource::new(tmp.path());\n    let mut app = DashboardApp::with_data_source(data_source);\n\n    // Load data\n    app.refresh().unwrap();\n\n    // Render should include loaded data\n    terminal.draw(|f| app.render(f)).unwrap();\n\n    let buffer = terminal.backend().buffer();\n    assert!(buffer_contains_text(buffer, \"claude\") || buffer_contains_text(buffer, \"codex\"));\n}\n```\n\n### 6. E2E Tests\n```bash\n#!/bin/bash\n# tests/e2e/tui_e2e.sh\n\nset -euo pipefail\nsource \"$(dirname \"$0\")/helpers.sh\"\n\nlog_section \"TUI Dashboard E2E Tests\"\n\nTEMP_DIR=$(mktemp -d)\nexport HOME=\"$TEMP_DIR\"\ntrap \"rm -rf $TEMP_DIR\" EXIT\n\n# Setup mock data\nsetup_tui_test_data() {\n    mkdir -p \"$TEMP_DIR/.claude\"\n    cat \u003e \"$TEMP_DIR/.claude/credentials.json\" \u003c\u003c 'EOF'\n{\"credentials\":{\"claudeAiOauth\":{\"accessToken\":\"test\",\"expiresAt\":\"2099-12-31T23:59:59Z\"}}}\nEOF\n}\n\nsetup_tui_test_data\n\n# Test 1: TUI starts without error\nlog_test \"TUI starts without error\"\n# Run with timeout and immediate quit\ntimeout 2 caut tui --test-mode 2\u003e\u00261 || [[ $? -eq 124 ]] || fail \"TUI failed to start\"\nlog_pass\n\n# Test 2: TUI respects --no-color flag\nlog_test \"TUI respects --no-color\"\nOUTPUT=$(timeout 1 caut tui --test-mode --no-color 2\u003e\u00261 || true)\n# Should not contain ANSI escape codes (simplified check)\nif echo \"$OUTPUT\" | grep -q $'\\033\\['; then\n    fail \"Found color codes with --no-color\"\nfi\nlog_pass\n\n# Test 3: TUI handles missing data gracefully\nlog_test \"TUI handles missing data\"\nrm -rf \"$TEMP_DIR/.claude\"\ntimeout 1 caut tui --test-mode 2\u003e\u00261 || [[ $? -eq 124 ]] || fail \"TUI crashed with missing data\"\nlog_pass\n\n# Test 4: TUI refresh interval\nlog_test \"TUI accepts refresh interval\"\ntimeout 1 caut tui --test-mode --refresh 10 2\u003e\u00261 || [[ $? -eq 124 ]] || fail \"TUI failed with refresh interval\"\nlog_pass\n\n# Test 5: TUI single-provider mode\nlog_test \"TUI single-provider mode\"\nsetup_tui_test_data\ntimeout 1 caut tui --test-mode --provider claude 2\u003e\u00261 || [[ $? -eq 124 ]] || fail \"TUI failed in single-provider mode\"\nlog_pass\n\nlog_summary\n```\n\n### 7. Accessibility Tests\n```rust\n#[cfg(test)]\nmod accessibility_tests {\n    #[test]\n    fn test_high_contrast_mode() {\n        let mut app = DashboardApp::new(mock_providers())\n            .with_high_contrast(true);\n\n        let backend = TestBackend::new(80, 24);\n        let mut terminal = Terminal::new(backend).unwrap();\n\n        terminal.draw(|f| app.render(f)).unwrap();\n\n        // Verify high contrast colors are used\n        let buffer = terminal.backend().buffer();\n        // Check that we're not using low-contrast color combinations\n        assert!(verify_contrast_ratios(buffer));\n    }\n\n    #[test]\n    fn test_screen_reader_labels() {\n        let app = DashboardApp::new(mock_providers());\n\n        // Each interactive element should have an accessible label\n        for widget in app.interactive_widgets() {\n            assert!(widget.accessible_label().is_some());\n        }\n    }\n\n    #[test]\n    fn test_keyboard_only_operation() {\n        let mut app = DashboardApp::new(mock_providers());\n\n        // Should be able to reach all panels via keyboard\n        let mut visited_panels = std::collections::HashSet::new();\n\n        for _ in 0..10 {\n            visited_panels.insert(app.focused_panel());\n            app.handle_key(KeyCode::Tab, KeyModifiers::empty());\n        }\n\n        assert!(visited_panels.contains(\u0026Panel::Providers));\n        assert!(visited_panels.contains(\u0026Panel::History));\n        assert!(visited_panels.contains(\u0026Panel::Status));\n    }\n}\n```\n\n### 8. Logging Verification\n```rust\n#[cfg(test)]\nmod logging_tests {\n    #[test]\n    fn test_tui_startup_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let _app = DashboardApp::new(mock_providers());\n\n        capture.assert_logged(\"initializing TUI dashboard\");\n    }\n\n    #[test]\n    fn test_data_refresh_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        let mut app = DashboardApp::new(mock_providers());\n        app.refresh().unwrap();\n\n        capture.assert_logged(\"refreshing provider data\");\n    }\n\n    #[test]\n    fn test_render_errors_logged() {\n        let capture = TestLogCapture::new();\n        let _guard = capture.install();\n\n        // Force a render error scenario\n        let backend = TestBackend::new(1, 1); // Too small\n        let mut terminal = Terminal::new(backend).unwrap();\n        let mut app = DashboardApp::new(mock_providers());\n\n        // Should handle gracefully and log\n        let _ = terminal.draw(|f| app.render(f));\n\n        // Either logs warning about size or renders condensed\n        // (depending on implementation)\n    }\n}\n```\n\n## Acceptance Criteria\n- [ ] All components render correctly\n- [ ] Layout adapts to terminal size\n- [ ] Keyboard navigation works (arrows, vim keys, tab)\n- [ ] Live updates trigger redraws\n- [ ] High contrast mode works\n- [ ] E2E tests pass\n- [ ] All operations properly logged\n\n## Dependencies\n- Requires logging infrastructure (coding_agent_usage_tracker-zev)\n- Requires historical data for sparklines (coding_agent_usage_tracker-smv)\n- Requires TUI implementation tasks\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:56:27.745131576-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:56:27.745131576-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-t1u","depends_on_id":"coding_agent_usage_tracker-zev","type":"blocks","created_at":"2026-01-18T14:57:03.251165167-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-t1u","depends_on_id":"coding_agent_usage_tracker-36t","type":"blocks","created_at":"2026-01-18T14:57:03.300058289-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-t1u","depends_on_id":"coding_agent_usage_tracker-smv","type":"blocks","created_at":"2026-01-18T14:57:03.34939655-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-teh","title":"API: Implement SSE streaming for real-time updates","description":"Create src/api/handlers/stream.rs. /stream returns SSE event stream via axum::response::sse. Events sent at configurable interval (default 30s). StreamData includes providers, timestamp, optional error. Keep-alive every 15s prevents timeout. Errors sent as events not disconnects. Include JS client example in docs. ProviderSnapshot includes trend field.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:15:45.97157235-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:15:45.97157235-05:00"}
{"id":"coding_agent_usage_tracker-thy","title":"Unit tests for error module (error.rs)","description":"## Overview\nComplete unit test coverage for the error handling module.\n\n## Target: src/error.rs\nCurrent coverage: Unknown - needs verification\n\n## Test Cases\n1. **Error Construction**\n   - Test each error variant creation\n   - Verify Display implementations\n   - Test From implementations for wrapped errors\n\n2. **Error Conversion**\n   - IO errors ‚Üí CautError\n   - JSON parse errors ‚Üí CautError\n   - HTTP errors ‚Üí CautError\n\n3. **Error Context**\n   - Provider context attachment\n   - Path context for file operations\n   - URL context for HTTP operations\n\n## Acceptance Criteria\n- [ ] All error variants tested\n- [ ] Display trait outputs verified\n- [ ] From conversions tested\n- [ ] Context methods tested\n- [ ] 100% line coverage for error.rs","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:12:06.590570477-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:12:06.590570477-05:00"}
{"id":"coding_agent_usage_tracker-u5h","title":"Create test utilities module with shared helpers","description":"## Overview\nCreate a dedicated test utilities module (`src/test_utils.rs` or `tests/common/mod.rs`) with shared helpers for all tests.\n\n## Requirements\n\n### Test Helper Functions\n- `make_test_provider_payload(provider: \u0026str, source: \u0026str)` - Creates realistic ProviderPayload\n- `make_test_rate_window(used_percent: f64)` - Creates RateWindow with reset description\n- `make_test_usage_snapshot()` - Creates full UsageSnapshot\n- `make_test_credits_snapshot(remaining: f64)` - Creates CreditsSnapshot\n- `make_test_status_payload(indicator: StatusIndicator)` - Creates StatusPayload\n- `make_test_cost_payload(provider: \u0026str)` - Creates CostPayload\n\n### Temp Directory Utilities\n- `TestDir` struct with auto-cleanup (Drop impl)\n- `TestDir::new()` - Creates isolated temp directory\n- `TestDir::create_file(name, content)` - Create test files\n- `TestDir::path()` - Get path for assertions\n\n### Assertion Helpers\n- `assert_contains!(haystack, needle)` - String containment\n- `assert_json_valid!(json_str)` - JSON parse validation\n- `assert_ansi_codes!(text)` - Verify ANSI escape sequences present\n- `assert_no_ansi_codes!(text)` - Verify no ANSI codes\n\n## Implementation Notes\n- NO MOCKS - use real struct instances\n- Use `#[cfg(test)]` to exclude from production builds\n- Export via `pub mod test_utils` in lib.rs (test-only)\n\n## Acceptance Criteria\n- [ ] All helper functions implemented\n- [ ] TestDir with proper cleanup\n- [ ] Assertion macros work correctly\n- [ ] Documentation with examples\n- [ ] Used by at least 3 existing test modules","status":"closed","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:09:54.200424083-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:14:29.680734135-05:00","closed_at":"2026-01-18T04:14:29.680734135-05:00","close_reason":"Completed test_utils module: all factory functions, TestDir with cleanup, assertion macros implemented and working. Integrated into 3 test modules (render/human.rs, render/robot.rs, core/models.rs). All tests pass."}
{"id":"coding_agent_usage_tracker-ucr","title":"[EPIC] Configuration File (~/.config/caut/config.toml)","description":"## Overview\nAdd support for a configuration file that stores user preferences and provider settings, eliminating the need to repeatedly specify flags.\n\n## Background \u0026 Rationale\n\n### The Problem\nCurrently, users must specify their preferred providers, output format, and other options via CLI flags every time:\n```bash\ncaut usage --provider claude,codex --format json --timeout 15\n```\n\nThis is tedious for power users who always want the same settings. It also makes AI agents less efficient as they need to remember and specify flags each time.\n\n### The Solution\nA `~/.config/caut/config.toml` file that stores persistent preferences:\n```toml\n[defaults]\nproviders = [\"claude\", \"codex\"]\nformat = \"human\"\ntimeout_seconds = 10\nno_color = false\n\n[providers.claude]\nenabled = true\npriority = 1\ntimeout_seconds = 15\n\n[providers.codex]\nenabled = true\npriority = 2\n# Uses default timeout\n```\n\n### Why TOML\n- Human-readable and easy to edit manually\n- Well-established in Rust ecosystem (Cargo.toml)\n- Good balance of simplicity and expressiveness\n- Serde integration is excellent\n\n### Precedence Rules\n1. CLI flags override everything\n2. Environment variables override config file\n3. Config file overrides built-in defaults\n4. Built-in defaults as ultimate fallback\n\n### XDG Base Directory Compliance\n- Primary: `$XDG_CONFIG_HOME/caut/config.toml` (usually ~/.config/caut/)\n- Fallback: `~/.cautrc` for simplicity\n\n## Business Value\n- Reduces friction for power users\n- Makes AI agent integration smoother\n- Enables per-provider customization\n- Follows Unix conventions (config files)\n\n## Subtasks\n1. Core config loading and parsing\n2. Provider-specific settings\n3. CLI/environment variable integration\n4. Config init command\n5. Documentation and validation\n\n## Success Metrics\n- Config file respected in all commands\n- Clear error messages for invalid config\n- `caut config show` displays effective settings\n- AI agents can rely on persistent preferences\n\n## Technical Considerations\n- Use directories crate for XDG paths (already in dependencies)\n- serde + toml crates for parsing\n- Config validation at load time, not runtime\n- Consider migration path if format changes","status":"open","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:55:17.661340012-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:55:17.661340012-05:00"}
{"id":"coding_agent_usage_tracker-us2","title":"Unit tests for core/cli_runner.rs (command execution)","description":"## Overview\nTest the CLI runner module that handles command execution flow.\n\n## Target: src/core/cli_runner.rs (3.7KB)\nCritical for: Correct CLI behavior\n\n## Test Cases\n\n### 1. Command Dispatch\n- Usage command routing\n- Cost command routing\n- Unknown command handling\n- Help flag handling\n\n### 2. Flag Processing\n- --json flag enables robot mode\n- --no-color flag disables ANSI\n- --provider flag filters providers\n- --verbose flag enables debug output\n- Flag combination handling\n\n### 3. Output Coordination\n- Stdout vs stderr routing\n- Exit code determination\n- Error message formatting\n\n### 4. Pipeline Integration\n- Calls fetch pipeline correctly\n- Handles pipeline errors\n- Aggregates multi-provider results\n\n## Test Infrastructure\n- Use test helpers for mock arguments\n- Capture stdout/stderr in tests\n- Verify exit codes\n\n## Acceptance Criteria\n- [ ] All command paths tested\n- [ ] All flag combinations tested\n- [ ] Exit codes verified\n- [ ] Error messages validated","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:51:14.951064294-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:51:14.951064294-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-us2","depends_on_id":"coding_agent_usage_tracker-u5h","type":"blocks","created_at":"2026-01-18T02:53:18.935848586-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-uuv","title":"JSON schema contract tests (robot mode output validation)","description":"## Overview\nVerify that JSON output matches the documented schema contract. This prevents breaking changes to machine-readable output that downstream tools depend on.\n\n## Target: src/render/robot.rs and all JSON output\nCritical for: API stability, downstream tool compatibility\n\n## Schema Contract\n\n### RobotOutput Envelope (required fields)\n```json\n{\n  \"schemaVersion\": \"caut.v1\",      // Required, string\n  \"generatedAt\": \"2026-01-18...\",  // Required, ISO8601\n  \"command\": \"usage\",              // Required, string\n  \"data\": [...],                   // Required, array\n  \"errors\": [],                    // Required, array (may be empty)\n  \"meta\": {                        // Required, object\n    \"format\": \"json\",              // Required\n    \"flags\": [],                   // Required\n    \"runtime\": \"cli\"               // Required\n  }\n}\n```\n\n### ProviderPayload (for usage command)\n```json\n{\n  \"provider\": \"claude\",            // Required, string\n  \"source\": \"config\",              // Required, string\n  \"usage\": {                       // Required, object\n    \"primary\": {                   // Optional, RateWindow\n      \"usedPercent\": 30.0,\n      \"windowMinutes\": 180,\n      \"resetsAt\": \"2026-01-18T...\",\n      \"resetDescription\": \"in 2 hours\"\n    },\n    \"secondary\": {...},            // Optional\n    \"tertiary\": {...},             // Optional\n    \"updatedAt\": \"2026-01-18...\"   // Required\n  },\n  \"credits\": {...},                // Optional\n  \"status\": {...},                 // Optional\n  \"version\": \"1.0.0\"               // Optional\n}\n```\n\n### CostPayload (for cost command)\n```json\n{\n  \"provider\": \"claude\",\n  \"source\": \"local\",\n  \"updatedAt\": \"2026-01-18...\",\n  \"sessionTokens\": 12345,          // Optional, integer\n  \"sessionCostUsd\": 0.15,          // Optional, float\n  \"last30DaysTokens\": 500000,      // Optional\n  \"last30DaysCostUsd\": 5.50,       // Optional\n  \"daily\": [...],                  // Optional, array\n  \"totals\": {...}                  // Optional\n}\n```\n\n## Test Cases\n\n### 1. Schema Version Tests\n- schemaVersion is exactly \"caut.v1\"\n- schemaVersion never changes unexpectedly\n- Test with snapshot comparison\n\n### 2. Required Fields Tests\n- All required fields present\n- Required fields have correct types\n- Missing required fields fail validation\n\n### 3. Optional Fields Tests\n- Optional fields can be absent\n- Optional fields have correct types when present\n- null vs absent distinction (if any)\n\n### 4. Field Naming Tests\n- camelCase naming verified\n- No snake_case leakage\n- Consistent naming across payloads\n\n### 5. Type Validation Tests\n- Numbers are numbers (not strings)\n- Dates are ISO8601 formatted\n- Arrays are arrays (not objects)\n- Enums have valid values only\n\n### 6. Backward Compatibility Tests\n- Old schema samples still validate\n- New fields don't break old parsers\n- Removed fields documented\n\n## Implementation\n\n### JSON Schema Definition\nCreate `schemas/caut-v1.schema.json`:\n```json\n{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"title\": \"CAUT Robot Output\",\n  \"type\": \"object\",\n  \"required\": [\"schemaVersion\", \"generatedAt\", \"command\", \"data\", \"errors\", \"meta\"],\n  \"properties\": {\n    \"schemaVersion\": {\"const\": \"caut.v1\"},\n    ...\n  }\n}\n```\n\n### Rust Test with jsonschema crate\n```rust\nuse jsonschema::JSONSchema;\n\n#[test]\nfn test_usage_output_matches_schema() {\n    let schema = include_str!(\"../../schemas/caut-v1.schema.json\");\n    let schema: serde_json::Value = serde_json::from_str(schema).unwrap();\n    let compiled = JSONSchema::compile(\u0026schema).unwrap();\n    \n    let output = get_caut_usage_json_output();\n    let result = compiled.validate(\u0026output);\n    \n    assert!(result.is_ok(), \"Output should match schema\");\n}\n```\n\n## Acceptance Criteria\n- [ ] JSON Schema file created\n- [ ] Schema validates all required fields\n- [ ] Schema validates field types\n- [ ] Tests verify current output matches schema\n- [ ] Tests catch schema violations\n- [ ] Schema version documented\n- [ ] Backward compatibility tested","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:57:24.484560543-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T04:55:44.322836523-05:00","closed_at":"2026-01-18T04:55:44.322836523-05:00","close_reason":"Created JSON Schema file (schemas/caut-v1.schema.json) with comprehensive definitions for RobotOutput, ProviderPayload, CostPayload, RateWindow, UsageSnapshot, StatusPayload, CreditsSnapshot, and CostDailyEntry. Added 46 schema contract tests covering: schema version validation, required field checks, type validation, enum constraints (command, format, runtime, StatusIndicator), date format patterns, RateWindow bounds (0-100%), nested object validation via oneOf, camelCase naming verification, and backward compatibility. All acceptance criteria met.","dependencies":[{"issue_id":"coding_agent_usage_tracker-uuv","depends_on_id":"coding_agent_usage_tracker-32d","type":"blocks","created_at":"2026-01-18T02:57:31.972961959-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-v3f","title":"[EPIC] Offline Mode with Graceful Degradation","description":"## Overview\n\nWhen network is unavailable or providers are unreachable, show cached data with clear staleness indicators rather than failing completely. A tool that fails on network hiccups is frustrating; a tool that degrades gracefully feels robust and reliable.\n\n## Strategic Importance (Why P2)\n\n- **Reliability is a hygiene factor**: Users expect tools to work\n- **Low complexity, high polish**: Simple caching with good UX\n- **Prevents frustration**: Network issues shouldn't mean \"no data\"\n- **Good engineering practice**: Graceful degradation is professional\n\n## User Value Proposition\n\n**Network down**:\n```\n$ caut usage\n‚ö° Offline Mode (cached data from 5 minutes ago)\n\nClaude: 62% used (as of 12:30)\nCodex:  41% used (as of 12:28)\n\nNote: Data may be stale. Will refresh when network available.\n```\n\n**One provider unreachable**:\n```\n$ caut usage\nClaude: 65% used ‚úì\nCodex:  [cached] 41% used (15 min ago, fetch failed)\n        ‚îî‚îÄ Error: Connection timeout. Using cached value.\n```\n\n**Watch mode with intermittent connection**:\n```\n‚îå‚îÄ caut watch ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ ‚ö° Network issues - showing cached data      ‚îÇ\n‚îÇ Last successful fetch: 3 minutes ago         ‚îÇ\n‚îÇ Retrying in 10s...                           ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Claude: 65% [cached]    Codex: 41% [cached]  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n## Technical Approach\n\n### Cache Layer with TTL Tracking\n\n```rust\nstruct CachedUsage {\n    snapshot: UsageSnapshot,\n    fetched_at: DateTime\u003cUtc\u003e,\n    source: FetchSource,\n    fetch_duration_ms: u32,\n}\n\nimpl CachedUsage {\n    fn staleness(\u0026self) -\u003e Duration {\n        Utc::now() - self.fetched_at\n    }\n    \n    fn freshness_status(\u0026self) -\u003e FreshnessStatus {\n        let age = self.staleness();\n        match age {\n            d if d \u003c Duration::minutes(1) =\u003e FreshnessStatus::Fresh,\n            d if d \u003c Duration::minutes(5) =\u003e FreshnessStatus::Recent,\n            d if d \u003c Duration::minutes(30) =\u003e FreshnessStatus::Stale,\n            d if d \u003c Duration::hours(1) =\u003e FreshnessStatus::VeryStale,\n            _ =\u003e FreshnessStatus::Expired,\n        }\n    }\n}\n```\n\n### Fetch with Fallback\n\n```rust\nasync fn fetch_with_cache(provider: \u0026Provider) -\u003e UsageResult {\n    // Try live fetch first\n    match fetch_live(provider).await {\n        Ok(snapshot) =\u003e {\n            // Success - update cache and return fresh data\n            cache_write(provider, \u0026snapshot);\n            UsageResult::Fresh(snapshot)\n        }\n        Err(e) =\u003e {\n            // Fetch failed - try cache\n            match cache_read(provider) {\n                Some(cached) if !cached.is_expired() =\u003e {\n                    // Cache hit - return with staleness info\n                    UsageResult::Cached {\n                        snapshot: cached.snapshot,\n                        age: cached.staleness(),\n                        error: Some(e),\n                    }\n                }\n                Some(cached) =\u003e {\n                    // Cache expired but better than nothing\n                    UsageResult::ExpiredCache {\n                        snapshot: cached.snapshot,\n                        age: cached.staleness(),\n                        error: e,\n                    }\n                }\n                None =\u003e {\n                    // No cache - actual failure\n                    UsageResult::Failed(e)\n                }\n            }\n        }\n    }\n}\n```\n\n### Staleness Display\n\n```rust\nfn format_staleness(age: Duration) -\u003e String {\n    if age \u003c Duration::minutes(1) {\n        \"just now\".into()\n    } else if age \u003c Duration::hours(1) {\n        format!(\"{} min ago\", age.num_minutes())\n    } else if age \u003c Duration::hours(24) {\n        format!(\"{} hours ago\", age.num_hours())\n    } else {\n        format!(\"{} days ago\", age.num_days())\n    }\n}\n\nfn format_cached_indicator(freshness: FreshnessStatus) -\u003e \u0026'static str {\n    match freshness {\n        FreshnessStatus::Fresh =\u003e \"\",\n        FreshnessStatus::Recent =\u003e \"[cached]\",\n        FreshnessStatus::Stale =\u003e \"[stale]\",\n        FreshnessStatus::VeryStale =\u003e \"[very stale ‚ö†Ô∏è]\",\n        FreshnessStatus::Expired =\u003e \"[expired ‚ö†Ô∏è]\",\n    }\n}\n```\n\n### Background Refresh\n\nIn watch mode, when showing cached data:\n1. Schedule background retry with exponential backoff\n2. Update display when fresh data arrives\n3. Show \"Reconnecting...\" status\n\n```rust\nasync fn background_refresh(provider: \u0026Provider, attempt: u32) {\n    let delay = Duration::from_secs(10 * 2u64.pow(attempt.min(4)));\n    sleep(delay).await;\n    \n    if let Ok(snapshot) = fetch_live(provider).await {\n        cache_write(provider, \u0026snapshot);\n        notify_refresh_complete(provider);\n    }\n}\n```\n\n## Cache Storage\n\nUse existing SQLite for durability:\n- Survives process restart\n- Shared across terminal sessions\n- Atomic writes\n\n## Success Criteria\n\n- [ ] Cached data shown when fetch fails\n- [ ] Staleness clearly indicated in output\n- [ ] Different staleness levels distinguished\n- [ ] Background retry in watch mode\n- [ ] Cache persists across process restarts\n- [ ] Expired cache still shown as last resort (with warning)\n\n## Dependencies\n\n- **Uses**: Existing storage infrastructure\n- **Independent of**: Other EPICs\n- **Benefits**: All fetch operations\n\n## Considerations\n\n- Cache invalidation: When is cached data \"too old\"?\n- Concurrent access: Multiple caut instances sharing cache\n- Disk space: Cache should have size limits\n- Privacy: Cache may contain usage data (local only)","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-18T13:58:04.34107593-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T13:58:04.34107593-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-v3f","depends_on_id":"coding_agent_usage_tracker-r8q","type":"blocks","created_at":"2026-01-18T15:16:42.055004085-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-v3f","depends_on_id":"coding_agent_usage_tracker-8rv","type":"blocks","created_at":"2026-01-18T15:16:42.101647018-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-v3f","depends_on_id":"coding_agent_usage_tracker-c6i","type":"blocks","created_at":"2026-01-18T15:16:42.151470531-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-v3f","depends_on_id":"coding_agent_usage_tracker-yii","type":"blocks","created_at":"2026-01-18T15:16:42.198852145-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-v53","title":"Errors: Error taxonomy and structured error types","description":"## Overview\nCreate a comprehensive error taxonomy that categorizes errors and associates them with fix metadata.\n\n## Background \u0026 Rationale\nTo provide actionable suggestions, we need to know what KIND of error occurred. A structured taxonomy lets us map errors to fixes consistently.\n\n## Technical Approach\n\n### 1. Error Categories\n```rust\n// In error.rs\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum ErrorCategory {\n    /// Authentication issues (expired, missing, invalid).\n    Authentication,\n    /// Network issues (timeout, DNS, SSL).\n    Network,\n    /// Configuration issues (parse, validation, missing).\n    Configuration,\n    /// Provider-specific issues (rate limit, unavailable).\n    Provider,\n    /// Environment issues (missing tools, permissions).\n    Environment,\n    /// Internal errors (bugs, unexpected state).\n    Internal,\n}\n```\n\n### 2. Enhanced CautError\n```rust\n#[derive(Debug, thiserror::Error)]\npub enum CautError {\n    // Authentication errors\n    #[error(\"Authentication expired for {provider}\")]\n    AuthExpired {\n        provider: String,\n        #[source]\n        source: Option\u003cBox\u003cdyn std::error::Error + Send + Sync\u003e\u003e,\n    },\n    \n    #[error(\"Authentication not configured for {provider}\")]\n    AuthNotConfigured {\n        provider: String,\n    },\n    \n    #[error(\"Invalid credentials for {provider}\")]\n    AuthInvalid {\n        provider: String,\n        reason: String,\n    },\n    \n    // Network errors\n    #[error(\"Network timeout after {seconds}s for {provider}\")]\n    Timeout {\n        provider: String,\n        seconds: u64,\n    },\n    \n    #[error(\"Network error: {message}\")]\n    Network {\n        message: String,\n        #[source]\n        source: Option\u003creqwest::Error\u003e,\n    },\n    \n    #[error(\"DNS resolution failed for {host}\")]\n    DnsFailure {\n        host: String,\n    },\n    \n    #[error(\"SSL/TLS error: {message}\")]\n    SslError {\n        message: String,\n    },\n    \n    // Configuration errors\n    #[error(\"Config file not found: {path}\")]\n    ConfigNotFound {\n        path: String,\n    },\n    \n    #[error(\"Config parse error at {path}:{line}: {message}\")]\n    ConfigParse {\n        path: String,\n        line: Option\u003cusize\u003e,\n        message: String,\n    },\n    \n    #[error(\"Invalid config value for {key}: {message}\")]\n    ConfigInvalid {\n        key: String,\n        value: String,\n        message: String,\n    },\n    \n    // Provider errors\n    #[error(\"Rate limited by {provider}: {message}\")]\n    RateLimited {\n        provider: String,\n        retry_after: Option\u003cDuration\u003e,\n        message: String,\n    },\n    \n    #[error(\"Provider {provider} unavailable: {message}\")]\n    ProviderUnavailable {\n        provider: String,\n        message: String,\n    },\n    \n    // Environment errors\n    #[error(\"CLI tool not found: {name}\")]\n    CliNotFound {\n        name: String,\n    },\n    \n    #[error(\"Permission denied: {path}\")]\n    PermissionDenied {\n        path: String,\n    },\n    \n    // Generic fallback\n    #[error(\"{0}\")]\n    Other(String),\n}\n```\n\n### 3. Error Metadata Trait\n```rust\nimpl CautError {\n    pub fn category(\u0026self) -\u003e ErrorCategory {\n        match self {\n            Self::AuthExpired { .. } |\n            Self::AuthNotConfigured { .. } |\n            Self::AuthInvalid { .. } =\u003e ErrorCategory::Authentication,\n            \n            Self::Timeout { .. } |\n            Self::Network { .. } |\n            Self::DnsFailure { .. } |\n            Self::SslError { .. } =\u003e ErrorCategory::Network,\n            \n            Self::ConfigNotFound { .. } |\n            Self::ConfigParse { .. } |\n            Self::ConfigInvalid { .. } =\u003e ErrorCategory::Configuration,\n            \n            Self::RateLimited { .. } |\n            Self::ProviderUnavailable { .. } =\u003e ErrorCategory::Provider,\n            \n            Self::CliNotFound { .. } |\n            Self::PermissionDenied { .. } =\u003e ErrorCategory::Environment,\n            \n            Self::Other(_) =\u003e ErrorCategory::Internal,\n        }\n    }\n    \n    pub fn error_code(\u0026self) -\u003e \u0026str {\n        match self {\n            Self::AuthExpired { .. } =\u003e \"CAUT-A001\",\n            Self::AuthNotConfigured { .. } =\u003e \"CAUT-A002\",\n            Self::AuthInvalid { .. } =\u003e \"CAUT-A003\",\n            Self::Timeout { .. } =\u003e \"CAUT-N001\",\n            Self::Network { .. } =\u003e \"CAUT-N002\",\n            // ... etc\n            Self::Other(_) =\u003e \"CAUT-X000\",\n        }\n    }\n    \n    pub fn is_retryable(\u0026self) -\u003e bool {\n        matches\\!(self,\n            Self::Timeout { .. } |\n            Self::Network { .. } |\n            Self::RateLimited { .. }\n        )\n    }\n}\n```\n\n### 4. Migration from Generic Errors\n```rust\n// Example: Instead of this\nErr(CautError::FetchFailed { \n    provider: \"claude\".to_string(),\n    reason: \"Network timeout\".to_string(),\n})\n\n// Use this\nErr(CautError::Timeout {\n    provider: \"claude\".to_string(),\n    seconds: 10,\n})\n```\n\n## Files to Modify\n- `src/error.rs`: Completely revamp error types\n- All provider files: Update error construction\n- All CLI files: Update error handling\n\n## Dependencies\n- None (foundational)\n\n## Acceptance Criteria\n- [ ] All errors have a category\n- [ ] All errors have a stable error code\n- [ ] Retryable errors are flagged\n- [ ] Error codes are documented\n- [ ] Migration from generic errors complete\n\n## Testing Strategy\n- Test category assignment for all variants\n- Test error code uniqueness\n- Test retryable flag accuracy\n- Test serialization of error types","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T03:00:56.329233488-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T12:25:28.639359813-05:00","closed_at":"2026-01-18T12:25:28.639359813-05:00","close_reason":"Added ErrorCategory enum with 6 categories (Authentication, Network, Configuration, Provider, Environment, Internal). Added 15+ new specific error variants. Implemented methods: category(), error_code() with stable CAUT-* codes, is_retryable(), retry_after(), provider(). Added 18 unit tests, all passing. Maintained backward compatibility with legacy variants."}
{"id":"coding_agent_usage_tracker-v7m","title":"TUI: Implement keyboard navigation system","description":"Add vim-style (j/k) and arrow key navigation, tab panel cycling, number key provider selection, and help overlay. See /tmp/bead_tui_impl_tasks.md Task 4 for KeyHandler implementation.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:13:10.497374516-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:13:10.497374516-05:00"}
{"id":"coding_agent_usage_tracker-vf5","title":"Implement token-accounts list and convert commands","description":"Complete the token-accounts subcommands: list (show configured accounts per provider) and convert (migrate between CodexBar and caut formats).","status":"closed","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T01:01:04.398321417-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T01:34:24.010759507-05:00","closed_at":"2026-01-18T01:34:24.010759507-05:00","close_reason":"Duplicate of coding_agent_usage_tracker-h3p which was already implemented"}
{"id":"coding_agent_usage_tracker-vv4","title":"API: Implement server-side caching with background refresh","description":"## Summary\nImplement server-side caching with configurable refresh intervals for the API server.\n\n## Background\nThe API server needs intelligent caching to:\n1. Reduce load on provider APIs\n2. Respond quickly to client requests\n3. Keep data reasonably fresh\n4. Support forced refreshes\n\n## Technical Design\n\n### Background Refresh Task\n```rust\npub struct RefreshScheduler {\n    state: Arc\u003cAppState\u003e,\n    intervals: HashMap\u003cString, Duration\u003e,\n    running: Arc\u003cAtomicBool\u003e,\n}\n\nimpl RefreshScheduler {\n    pub fn new(state: Arc\u003cAppState\u003e) -\u003e Self {\n        Self {\n            state,\n            intervals: Self::default_intervals(),\n            running: Arc::new(AtomicBool::new(false)),\n        }\n    }\n    \n    fn default_intervals() -\u003e HashMap\u003cString, Duration\u003e {\n        let mut intervals = HashMap::new();\n        intervals.insert(\"claude\".to_string(), Duration::from_secs(60));\n        intervals.insert(\"codex\".to_string(), Duration::from_secs(60));\n        intervals.insert(\"openrouter\".to_string(), Duration::from_secs(120));\n        intervals\n    }\n    \n    pub async fn start(\u0026self) {\n        self.running.store(true, Ordering::SeqCst);\n        \n        // Spawn refresh task for each provider\n        for (provider, interval) in \u0026self.intervals {\n            let state = self.state.clone();\n            let provider = provider.clone();\n            let interval = *interval;\n            let running = self.running.clone();\n            \n            tokio::spawn(async move {\n                let mut ticker = tokio::time::interval(interval);\n                \n                while running.load(Ordering::SeqCst) {\n                    ticker.tick().await;\n                    \n                    if let Some(fetcher) = state.fetchers.get(\u0026provider) {\n                        match fetcher.fetch().await {\n                            Ok(payload) =\u003e {\n                                let mut cache = state.cache.write().await;\n                                cache.insert(provider.clone(), CacheEntry::new(payload));\n                                \n                                // Broadcast update event\n                                state.event_tx.send(Event::Updated {\n                                    provider: provider.clone(),\n                                }).ok();\n                            }\n                            Err(e) =\u003e {\n                                warn!(\"Background refresh failed for {}: {}\", provider, e);\n                            }\n                        }\n                    }\n                }\n            });\n        }\n    }\n    \n    pub fn stop(\u0026self) {\n        self.running.store(false, Ordering::SeqCst);\n    }\n}\n```\n\n### Cache-Aware Request Handler\n```rust\nmod handlers {\n    /// GET /api/v1/usage/:provider with cache control\n    pub async fn get_provider_usage(\n        State(state): State\u003cArc\u003cAppState\u003e\u003e,\n        Path(provider): Path\u003cString\u003e,\n        Query(params): Query\u003cUsageQueryParams\u003e,\n    ) -\u003e Result\u003c(StatusCode, Json\u003cProviderUsageResponse\u003e), StatusCode\u003e {\n        // Check if client wants fresh data\n        if params.refresh.unwrap_or(false) {\n            return refresh_and_return(\u0026state, \u0026provider).await;\n        }\n        \n        // Check cache\n        let cache = state.cache.read().await;\n        \n        if let Some(entry) = cache.get(\u0026provider) {\n            // Check if client accepts stale data\n            let max_age = params.max_age.unwrap_or(60);\n            \n            if entry.age_seconds() \u003c= max_age {\n                return Ok((\n                    StatusCode::OK,\n                    Json(entry.to_response(\u0026provider)),\n                ));\n            }\n            \n            // Data too stale, refresh in background\n            drop(cache);\n            tokio::spawn(refresh_provider(state.clone(), provider.clone()));\n            \n            // Return stale data with warning header\n            let cache = state.cache.read().await;\n            let entry = cache.get(\u0026provider).unwrap();\n            \n            return Ok((\n                StatusCode::OK,  // Consider 203 Non-Authoritative\n                Json(entry.to_response(\u0026provider)),\n            ));\n        }\n        \n        Err(StatusCode::NOT_FOUND)\n    }\n}\n\n#[derive(Deserialize)]\npub struct UsageQueryParams {\n    refresh: Option\u003cbool\u003e,\n    max_age: Option\u003cu64\u003e,  // Max acceptable age in seconds\n}\n```\n\n### Cache Warming\n```rust\nimpl ApiServer {\n    /// Warm cache on server start\n    async fn warm_cache(\u0026self) -\u003e Result\u003c()\u003e {\n        let providers: Vec\u003c_\u003e = self.state.fetchers.keys().cloned().collect();\n        \n        // Fetch all providers in parallel\n        let futures: Vec\u003c_\u003e = providers\n            .iter()\n            .filter_map(|p| {\n                self.state.fetchers.get(p).map(|f| {\n                    let provider = p.clone();\n                    async move {\n                        let result = f.fetch().await;\n                        (provider, result)\n                    }\n                })\n            })\n            .collect();\n        \n        let results = futures::future::join_all(futures).await;\n        \n        let mut cache = self.state.cache.write().await;\n        for (provider, result) in results {\n            if let Ok(payload) = result {\n                cache.insert(provider, CacheEntry::new(payload));\n            }\n        }\n        \n        Ok(())\n    }\n}\n```\n\n### Configuration\n```toml\n# ~/.config/caut/config.toml\n[server]\nport = 8420\nhost = \"127.0.0.1\"\n\n[server.refresh]\nenabled = true\ndefault_interval_seconds = 60\n\n[server.refresh.providers]\nclaude = { interval_seconds = 60 }\ncodex = { interval_seconds = 60 }\nopenrouter = { interval_seconds = 120 }\n\n[server.cache]\nwarm_on_start = true\nmax_age_seconds = 300\n```\n\n### HTTP Cache Headers\n```rust\nasync fn get_provider_usage(/*...*/) -\u003e impl IntoResponse {\n    let entry = /*...*/;\n    \n    let headers = [\n        (header::CACHE_CONTROL, format!(\"max-age={}\", entry.ttl_remaining())),\n        (header::AGE, entry.age_seconds().to_string()),\n        (header::LAST_MODIFIED, entry.cached_at.to_rfc2822()),\n    ];\n    \n    (headers, Json(response))\n}\n```\n\n## Acceptance Criteria\n- [ ] Background refresh runs at configured intervals\n- [ ] Cache warming on server start works\n- [ ] ?refresh=true forces immediate fetch\n- [ ] ?max_age=N controls acceptable staleness\n- [ ] HTTP cache headers present\n- [ ] Refresh scheduler can be stopped\n- [ ] Per-provider intervals configurable\n- [ ] Failed refreshes don't crash server\n\n## API Query Parameters\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| refresh | bool | Force immediate refresh |\n| max_age | u64 | Max acceptable age in seconds |\n\n## Dependencies\n- Requires axum server setup (sibling task)\n- Requires cache layer (EPIC 9)\n- Used by SSE streaming\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:20:30.200653691-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:20:30.200653691-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-vv4","depends_on_id":"coding_agent_usage_tracker-zaj","type":"blocks","created_at":"2026-01-18T14:22:24.184876146-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-vv4","depends_on_id":"coding_agent_usage_tracker-bkz","type":"blocks","created_at":"2026-01-18T14:22:24.231291744-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-wxz","title":"Unit tests for core/pipeline.rs (data pipeline)","description":"## Overview\nTest the data pipeline that orchestrates provider fetching and aggregation.\n\n## Target: src/core/pipeline.rs (5.6KB)\nCritical for: Correct data flow\n\n## Test Cases\n\n### 1. Pipeline Execution\n- Single provider execution\n- Multi-provider parallel execution\n- Provider error isolation (one fails, others continue)\n\n### 2. Result Aggregation\n- Combine multiple ProviderPayload results\n- Error collection and reporting\n- Partial success handling\n\n### 3. Pipeline Options\n- Verbose mode logging\n- Cache bypass option\n- Timeout enforcement\n\n### 4. Error Handling\n- Individual provider failures\n- All providers fail\n- Partial data from provider\n- Timeout during fetch\n\n## Test Infrastructure\n- Mock provider implementations for testing\n- Capture pipeline stages\n- Verify aggregation logic\n\n## Acceptance Criteria\n- [ ] Single/multi-provider execution tested\n- [ ] Error isolation verified\n- [ ] Result aggregation correct\n- [ ] Timeout behavior verified","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:51:44.039349914-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:51:44.039349914-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-wxz","depends_on_id":"coding_agent_usage_tracker-u5h","type":"blocks","created_at":"2026-01-18T02:53:19.041762416-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-x3j","title":"Prediction: Test suite with velocity validation and edge cases","description":"## Summary\nImplement comprehensive test suite for Time-to-Limit Prediction validating velocity calculations, edge cases, and display accuracy.\n\n## Parent EPIC\n[EPIC] Time-to-Limit Prediction (coding_agent_usage_tracker-swp)\n\n## Test Categories\n\n### 1. Unit Tests: Velocity Calculation\n```rust\n#[cfg(test)]\nmod velocity_tests {\n    use super::*;\n    \n    fn make_snapshot(pct: f64, hours_ago: i64) -\u003e StoredSnapshot {\n        StoredSnapshot {\n            id: 0,\n            provider: \"claude\".to_string(),\n            fetched_at: Utc::now() - Duration::hours(hours_ago),\n            primary_used_pct: Some(pct),\n            ..Default::default()\n        }\n    }\n    \n    #[test]\n    fn test_positive_velocity_calculation() {\n        // Usage increasing: 30% -\u003e 50% over 2 hours = 10%/hr\n        let history = vec![\n            make_snapshot(30.0, 2),\n            make_snapshot(50.0, 0),\n        ];\n        \n        let velocity = calculate_velocity(\u0026history, Duration::hours(3)).unwrap();\n        assert!((velocity - 10.0).abs() \u003c 0.1, \"Expected ~10%/hr, got {}\", velocity);\n    }\n    \n    #[test]\n    fn test_negative_velocity_decreasing_usage() {\n        // Usage decreasing: 80% -\u003e 60% over 2 hours = -10%/hr\n        let history = vec![\n            make_snapshot(80.0, 2),\n            make_snapshot(60.0, 0),\n        ];\n        \n        let velocity = calculate_velocity(\u0026history, Duration::hours(3)).unwrap();\n        assert!(velocity \u003c 0.0, \"Expected negative velocity for decreasing usage\");\n        assert!((velocity - (-10.0)).abs() \u003c 0.1);\n    }\n    \n    #[test]\n    fn test_zero_velocity_stable_usage() {\n        // Stable usage: 50% throughout\n        let history = vec![\n            make_snapshot(50.0, 3),\n            make_snapshot(50.0, 2),\n            make_snapshot(50.0, 1),\n            make_snapshot(50.0, 0),\n        ];\n        \n        let velocity = calculate_velocity(\u0026history, Duration::hours(4)).unwrap();\n        assert!(velocity.abs() \u003c 0.1, \"Expected ~0%/hr for stable usage\");\n    }\n    \n    #[test]\n    fn test_insufficient_data_returns_none() {\n        // Single point - cannot calculate velocity\n        let history = vec![make_snapshot(50.0, 0)];\n        \n        assert!(calculate_velocity(\u0026history, Duration::hours(1)).is_none());\n    }\n    \n    #[test]\n    fn test_empty_history_returns_none() {\n        let history: Vec\u003cStoredSnapshot\u003e = vec![];\n        assert!(calculate_velocity(\u0026history, Duration::hours(1)).is_none());\n    }\n    \n    #[test]\n    fn test_velocity_with_noisy_data() {\n        // Noisy but trending upward: linear regression should smooth\n        let history = vec![\n            make_snapshot(30.0, 4),\n            make_snapshot(38.0, 3),  // +8 (noise)\n            make_snapshot(42.0, 2),  // +4 (noise)\n            make_snapshot(55.0, 1),  // +13 (noise)\n            make_snapshot(50.0, 0),  // -5 (noise)\n        ];\n        \n        // Overall trend: ~5%/hr despite noise\n        let velocity = calculate_velocity(\u0026history, Duration::hours(5)).unwrap();\n        assert!(velocity \u003e 3.0 \u0026\u0026 velocity \u003c 7.0, \"Expected ~5%/hr trend, got {}\", velocity);\n    }\n    \n    #[test]\n    fn test_velocity_respects_window() {\n        // Old spike shouldn't affect recent velocity\n        let history = vec![\n            make_snapshot(90.0, 24),  // Old spike - outside window\n            make_snapshot(30.0, 2),\n            make_snapshot(40.0, 1),\n            make_snapshot(50.0, 0),\n        ];\n        \n        let velocity = calculate_velocity(\u0026history, Duration::hours(3)).unwrap();\n        // Should only consider last 3 hours: 30-\u003e50 = ~10%/hr\n        assert!((velocity - 10.0).abs() \u003c 1.0);\n    }\n}\n```\n\n### 2. Unit Tests: Reset Detection\n```rust\n#[cfg(test)]\nmod reset_tests {\n    #[test]\n    fn test_detect_reset_large_drop() {\n        let prev = make_snapshot(85.0, 1);\n        let curr = make_snapshot(5.0, 0);\n        \n        assert!(detect_reset(\u0026prev, \u0026curr));\n    }\n    \n    #[test]\n    fn test_no_reset_gradual_decrease() {\n        let prev = make_snapshot(50.0, 1);\n        let curr = make_snapshot(45.0, 0);\n        \n        assert!(!detect_reset(\u0026prev, \u0026curr));\n    }\n    \n    #[test]\n    fn test_velocity_excludes_reset_events() {\n        // History with a reset in the middle\n        let history = vec![\n            make_snapshot(40.0, 4),\n            make_snapshot(60.0, 3),\n            make_snapshot(80.0, 2),\n            make_snapshot(5.0, 1),   // RESET\n            make_snapshot(15.0, 0),\n        ];\n        \n        // Should calculate velocity only from post-reset data\n        let velocity = calculate_velocity_with_reset_handling(\u0026history, Duration::hours(5)).unwrap();\n        // 5% -\u003e 15% over 1 hour = 10%/hr\n        assert!((velocity - 10.0).abs() \u003c 1.0);\n    }\n}\n```\n\n### 3. Unit Tests: Time-to-Limit Prediction\n```rust\n#[cfg(test)]\nmod prediction_tests {\n    #[test]\n    fn test_predict_time_to_limit() {\n        // 50% used, 10%/hr velocity\n        // Time to 100% = 50% / 10%/hr = 5 hours\n        let prediction = predict_time_to_limit(50.0, 10.0);\n        \n        assert_eq!(prediction, PredictionStatus::WillHitLimit { minutes: 300 });\n    }\n    \n    #[test]\n    fn test_predict_sustainable_negative_velocity() {\n        // Decreasing usage = sustainable\n        let prediction = predict_time_to_limit(50.0, -5.0);\n        \n        assert_eq!(prediction, PredictionStatus::Decreasing);\n    }\n    \n    #[test]\n    fn test_predict_sustainable_zero_velocity() {\n        let prediction = predict_time_to_limit(50.0, 0.0);\n        \n        assert_eq!(prediction, PredictionStatus::Sustainable);\n    }\n    \n    #[test]\n    fn test_predict_unknown_insufficient_data() {\n        let prediction = predict_time_to_limit_from_history(\u0026[]);\n        \n        assert_eq!(prediction, PredictionStatus::Unknown);\n    }\n    \n    #[test]\n    fn test_prediction_accounts_for_reset_window() {\n        // 60% used, 10%/hr, but resets in 30 minutes\n        let prediction = predict_with_reset(60.0, 10.0, Duration::minutes(30));\n        \n        // Would hit 100% in 4 hours, but resets in 30 min\n        assert_eq!(prediction, PredictionStatus::WillReset { minutes: 30 });\n    }\n}\n```\n\n### 4. Unit Tests: Display Formatting\n```rust\n#[cfg(test)]\nmod display_tests {\n    #[test]\n    fn test_format_will_hit_limit() {\n        let status = PredictionStatus::WillHitLimit { minutes: 90 };\n        let formatted = status.format_for_display();\n        \n        assert!(formatted.contains(\"1h 30m\"));\n        assert!(formatted.contains(\"limit\"));\n    }\n    \n    #[test]\n    fn test_format_sustainable() {\n        let status = PredictionStatus::Sustainable;\n        let formatted = status.format_for_display();\n        \n        assert!(formatted.contains(\"sustainable\") || formatted.contains(\"stable\"));\n    }\n    \n    #[test]\n    fn test_color_coding() {\n        // Red for \u003c1hr\n        assert_eq!(PredictionStatus::WillHitLimit { minutes: 30 }.severity(), Severity::Critical);\n        \n        // Yellow for 1-4hr\n        assert_eq!(PredictionStatus::WillHitLimit { minutes: 120 }.severity(), Severity::Warning);\n        \n        // Green for \u003e4hr or sustainable\n        assert_eq!(PredictionStatus::WillHitLimit { minutes: 300 }.severity(), Severity::Ok);\n        assert_eq!(PredictionStatus::Sustainable.severity(), Severity::Ok);\n    }\n}\n```\n\n### 5. Integration Tests\n```rust\n// tests/prediction_integration.rs\n\n#[test]\nfn test_prediction_from_real_history() {\n    let tmp = TempDir::new().unwrap();\n    let store = HistoryStore::open(tmp.path().join(\"test.db\")).unwrap();\n    \n    // Simulate 4 hours of increasing usage\n    for i in 0..=8 {\n        let pct = 20.0 + (i as f64 * 5.0);  // 20% -\u003e 60% over 4 hours\n        let mut snapshot = usage_snapshot(pct, None);\n        snapshot.updated_at = Utc::now() - Duration::minutes((8 - i) * 30);\n        store.record_snapshot(\u0026snapshot, \"claude\").unwrap();\n    }\n    \n    let history = store.get_snapshots(\"claude\", Utc::now() - Duration::hours(5), Utc::now()).unwrap();\n    let prediction = predict_time_to_limit_from_history(\u0026history);\n    \n    // 10%/hr velocity, 40% remaining = ~4 hours to limit\n    match prediction {\n        PredictionStatus::WillHitLimit { minutes } =\u003e {\n            assert!(minutes \u003e 200 \u0026\u0026 minutes \u003c 280, \"Expected ~240min, got {}\", minutes);\n        }\n        _ =\u003e panic!(\"Expected WillHitLimit, got {:?}\", prediction),\n    }\n}\n```\n\n### 6. E2E Tests\n```bash\n#!/bin/bash\n# tests/e2e/prediction_e2e.sh\n\nset -euo pipefail\nsource \"$(dirname \"$0\")/helpers.sh\"\n\nlog_section \"Prediction E2E Tests\"\n\nTEMP_DIR=$(mktemp -d)\nexport CAUT_DATA_DIR=\"$TEMP_DIR\"\ntrap \"rm -rf $TEMP_DIR\" EXIT\n\n# Test 1: Prediction shown in output\nlog_test \"Prediction appears in fetch output\"\n# Simulate history by running multiple mocked fetches\nfor pct in 30 40 50 60; do\n    MOCK_USAGE_PCT=$pct caut fetch --mock --provider claude\n    sleep 1\ndone\nOUTPUT=$(caut fetch --mock --provider claude 2\u003e\u00261)\necho \"$OUTPUT\" | grep -qiE \"(limit|sustainable|insufficient)\" || fail \"No prediction in output\"\nlog_pass\n\n# Test 2: Insufficient data handling\nlog_test \"Insufficient data handled gracefully\"\nrm -rf \"$TEMP_DIR\"/*\nOUTPUT=$(caut fetch --mock --provider claude 2\u003e\u00261)\n# First fetch should show insufficient data (or no prediction)\necho \"$OUTPUT\" | grep -qiE \"(insufficient|gathering)\" \u0026\u0026 log_pass || log_pass \"No message for single point is OK\"\n\n# Test 3: Prediction accuracy\nlog_test \"Prediction calculation correct\"\n# Create controlled history\nfor i in {1..5}; do\n    MOCK_USAGE_PCT=$((20 + i * 10)) caut fetch --mock --provider claude\n    sleep 0.5\ndone\n# Should predict ~4-6 hours based on 10%/hr velocity from 70%\nOUTPUT=$(caut fetch --mock --provider claude --format json 2\u003e\u00261)\n# Verify prediction exists and is reasonable\nlog_pass\n\nlog_summary\n```\n\n### 7. Edge Case Matrix\n| Scenario | Input | Expected Output |\n|----------|-------|-----------------|\n| Rapid increase | 10%/min velocity | \"\u003c 10 min to limit\" (critical) |\n| Slow increase | 1%/hr | \"~30 hours to limit\" |\n| Stable | 0%/hr | \"Sustainable\" |\n| Decreasing | -5%/hr | \"Usage decreasing\" |\n| Near limit | 95% used | Accurate short-term prediction |\n| After reset | 5% used, reset detected | Uses post-reset data only |\n| No data | Empty history | \"Insufficient data\" |\n\n## Acceptance Criteria\n- [ ] All velocity calculation tests pass\n- [ ] Reset detection works correctly\n- [ ] Prediction accuracy within 10% for controlled scenarios\n- [ ] Display formatting correct for all states\n- [ ] E2E script passes\n- [ ] Edge cases documented and tested\n- [ ] Logging verified\n\n## Dependencies\n- Requires history storage implementation\n- Requires logging infrastructure\n","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:48:35.714705466-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:48:35.714705466-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-x3j","depends_on_id":"coding_agent_usage_tracker-zev","type":"blocks","created_at":"2026-01-18T14:56:58.520769221-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-x3j","depends_on_id":"coding_agent_usage_tracker-swp","type":"blocks","created_at":"2026-01-18T14:56:58.570648259-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-x9i","title":"Unit tests for CLI argument validation","description":"## Overview\nTest argument validation and error messages.\n\n## Target: CLI argument handling layer\n\n## Test Cases\n1. **Provider Validation**\n   - Valid providers accepted\n   - Invalid provider names rejected\n   - Case sensitivity handling\n\n2. **Flag Conflicts**\n   - Mutually exclusive flags\n   - Required flag combinations\n\n3. **Value Validation**\n   - Timeout values in range\n   - Path arguments exist (if required)\n\n4. **Error Messages**\n   - Clear error for invalid input\n   - Suggestions for typos\n   - Help hint on errors\n\n## Acceptance Criteria\n- [ ] All validation rules tested\n- [ ] Error messages verified\n- [ ] Suggestions tested","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:15:01.143732914-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T02:15:01.143732914-05:00"}
{"id":"coding_agent_usage_tracker-yfg","title":"Prompt: Create 'caut prompt' command for shell integration","description":"## Summary\nImplement a dedicated `caut prompt` subcommand optimized for shell prompt integration with minimal overhead.\n\n## Background\nThe `caut prompt` command is the user-facing interface for shell integration. It must:\n1. Start and complete in \u003c50ms total\n2. Output configurable, parseable format\n3. Support multiple output styles for different shells\n4. Gracefully degrade when data unavailable\n\n## Command Interface\n```\ncaut prompt [OPTIONS]\n\nOPTIONS:\n    -p, --provider \u003cPROVIDER\u003e    Provider to display (default: all configured)\n    -f, --format \u003cFORMAT\u003e        Output format: minimal, compact, full, custom\n    -c, --color \u003cWHEN\u003e           Color output: auto, always, never\n    --cache-only                 Only read cache, never fetch (fastest)\n    --refresh                    Force cache refresh in background\n    --template \u003cTEMPLATE\u003e        Custom format template\n```\n\n## Output Formats\n\n### Minimal (default for prompts)\n```\nC:30%|X:45%\n```\n\n### Compact\n```\nclaude:30% codex:45%\n```\n\n### Full\n```\nClaude: 30% (3h window) | Codex: 45% (7d window)\n```\n\n### Custom Template\n```\n--template \"{claude.pct}% {codex.pct}%\"\n```\n\n## Implementation\n```rust\n#[derive(Parser)]\npub struct PromptCommand {\n    #[arg(short, long)]\n    provider: Option\u003cString\u003e,\n    \n    #[arg(short, long, default_value = \"minimal\")]\n    format: PromptFormat,\n    \n    #[arg(long)]\n    cache_only: bool,\n    \n    #[arg(long)]\n    refresh: bool,\n    \n    #[arg(long)]\n    template: Option\u003cString\u003e,\n}\n\nimpl PromptCommand {\n    pub async fn run(\u0026self) -\u003e Result\u003c()\u003e {\n        let start = Instant::now();\n        \n        // 1. Read cache (fast path)\n        let cache = PromptCache::read_fast();\n        \n        // 2. Format output\n        let output = self.format_output(\u0026cache)?;\n        \n        // 3. Print (no newline for prompt embedding)\n        print!(\"{}\", output);\n        \n        // 4. Maybe trigger background refresh\n        if self.refresh || cache.map(|c| c.is_stale()).unwrap_or(true) {\n            self.trigger_background_refresh();\n        }\n        \n        debug!(\"prompt command completed in {:?}\", start.elapsed());\n        Ok(())\n    }\n}\n```\n\n## Color Support\n- Green: 0-50% usage\n- Yellow: 50-80% usage  \n- Red: 80-100% usage\n- Gray: stale data\n- Dim: unknown/unavailable\n\n## Acceptance Criteria\n- [ ] Command completes in \u003c50ms with warm cache\n- [ ] All output formats work correctly\n- [ ] Custom templates parse and render\n- [ ] Colors work with auto-detection\n- [ ] --cache-only never makes network calls\n- [ ] Background refresh works correctly\n- [ ] Exit code 0 even on errors (prompts must not fail)\n\n## Error Handling\nCRITICAL: This command must NEVER fail visibly:\n- Network errors: use cached data or empty output\n- Parse errors: empty output\n- Any panic: caught and converted to empty output\n\n## Dependencies\n- Requires cache layer (sibling task)\n- Cache populated by regular caut fetch or watch\n\n## Shell Integration Examples\nIncluded in documentation but tested here:\n```bash\n# Bash\nPS1=\"\\$(caut prompt) \\$ \"\n\n# Zsh  \nPROMPT=\"\\$(caut prompt) %# \"\n\n# Fish\nfunction fish_prompt\n    echo (caut prompt)\" \u003e \"\nend\n```","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:11:16.034905375-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:11:16.034905375-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-yfg","depends_on_id":"coding_agent_usage_tracker-mf1","type":"blocks","created_at":"2026-01-18T14:21:49.362353859-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-yii","title":"Offline: Implement background refresh mechanism","description":"Create src/core/background_refresh.rs with BackgroundRefresher. Track RefreshState per provider (attempt, last_attempt, last_success, in_progress). Exponential backoff: 10s, 20s, 40s... up to 5min max. Emit RefreshEvent (Success/Failed/Retrying) via mpsc channel. Prevent concurrent refresh attempts. Manual refresh resets backoff. Watch mode shows 'Retrying in Xs...'.","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T15:15:24.450018516-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:15:24.450018516-05:00"}
{"id":"coding_agent_usage_tracker-ymb","title":"TUI: Create provider panel widgets with progress bars and status","description":"## Summary\nImplement provider panel widgets with progress bars, status indicators, and real-time data.\n\n## Background\nEach provider needs a dedicated panel showing:\n1. Visual progress bar for usage\n2. Numeric usage percentages\n3. Reset time countdown\n4. Status indicator\n5. Additional provider-specific info (credits, auth status)\n\n## Technical Design\n\n### Provider Panel Widget\n```rust\nuse ratatui::{\n    style::{Color, Modifier, Style},\n    text::{Line, Span},\n    widgets::{Block, Borders, Gauge, Widget},\n};\n\npub struct ProviderPanel {\n    pub name: String,\n    pub usage: UsageSnapshot,\n    pub status: Option\u003cStatusPayload\u003e,\n    pub credits: Option\u003cCreditsSnapshot\u003e,\n    pub auth_health: Option\u003cProviderAuthHealth\u003e,\n}\n\nimpl Widget for \u0026ProviderPanel {\n    fn render(self, area: Rect, buf: \u0026mut Buffer) {\n        // Panel border\n        let block = Block::default()\n            .title(self.name.as_str())\n            .borders(Borders::ALL)\n            .border_style(self.border_style());\n        let inner = block.inner(area);\n        block.render(area, buf);\n        \n        // Split inner area\n        let chunks = Layout::default()\n            .direction(Direction::Vertical)\n            .constraints([\n                Constraint::Length(2),  // Progress bar\n                Constraint::Length(1),  // Primary usage text\n                Constraint::Length(1),  // Secondary usage\n                Constraint::Length(1),  // Status\n                Constraint::Min(0),     // Additional info\n            ])\n            .split(inner);\n        \n        // Render progress bar\n        self.render_progress_bar(chunks[0], buf);\n        \n        // Render usage text\n        self.render_usage_text(chunks[1], chunks[2], buf);\n        \n        // Render status\n        self.render_status(chunks[3], buf);\n        \n        // Render additional info\n        self.render_additional(chunks[4], buf);\n    }\n}\n```\n\n### Progress Bar Implementation\n```rust\nimpl ProviderPanel {\n    fn render_progress_bar(\u0026self, area: Rect, buf: \u0026mut Buffer) {\n        let pct = self.usage.primary\n            .as_ref()\n            .map(|w| w.used_percent)\n            .unwrap_or(0.0);\n        \n        let color = self.color_for_percentage(pct);\n        \n        let gauge = Gauge::default()\n            .gauge_style(Style::default().fg(color))\n            .ratio(pct / 100.0)\n            .label(format!(\"{:.0}%\", pct));\n        \n        gauge.render(area, buf);\n    }\n    \n    fn color_for_percentage(\u0026self, pct: f64) -\u003e Color {\n        match pct {\n            p if p \u003e= 90.0 =\u003e Color::Red,\n            p if p \u003e= 75.0 =\u003e Color::Yellow,\n            p if p \u003e= 50.0 =\u003e Color::Blue,\n            _ =\u003e Color::Green,\n        }\n    }\n}\n```\n\n### Usage Text Rendering\n```rust\nimpl ProviderPanel {\n    fn render_usage_text(\u0026self, primary_area: Rect, secondary_area: Rect, buf: \u0026mut Buffer) {\n        // Primary window\n        if let Some(primary) = \u0026self.usage.primary {\n            let text = format!(\n                \"Primary: {:.0}% (resets {})\",\n                primary.used_percent,\n                primary.reset_description.as_deref().unwrap_or(\"unknown\")\n            );\n            Paragraph::new(text)\n                .style(Style::default().fg(Color::White))\n                .render(primary_area, buf);\n        }\n        \n        // Secondary window\n        if let Some(secondary) = \u0026self.usage.secondary {\n            let text = format!(\n                \"Secondary: {:.0}% (resets {})\",\n                secondary.used_percent,\n                secondary.reset_description.as_deref().unwrap_or(\"unknown\")\n            );\n            Paragraph::new(text)\n                .style(Style::default().fg(Color::Gray))\n                .render(secondary_area, buf);\n        }\n    }\n}\n```\n\n### Status Indicator\n```rust\nimpl ProviderPanel {\n    fn render_status(\u0026self, area: Rect, buf: \u0026mut Buffer) {\n        let (icon, text, color) = match self.status.as_ref().map(|s| \u0026s.indicator) {\n            Some(StatusIndicator::None) =\u003e (\"‚úì\", \"Operational\", Color::Green),\n            Some(StatusIndicator::Minor) =\u003e (\"‚ö†\", \"Minor disruption\", Color::Yellow),\n            Some(StatusIndicator::Major) =\u003e (\"‚ö†\", \"Major disruption\", Color::LightRed),\n            Some(StatusIndicator::Critical) =\u003e (\"‚úó\", \"Critical\", Color::Red),\n            Some(StatusIndicator::Maintenance) =\u003e (\"‚öô\", \"Maintenance\", Color::Blue),\n            _ =\u003e (\"?\", \"Unknown\", Color::Gray),\n        };\n        \n        let line = Line::from(vec![\n            Span::styled(icon, Style::default().fg(color)),\n            Span::raw(\" \"),\n            Span::styled(text, Style::default().fg(color)),\n        ]);\n        \n        Paragraph::new(line).render(area, buf);\n    }\n}\n```\n\n### Additional Info (Credits, Auth)\n```rust\nimpl ProviderPanel {\n    fn render_additional(\u0026self, area: Rect, buf: \u0026mut Buffer) {\n        let mut lines = Vec::new();\n        \n        // Credits if available\n        if let Some(credits) = \u0026self.credits {\n            lines.push(Line::from(format!(\n                \"Credits: ${:.2} remaining\",\n                credits.remaining\n            )));\n        }\n        \n        // Auth health if concerning\n        if let Some(auth) = \u0026self.auth_health {\n            if auth.overall != OverallHealth::Healthy {\n                let (icon, text) = match auth.overall {\n                    OverallHealth::ExpiringSoon =\u003e (\"‚ö†\", \"Auth expires soon\"),\n                    OverallHealth::Expired =\u003e (\"‚úó\", \"Auth expired!\"),\n                    _ =\u003e (\"?\", \"Auth unknown\"),\n                };\n                lines.push(Line::from(vec![\n                    Span::styled(icon, Style::default().fg(Color::Yellow)),\n                    Span::raw(\" \"),\n                    Span::raw(text),\n                ]));\n            }\n        }\n        \n        let paragraph = Paragraph::new(lines);\n        paragraph.render(area, buf);\n    }\n}\n```\n\n## Acceptance Criteria\n- [ ] Provider panels render correctly\n- [ ] Progress bars show accurate percentages\n- [ ] Colors reflect usage severity\n- [ ] Reset times display correctly\n- [ ] Status indicators work for all states\n- [ ] Credits display for applicable providers\n- [ ] Auth warnings show when relevant\n- [ ] Panels adapt to available space\n\n## Visual Examples\n\n### Healthy Provider\n```\n‚îå‚îÄ Claude ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 35%       ‚îÇ\n‚îÇ Primary: 35% (resets 2h 45m) ‚îÇ\n‚îÇ Secondary: 22% (resets 6d)   ‚îÇ\n‚îÇ ‚úì Operational                ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n### Warning State\n```\n‚îå‚îÄ Codex ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 87%     ‚îÇ\n‚îÇ Primary: 87% (resets 15m)    ‚îÇ\n‚îÇ ‚ö† Minor disruption           ‚îÇ\n‚îÇ Credits: $12.50 remaining    ‚îÇ\n‚îÇ ‚ö† Auth expires in 2h         ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n## Dependencies\n- Requires core TUI layout (sibling task)\n- Used by dashboard renderer\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:15:54.630837092-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:15:54.630837092-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-ymb","depends_on_id":"coding_agent_usage_tracker-i9x","type":"blocks","created_at":"2026-01-18T14:22:09.151821614-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-yq1","title":"CI workflow: E2E tests with logging","description":"## Overview\nGitHub Actions workflow for E2E test execution with comprehensive logging.\n\n## File: .github/workflows/e2e.yml\n\n## Workflow Steps\n1. **Setup**\n   - Checkout code\n   - Build release binary\n   - Install test dependencies (bats, shellcheck)\n\n2. **Run E2E Tests**\n   - Execute test scripts\n   - Capture all output\n   - Generate JUnit XML\n\n3. **Logging**\n   - Upload test logs as artifacts\n   - Print summary in job output\n   - Highlight failures\n\n## Triggers\n- Push to main\n- Release tags\n- Manual dispatch\n\n## Test Environment\n- Linux runner (primary)\n- macOS runner (optional)\n- Windows runner (optional)\n\n## Artifacts\n- Test logs (all scenarios)\n- JUnit XML results\n- Performance metrics\n\n## Acceptance Criteria\n- [ ] E2E tests run in CI\n- [ ] Logs preserved as artifacts\n- [ ] JUnit results for GitHub UI\n- [ ] Cross-platform if feasible","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T02:17:43.257111566-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T12:56:28.516730502-05:00","closed_at":"2026-01-18T12:56:28.516730502-05:00","close_reason":"Created .github/workflows/e2e.yml with: cross-platform support (Ubuntu, macOS, Windows), shell and Rust E2E test execution, JUnit XML output via .config/nextest.toml, comprehensive logging with artifacts, GitHub Actions summary integration, and triggers for push/PR/release/manual dispatch","dependencies":[{"issue_id":"coding_agent_usage_tracker-yq1","depends_on_id":"coding_agent_usage_tracker-cn8","type":"blocks","created_at":"2026-01-18T02:18:39.937800605-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-yq1","depends_on_id":"coding_agent_usage_tracker-a5q","type":"blocks","created_at":"2026-01-18T02:18:40.037239614-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-yzr","title":"Creds: Add auth freshness tracking and warnings in output","description":"## Summary\nTrack authentication freshness across providers and surface warnings in caut output.\n\n## Background\nBuilding on JWT/token health checking, we need to:\n1. Aggregate health status across all credential sources per provider\n2. Surface warnings in caut fetch/watch output\n3. Provide actionable re-auth instructions\n4. Track when credentials were last successfully used\n\n## Technical Design\n\n### Auth Health Aggregator\n```rust\npub struct AuthHealthAggregator {\n    jwt_checker: JwtHealthChecker,\n    oauth_checker: OAuthHealthChecker,\n    cookie_checker: CookieHealthChecker,\n}\n\nimpl AuthHealthAggregator {\n    /// Get overall auth health for a provider\n    pub fn check_provider(\u0026self, provider: \u0026str) -\u003e ProviderAuthHealth {\n        let sources = self.find_auth_sources(provider);\n        \n        let checks: Vec\u003c_\u003e = sources\n            .iter()\n            .map(|s| (s.source_type.clone(), self.check_source(s)))\n            .collect();\n        \n        ProviderAuthHealth {\n            provider: provider.to_string(),\n            overall: self.aggregate_health(\u0026checks),\n            sources: checks,\n            last_successful_use: self.get_last_success(provider),\n            recommended_action: self.get_recommendation(\u0026checks),\n        }\n    }\n    \n    fn aggregate_health(\u0026self, checks: \u0026[(String, SourceHealth)]) -\u003e OverallHealth {\n        // Worst status wins\n        if checks.iter().any(|(_, h)| h.is_expired()) {\n            OverallHealth::Expired\n        } else if checks.iter().any(|(_, h)| h.is_expiring_soon()) {\n            OverallHealth::ExpiringSoon\n        } else if checks.iter().all(|(_, h)| h.is_valid()) {\n            OverallHealth::Healthy\n        } else {\n            OverallHealth::Unknown\n        }\n    }\n}\n\n#[derive(Debug)]\npub struct ProviderAuthHealth {\n    pub provider: String,\n    pub overall: OverallHealth,\n    pub sources: Vec\u003c(String, SourceHealth)\u003e,\n    pub last_successful_use: Option\u003cDateTime\u003cUtc\u003e\u003e,\n    pub recommended_action: Option\u003cString\u003e,\n}\n```\n\n### Warning Display Integration\n```rust\nimpl ProviderPayload {\n    /// Render with auth health warnings\n    pub fn render_with_health(\u0026self, health: \u0026ProviderAuthHealth) -\u003e String {\n        let mut output = self.render_usage();\n        \n        match health.overall {\n            OverallHealth::Expired =\u003e {\n                output.push_str(\u0026format!(\n                    \"\\n‚ö†Ô∏è  Auth expired! Run: {}\",\n                    health.recommended_action.as_deref().unwrap_or(\"re-authenticate\")\n                ));\n            }\n            OverallHealth::ExpiringSoon =\u003e {\n                output.push_str(\u0026format!(\n                    \"\\n‚ö†Ô∏è  Auth expires soon. Consider re-authenticating.\"\n                ));\n            }\n            _ =\u003e {}\n        }\n        \n        output\n    }\n}\n```\n\n### Re-auth Instructions\n```rust\npub fn get_reauth_instructions(provider: \u0026str, source: \u0026str) -\u003e String {\n    match (provider, source) {\n        (\"claude\", \"oauth\") =\u003e \"Run: claude auth login\",\n        (\"claude\", \"cookies\") =\u003e \"Visit claude.ai and log in again\",\n        (\"codex\", \"oauth\") =\u003e \"Run: codex auth login\",\n        _ =\u003e \"Re-authenticate with your provider\",\n    }.to_string()\n}\n```\n\n### Tracking Last Successful Use\n```rust\npub struct AuthSuccessTracker {\n    db: SqliteConnection,\n}\n\nimpl AuthSuccessTracker {\n    /// Record successful auth use\n    pub fn record_success(\u0026self, provider: \u0026str, source: \u0026str) -\u003e Result\u003c()\u003e {\n        sqlx::query!(\n            \"INSERT OR REPLACE INTO auth_success (provider, source, last_success)\n             VALUES (?, ?, ?)\",\n            provider, source, Utc::now()\n        ).execute(\u0026self.db)?;\n        Ok(())\n    }\n    \n    /// Get last successful use\n    pub fn get_last_success(\u0026self, provider: \u0026str) -\u003e Option\u003cDateTime\u003cUtc\u003e\u003e {\n        sqlx::query_scalar!(\n            \"SELECT last_success FROM auth_success WHERE provider = ?\",\n            provider\n        ).fetch_optional(\u0026self.db)?.flatten()\n    }\n}\n```\n\n## Output Integration\n```\nClaude Code (oauth)                                          ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 62%\n  Primary: 62% used (resets in 2h 15m)\n  ‚ö†Ô∏è  OAuth token expires in 4 hours. Run: claude auth login\n```\n\n## Acceptance Criteria\n- [ ] Health aggregation works across all source types\n- [ ] Warnings appear in caut fetch output\n- [ ] Warnings appear in caut watch mode\n- [ ] Re-auth instructions are provider-specific\n- [ ] Last successful use is tracked\n- [ ] No warnings for healthy credentials\n- [ ] Warnings are visually distinct but not overwhelming\n\n## Configuration\n```toml\n# ~/.config/caut/config.toml\n[auth_warnings]\nenabled = true\nwarn_hours_before_expiry = 24\nshow_in_watch = true\n```\n\n## Dependencies\n- Requires JWT/token health checking (sibling task)\n- Requires history database (EPIC 1, for tracking)\n\n## Privacy Considerations\n- Never log or display actual token values\n- Only show expiration times, not token contents\n- Track success timestamps, not credentials\n","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:13:42.887325617-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:13:42.887325617-05:00","dependencies":[{"issue_id":"coding_agent_usage_tracker-yzr","depends_on_id":"coding_agent_usage_tracker-5gn","type":"blocks","created_at":"2026-01-18T14:21:58.682694265-05:00","created_by":"Dicklesworthstone"},{"issue_id":"coding_agent_usage_tracker-yzr","depends_on_id":"coding_agent_usage_tracker-hws","type":"blocks","created_at":"2026-01-18T14:21:58.732380662-05:00","created_by":"Dicklesworthstone"}]}
{"id":"coding_agent_usage_tracker-zaj","title":"API: Set up axum HTTP server with core endpoints","description":"## Summary\nImplement a local HTTP server using axum that serves usage data via REST API.\n\n## Background\nExternal tools (editor extensions, scripts, dashboards) need programmatic access to caut data. An HTTP server provides:\n1. Language-agnostic interface\n2. Easy integration\n3. Standard REST patterns\n4. Real-time updates via SSE\n\n## Technical Design\n\n### Server Setup\n```rust\nuse axum::{\n    routing::{get, post},\n    Router,\n    extract::{State, Path, Query},\n    response::{Json, Sse},\n    http::StatusCode,\n};\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\npub struct ApiServer {\n    state: Arc\u003cAppState\u003e,\n    port: u16,\n}\n\npub struct AppState {\n    cache: RwLock\u003cHashMap\u003cString, CacheEntry\u003e\u003e,\n    fetchers: HashMap\u003cString, Box\u003cdyn UsageFetcher\u003e\u003e,\n    config: Config,\n}\n\nimpl ApiServer {\n    pub async fn run(\u0026self) -\u003e Result\u003c()\u003e {\n        let app = Router::new()\n            // Usage endpoints\n            .route(\"/api/v1/usage\", get(handlers::get_all_usage))\n            .route(\"/api/v1/usage/:provider\", get(handlers::get_provider_usage))\n            .route(\"/api/v1/usage/:provider/refresh\", post(handlers::refresh_provider))\n            \n            // Status endpoints\n            .route(\"/api/v1/status\", get(handlers::get_all_status))\n            .route(\"/api/v1/status/:provider\", get(handlers::get_provider_status))\n            \n            // History endpoints\n            .route(\"/api/v1/history/:provider\", get(handlers::get_history))\n            \n            // Budget endpoints\n            .route(\"/api/v1/budget\", get(handlers::get_budget_status))\n            \n            // Server-sent events for real-time updates\n            .route(\"/api/v1/events\", get(handlers::sse_events))\n            \n            // Health check\n            .route(\"/health\", get(handlers::health))\n            \n            .with_state(self.state.clone());\n        \n        let addr = format!(\"127.0.0.1:{}\", self.port);\n        println!(\"API server listening on http://{}\", addr);\n        \n        let listener = tokio::net::TcpListener::bind(\u0026addr).await?;\n        axum::serve(listener, app).await?;\n        \n        Ok(())\n    }\n}\n```\n\n### Request Handlers\n```rust\nmod handlers {\n    use super::*;\n    \n    /// GET /api/v1/usage\n    pub async fn get_all_usage(\n        State(state): State\u003cArc\u003cAppState\u003e\u003e,\n    ) -\u003e Result\u003cJson\u003cAllUsageResponse\u003e, StatusCode\u003e {\n        let cache = state.cache.read().await;\n        \n        let providers: Vec\u003c_\u003e = cache\n            .iter()\n            .map(|(name, entry)| ProviderUsageResponse {\n                provider: name.clone(),\n                usage: entry.payload.usage.clone(),\n                status: entry.payload.status.clone(),\n                cached_at: entry.cached_at,\n                staleness: entry.staleness().into(),\n            })\n            .collect();\n        \n        Ok(Json(AllUsageResponse {\n            providers,\n            timestamp: Utc::now(),\n        }))\n    }\n    \n    /// GET /api/v1/usage/:provider\n    pub async fn get_provider_usage(\n        State(state): State\u003cArc\u003cAppState\u003e\u003e,\n        Path(provider): Path\u003cString\u003e,\n    ) -\u003e Result\u003cJson\u003cProviderUsageResponse\u003e, StatusCode\u003e {\n        let cache = state.cache.read().await;\n        \n        cache.get(\u0026provider)\n            .map(|entry| Json(ProviderUsageResponse {\n                provider: provider.clone(),\n                usage: entry.payload.usage.clone(),\n                status: entry.payload.status.clone(),\n                cached_at: entry.cached_at,\n                staleness: entry.staleness().into(),\n            }))\n            .ok_or(StatusCode::NOT_FOUND)\n    }\n    \n    /// POST /api/v1/usage/:provider/refresh\n    pub async fn refresh_provider(\n        State(state): State\u003cArc\u003cAppState\u003e\u003e,\n        Path(provider): Path\u003cString\u003e,\n    ) -\u003e Result\u003cJson\u003cProviderUsageResponse\u003e, StatusCode\u003e {\n        let fetcher = state.fetchers.get(\u0026provider)\n            .ok_or(StatusCode::NOT_FOUND)?;\n        \n        let payload = fetcher.fetch().await\n            .map_err(|_| StatusCode::BAD_GATEWAY)?;\n        \n        // Update cache\n        let mut cache = state.cache.write().await;\n        let entry = CacheEntry::new(payload.clone());\n        cache.insert(provider.clone(), entry.clone());\n        \n        Ok(Json(ProviderUsageResponse {\n            provider,\n            usage: payload.usage,\n            status: payload.status,\n            cached_at: entry.cached_at,\n            staleness: Staleness::Fresh.into(),\n        }))\n    }\n    \n    /// GET /health\n    pub async fn health() -\u003e \u0026'static str {\n        \"ok\"\n    }\n}\n```\n\n### Response Types\n```rust\n#[derive(Serialize)]\npub struct AllUsageResponse {\n    pub providers: Vec\u003cProviderUsageResponse\u003e,\n    pub timestamp: DateTime\u003cUtc\u003e,\n}\n\n#[derive(Serialize)]\npub struct ProviderUsageResponse {\n    pub provider: String,\n    pub usage: UsageSnapshot,\n    pub status: Option\u003cStatusPayload\u003e,\n    pub cached_at: DateTime\u003cUtc\u003e,\n    pub staleness: StalenessResponse,\n}\n\n#[derive(Serialize)]\npub struct StalenessResponse {\n    pub level: String,  // \"fresh\", \"stale\", \"very_stale\"\n    pub age_seconds: Option\u003cu64\u003e,\n}\n```\n\n### CLI Integration\n```bash\n# Start API server\ncaut serve [OPTIONS]\n\nOPTIONS:\n    -p, --port \u003cPORT\u003e    Port to listen on (default: 8420)\n    --host \u003cHOST\u003e        Host to bind to (default: 127.0.0.1)\n    --no-refresh         Disable automatic background refresh\n```\n\n## API Documentation\n| Endpoint | Method | Description |\n|----------|--------|-------------|\n| /api/v1/usage | GET | Get all providers |\n| /api/v1/usage/:provider | GET | Get specific provider |\n| /api/v1/usage/:provider/refresh | POST | Force refresh |\n| /api/v1/status | GET | Get all status |\n| /api/v1/status/:provider | GET | Get provider status |\n| /api/v1/history/:provider | GET | Get usage history |\n| /api/v1/budget | GET | Get budget status |\n| /api/v1/events | GET | SSE event stream |\n| /health | GET | Health check |\n\n## Acceptance Criteria\n- [ ] Server starts and listens on port\n- [ ] GET /api/v1/usage returns all providers\n- [ ] GET /api/v1/usage/:provider returns specific provider\n- [ ] POST refresh triggers fetch\n- [ ] 404 for unknown providers\n- [ ] Health check returns \"ok\"\n- [ ] Localhost binding only (security)\n- [ ] Configurable port\n\n## Security Considerations\n- Bind to localhost only by default (127.0.0.1)\n- No authentication (local only)\n- CORS disabled (localhost doesn't need it)\n- Rate limiting optional\n\n## Dependencies\n```toml\n[dependencies]\naxum = \"0.7\"\ntokio = { version = \"1\", features = [\"full\"] }\ntower-http = { version = \"0.5\", features = [\"cors\", \"trace\"] }\n```\n\n## Dependencies (beads)\n- Requires cache layer (EPIC 9) for data storage\n- Used by SSE streaming task\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:20:05.609038098-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T14:20:05.609038098-05:00"}
{"id":"coding_agent_usage_tracker-zev","title":"Infra: Implement comprehensive logging infrastructure","description":"## Summary\nEnhance existing logging infrastructure with test log capture capabilities for verification in tests.\n\n## Background\nLogging infrastructure already exists in `src/core/logging.rs` using tracing. Test logging exists in `tests/common/logger.rs`. What's **missing** is the ability to capture and assert on log output during tests.\n\n## What Already Exists\n- `tracing` subscriber setup with JSON and human-readable formats\n- `LogLevel` enum with parsing\n- `TestLogger` for structured test output\n\n## What Needs to Be Added\n\n### 1. Test Log Capture for Assertions\n```rust\n// tests/common/log_capture.rs\n\nuse std::sync::{Arc, Mutex};\nuse tracing_subscriber::layer::SubscriberExt;\n\n/// Captures tracing logs during tests for verification.\npub struct TestLogCapture {\n    logs: Arc\u003cMutex\u003cVec\u003cCapturedLog\u003e\u003e\u003e,\n    _guard: tracing::subscriber::DefaultGuard,\n}\n\n#[derive(Debug, Clone)]\npub struct CapturedLog {\n    pub level: tracing::Level,\n    pub target: String,\n    pub message: String,\n    pub fields: Vec\u003c(String, String)\u003e,\n}\n\nimpl TestLogCapture {\n    /// Start capturing logs. Returns guard that stops capture on drop.\n    pub fn start() -\u003e Self {\n        let logs = Arc::new(Mutex::new(Vec::new()));\n        let layer = CaptureLayer { logs: logs.clone() };\n\n        let subscriber = tracing_subscriber::registry().with(layer);\n        let guard = tracing::subscriber::set_default(subscriber);\n\n        Self { logs, _guard: guard }\n    }\n\n    /// Assert a message was logged containing the given substring.\n    pub fn assert_logged(\u0026self, needle: \u0026str) {\n        let logs = self.logs.lock().unwrap();\n        let found = logs.iter().any(|l| l.message.contains(needle));\n        assert!(\n            found,\n            \"Expected log containing '{}'. Logged: {:?}\",\n            needle,\n            logs.iter().map(|l| \u0026l.message).collect::\u003cVec\u003c_\u003e\u003e()\n        );\n    }\n\n    /// Assert a message was logged at the given level.\n    pub fn assert_logged_at_level(\u0026self, level: tracing::Level, needle: \u0026str) {\n        let logs = self.logs.lock().unwrap();\n        let found = logs.iter().any(|l| l.level == level \u0026\u0026 l.message.contains(needle));\n        assert!(\n            found,\n            \"Expected {} log containing '{}'. Logged: {:?}\",\n            level,\n            needle,\n            logs.iter()\n                .filter(|l| l.level == level)\n                .map(|l| \u0026l.message)\n                .collect::\u003cVec\u003c_\u003e\u003e()\n        );\n    }\n\n    /// Assert no errors were logged.\n    pub fn assert_no_errors(\u0026self) {\n        let logs = self.logs.lock().unwrap();\n        let errors: Vec\u003c_\u003e = logs.iter()\n            .filter(|l| l.level == tracing::Level::ERROR)\n            .collect();\n        assert!(errors.is_empty(), \"Unexpected errors: {:?}\", errors);\n    }\n\n    /// Assert a structured field was logged.\n    pub fn assert_field_logged(\u0026self, field_name: \u0026str, field_value: \u0026str) {\n        let logs = self.logs.lock().unwrap();\n        let found = logs.iter().any(|l| {\n            l.fields.iter().any(|(k, v)| k == field_name \u0026\u0026 v.contains(field_value))\n        });\n        assert!(found, \"Expected field {}={}\", field_name, field_value);\n    }\n\n    /// Get all captured logs.\n    pub fn logs(\u0026self) -\u003e Vec\u003cCapturedLog\u003e {\n        self.logs.lock().unwrap().clone()\n    }\n}\n\n// Tracing layer that captures to vec\nstruct CaptureLayer {\n    logs: Arc\u003cMutex\u003cVec\u003cCapturedLog\u003e\u003e\u003e,\n}\n\nimpl\u003cS: tracing::Subscriber\u003e tracing_subscriber::Layer\u003cS\u003e for CaptureLayer {\n    fn on_event(\n        \u0026self,\n        event: \u0026tracing::Event\u003c'_\u003e,\n        _ctx: tracing_subscriber::layer::Context\u003c'_, S\u003e,\n    ) {\n        let mut visitor = FieldVisitor::default();\n        event.record(\u0026mut visitor);\n\n        let log = CapturedLog {\n            level: *event.metadata().level(),\n            target: event.metadata().target().to_string(),\n            message: visitor.message,\n            fields: visitor.fields,\n        };\n\n        self.logs.lock().unwrap().push(log);\n    }\n}\n```\n\n### 2. Integration with Existing TestLogger\n```rust\n// Enhance tests/common/logger.rs\n\nimpl TestLogger {\n    /// Create logger with capture for assertions.\n    pub fn with_capture(test_name: \u0026str) -\u003e (Self, TestLogCapture) {\n        let capture = TestLogCapture::start();\n        let logger = Self::new(test_name);\n        (logger, capture)\n    }\n}\n```\n\n### 3. Convenience Macros\n```rust\n/// Assert log was emitted within test scope\n#[macro_export]\nmacro_rules! assert_logged {\n    ($capture:expr, $needle:expr) =\u003e {\n        $capture.assert_logged($needle)\n    };\n    ($capture:expr, $level:expr, $needle:expr) =\u003e {\n        $capture.assert_logged_at_level($level, $needle)\n    };\n}\n```\n\n## Usage in Tests\n```rust\n#[test]\nfn test_snapshot_recording_logs() {\n    let capture = TestLogCapture::start();\n\n    let store = HistoryStore::open_in_memory().unwrap();\n    store.record_snapshot(\u0026usage_snapshot(50.0, None), \"claude\").unwrap();\n\n    capture.assert_logged(\"Recording usage snapshot\");\n    capture.assert_logged_at_level(tracing::Level::INFO, \"Snapshot recorded\");\n    capture.assert_field_logged(\"provider\", \"claude\");\n    capture.assert_no_errors();\n}\n```\n\n## Acceptance Criteria\n- [ ] TestLogCapture can capture tracing events\n- [ ] assert_logged() works with substrings\n- [ ] assert_logged_at_level() filters by level\n- [ ] assert_field_logged() checks structured fields\n- [ ] assert_no_errors() verifies no ERROR level logs\n- [ ] Integration with existing TestLogger\n- [ ] Documentation with examples\n\n## Dependencies\nAlready have: tracing, tracing-subscriber\nNo new dependencies needed.\n\n## Note\nThis is an enhancement to existing infrastructure, not a replacement. The existing `TestLogger` for structured test output remains unchanged.\n","status":"open","priority":0,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-18T14:47:03.568738837-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-18T15:00:53.634859519-05:00"}
